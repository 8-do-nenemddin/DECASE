{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "LLM_MODEL_FOR_PARSING = \"gpt-4o\"        \n",
    "LLM_MODEL_FOR_DECOMPOSITION = \"gpt-4o\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFP에서 요구사항 추출 및 정제\n",
    "def extract_text_with_page_info(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 페이지별로 추출하고, 각 페이지 시작에 페이지 번호를 표기합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        # 페이지 마커를 맨 앞에 추가하고, 실제 텍스트 내용과 명확히 구분되도록 줄바꿈 추가\n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def initial_text_split(text, chunk_size=4000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 LLM이 처리할 수 있는 크기로 초기 분할합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "        keep_separator=True # 페이지 마커 유지를 위해 True 권장\n",
    "    )\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs\n",
    "\n",
    "def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    final_semantic_chunks = []\n",
    "    req_id_counter = 0\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 시스템 요구사항을 전문적으로 분석하고 개발 표준에 맞춰 구조화하는 시니어 비즈니스 분석가입니다.\n",
    "    사용자가 제공하는 텍스트는 RFP 문서의 특정 섹션이며, 여기서 모든 기능적, 비기능적, 성능, 보안, 데이터, 제약사항 요구사항을 추출해야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "\n",
    "    -   **id**: 고유 식별자. 예를 들어, 기능적 요구사항은 \"FUNC-001\", 비기능적은 \"NFR-001\", 보안은 \"SEC-001\"과 같이 유형 접두사와 일련번호를 결합하여 생성하십시오. (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. 다음 중 하나를 선택: \"기능적\", \"비기능적\", \"성능\", \"보안\", \"데이터\", \"제약사항\", \"시스템 장비 구성\", \"컨설팅\", \"테스트\", \"품질\", \"프로젝트 관리\", \"프로젝트 지원\", \"기타\". 텍스트에 명시된 내용에 따라 가장 적합한 유형을 선택하십시오. (예: \"시스템 장비 구성요구사항\", \"컨설팅 요구사항\" 등 PDF의 분류명 활용)\n",
    "    -   **description**: 요구사항에 대한 명확하고 간결한 설명. 원본 PDF의 '요구사항 명칭'과 '정의', '상세설명/세부내용'을 종합하여 개발 친화적인 형태로 작성하십시오. 하나의 요구사항은 하나의 독립적인 기능 또는 특성을 나타내야 합니다.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 검증할 수 있는 구체적인 테스트 조건이나 결과. 1~2개의 명확한 문장으로 서술하십시오. 원본 텍스트에 직접적인 검증 기준이 없더라도, 요구사항의 내용에 기반하여 합리적으로 추론하여 작성하십시오. (예: \"사용자가 [기능]을 수행했을 때, [예상 결과]가 나타난다.\")\n",
    "    -   **priority**: 요구사항의 중요도. 다음 중 하나를 선택: \"필수\", \"높음\", \"중간\", \"낮음\". (텍스트에 명시되어 있다면 그대로 사용, 아니면 일반적으로 \"필수\"로 추정)\n",
    "    -   **responsible_module**: 이 요구사항이 주로 영향을 미치거나 구현될 것으로 예상되는 시스템/애플리케이션의 주요 모듈 또는 영역 (예: \"로그인 모듈\", \"결제 시스템\", \"관리자 페이지\", \"데이터베이스\"). 텍스트 내용을 기반으로 추론하십시오.\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트. 페이지 구분자(`---PAGE_START_N---`)를 참조하여 정확한 페이지 번호를 파싱하십시오.\n",
    "    -   **raw_text_snippet**: 이 요구사항이 포함된 원본 텍스트 스니펫. 해당 요구사항을 추출하는 데 사용된 원본 문장 또는 단락(예: 표의 해당 행 전체 내용)을 포함하십시오.\n",
    "\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 요구사항이 없다면 빈 배열 `[]`을 반환하십시오.\n",
    "    불필요한 서론, 사업 배경, 계약 조건, 제안 지침 등은 요구사항으로 추출하지 마십시오. PDF의 '상세 요구사항' 목록에 있는 구조화된 항목들 위주로 추출해주십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, chunk_doc in enumerate(initial_chunks):\n",
    "        chunk_text = chunk_doc.page_content\n",
    "        print(f\"--- LLM 처리 중 (요구사항 상세 추출): 청크 {i+1}/{len(initial_chunks)} (길이: {len(chunk_text)}자) ---\")\n",
    "\n",
    "        page_numbers_in_chunk = sorted(list(set(\n",
    "            int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text)\n",
    "        )))\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부입니다. 이 부분에서 모든 시스템 요구사항을 개발자 표준에 맞춰 JSON 형식으로 추출해 주세요.\n",
    "        주어진 텍스트 내의 \"요구사항 고유번호\", \"요구사항 명칭\", \"요구사항 분류\", \"정의\", \"상세설명/세부내용\" 등의 명시적 필드를 최대한 활용하여 JSON 객체를 구성해주십시오.\n",
    "\n",
    "        --- 텍스트 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            llm_response_content = response.choices[0].message.content\n",
    "            try:\n",
    "                extracted_data_outer = json.loads(llm_response_content)\n",
    "                extracted_data_list = []\n",
    "                if isinstance(extracted_data_outer, list):\n",
    "                    extracted_data_list = extracted_data_outer\n",
    "                elif isinstance(extracted_data_outer, dict):\n",
    "                    # 딕셔너리 값 중에 리스트를 찾아 첫 번째 것을 사용 (일반적인 LLM 응답 패턴)\n",
    "                    for key_in_dict in extracted_data_outer:\n",
    "                        if isinstance(extracted_data_outer[key_in_dict], list):\n",
    "                            extracted_data_list = extracted_data_outer[key_in_dict]\n",
    "                            break\n",
    "                    if not extracted_data_list: # 그래도 못찾으면 경고\n",
    "                        print(f\"경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: {list(extracted_data_outer.keys())}\")\n",
    "                else:\n",
    "                    print(f\"경고: LLM으로부터 예상치 못한 JSON 형식 응답 (리스트 또는 객체 내 리스트가 아님). {llm_response_content[:100]}...\")\n",
    "                    continue\n",
    "            except json.JSONDecodeError as e_inner:\n",
    "                print(f\"LLM 응답 내용 JSON 파싱 오류 (내부 시도): {e_inner}. 응답: {llm_response_content[:500]}...\")\n",
    "                continue\n",
    "\n",
    "            for req_idx, req in enumerate(extracted_data_list):\n",
    "                # 'id'가 없거나 비어있으면 생성, 또는 원본 ID 우선 사용\n",
    "                original_id = req.get('id') # LLM이 원본 ID (ECR-001 등)를 id 필드에 넣어줬길 기대\n",
    "                if not original_id:\n",
    "                    req_type_prefix = \"REQ\"\n",
    "                    req_type = req.get('type', '기타').strip()\n",
    "                    if \"기능\" in req_type: req_type_prefix = \"FUNC\"\n",
    "                    elif \"비기능\" in req_type: req_type_prefix = \"NFR\"\n",
    "                    elif \"성능\" in req_type: req_type_prefix = \"PERF\"\n",
    "                    elif \"보안\" in req_type: req_type_prefix = \"SEC\"\n",
    "                    elif \"데이터\" in req_type: req_type_prefix = \"DATA\"\n",
    "                    elif \"제약\" in req_type: req_type_prefix = \"CONST\"\n",
    "                    elif \"장비\" in req_type: req_type_prefix = \"ECR\"\n",
    "                    elif \"컨설팅\" in req_type: req_type_prefix = \"CSR\"\n",
    "                    elif \"테스트\" in req_type: req_type_prefix = \"TER\"\n",
    "                    elif \"품질\" in req_type: req_type_prefix = \"QUR\"\n",
    "                    elif \"관리\" in req_type: req_type_prefix = \"PMR\"\n",
    "                    elif \"지원\" in req_type: req_type_prefix = \"PSR\"\n",
    "                    req_id_counter += 1\n",
    "                    req['id'] = f\"{req_type_prefix}-{req_id_counter:03d}\"\n",
    "\n",
    "                if 'source_pages' not in req or not req['source_pages']:\n",
    "                    req['source_pages'] = page_numbers_in_chunk if page_numbers_in_chunk else []\n",
    "\n",
    "                if 'raw_text_snippet' not in req or not req['raw_text_snippet']:\n",
    "                    req['raw_text_snippet'] = f\"청크 {i+1}에서 추출됨. 원본 청크 일부: {chunk_text[:200]}...\" # 개선 필요\n",
    "\n",
    "                req['type'] = req.get('type', '기타')\n",
    "                req['description'] = req.get('description', '설명 없음')\n",
    "                req['acceptance_criteria'] = req.get('acceptance_criteria', '해당하는 경우 명시')\n",
    "                req['priority'] = req.get('priority', '필수')\n",
    "                req['responsible_module'] = req.get('responsible_module', '미정')\n",
    "                final_semantic_chunks.append(req)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"LLM API 호출 또는 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    return final_semantic_chunks\n",
    "\n",
    "\n",
    "# --- LLM으로 목차 파싱하는 함수 ---\n",
    "def parse_toc_with_llm(toc_raw_text, client_instance, llm_model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 목차 원문 텍스트를 파싱하여 구조화된 목차 항목을 추출합니다.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 PDF 문서에서 추출된 목차(Table of Contents)의 원시 텍스트를 분석하는 전문가입니다.\n",
    "    주어진 텍스트를 파싱하여 각 목차 항목의 제목, 페이지 번호, 그리고 해당 항목이 '요구사항' 관련 내용을 담고 있을 가능성을 분석하여 JSON 형태로 반환해야 합니다.\n",
    "    JSON의 최상위 레벨은 \"toc_entries\"라는 키를 가진 객체여야 하고, 그 키의 값은 목차 항목 객체들의 리스트여야 합니다.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    다음은 PDF에서 추출한 목차로 추정되는 텍스트입니다:\n",
    "\n",
    "    --- 목차 원문 텍스트 시작 ---\n",
    "    {toc_raw_text}\n",
    "    --- 목차 원문 텍스트 끝 ---\n",
    "\n",
    "    이 텍스트를 분석하여 JSON 객체를 반환해주세요. 이 객체는 \"toc_entries\"라는 키를 가져야 하며,\n",
    "    이 키의 값은 각 목차 항목을 나타내는 객체들의 리스트여야 합니다.\n",
    "    각 목차 항목 객체는 다음 키를 가져야 합니다:\n",
    "    - \"title\": (문자열) 목차 항목의 전체 제목. 제목 앞의 번호(예: \"1.\", \"II.\", \"가.\")도 포함해주세요.\n",
    "    - \"page\": (정수) 해당 항목의 시작 페이지 번호.\n",
    "    - \"is_requirement_related\": (불리언) 제목이나 내용을 볼 때, 해당 항목이 '요구사항', '과업 범위', '제안 요청 상세', '기능 명세', '기술 요건' 등과 관련된 내용을 다룰 가능성이 높으면 true, 그렇지 않으면 false로 설정해주세요.\n",
    "\n",
    "    예시 JSON 출력 형식:\n",
    "    {{\n",
    "      \"toc_entries\": [\n",
    "        {{\n",
    "          \"title\": \"1. 사업 개요\",\n",
    "          \"page\": 5,\n",
    "          \"is_requirement_related\": false\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"III. 제안요청 내용\",\n",
    "          \"page\": 6,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"3. 상세 요구사항\",\n",
    "          \"page\": 11,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"* 보안 요구사항 별표\",\n",
    "          \"page\": 63,\n",
    "          \"is_requirement_related\": true\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    만약 주어진 텍스트가 유효한 목차로 보이지 않거나 항목을 전혀 파싱할 수 없다면,\n",
    "    \"toc_entries\" 키의 값으로 빈 리스트 `[]`를 포함하는 JSON 객체를 반환해주세요. (예: {{\"toc_entries\": []}})\n",
    "    \"\"\"\n",
    "    llm_response_content = \"\" # 오류 발생 시 로깅을 위해 미리 선언\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        # print(f\"DEBUG: LLM RAW RESPONSE FOR TOC: {llm_response_content}\")\n",
    "\n",
    "        parsed_data = json.loads(llm_response_content)\n",
    "\n",
    "        extracted_list = []\n",
    "        if isinstance(parsed_data, dict) and \"toc_entries\" in parsed_data and isinstance(parsed_data[\"toc_entries\"], list):\n",
    "            extracted_list = parsed_data[\"toc_entries\"]\n",
    "        else:\n",
    "            print(f\"LLM 응답이 예상된 'toc_entries' 리스트를 포함하는 객체 형식이 아닙니다. 응답: {llm_response_content[:200]}\")\n",
    "            return [] # 빈 리스트 반환\n",
    "\n",
    "        valid_entries = []\n",
    "        for entry in extracted_list:\n",
    "            if isinstance(entry, dict) and 'title' in entry and 'page' in entry:\n",
    "                try:\n",
    "                    entry['page'] = int(entry['page'])\n",
    "                    entry['is_requirement_related'] = bool(entry.get('is_requirement_related', False)) # 명확히 불리언으로\n",
    "                    valid_entries.append(entry)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: 페이지 번호 '{entry.get('page')}'를 정수로 변환할 수 없습니다. 항목 건너뜀: {entry.get('title')}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"경고: 필수 키(title, page)가 누락된 항목입니다. 건너뜀: {entry}\")\n",
    "\n",
    "        return valid_entries\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 목차 파싱 응답 JSON 파싱 오류: {e}. 응답 미리보기: {llm_response_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생 (목차 파싱): {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 새로운 헬퍼 함수들 ---\n",
    "def extract_text_for_pages(full_text_with_pages, start_page_num, end_page_num):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 특정 페이지 범위의 텍스트만 추출합니다.\n",
    "    페이지 마커 '---PAGE_START_N---'를 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 페이지 범위 유효성 검사 (end_page_num이 start_page_num보다 작을 수 없음)\n",
    "    if end_page_num < start_page_num:\n",
    "        # print(f\"경고: 끝 페이지({end_page_num})가 시작 페이지({start_page_num})보다 작습니다. 빈 텍스트를 반환합니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    # 패턴 구성: 시작 페이지부터 (끝 페이지 + 1) 직전까지 모든 내용을 포함\n",
    "    # re.escape를 사용하여 페이지 마커의 특수 문자를 이스케이프할 필요는 여기서는 없음\n",
    "    # DOTALL 플래그를 사용하여 \\n도 .에 매치되도록 함\n",
    "\n",
    "    # 시작점 찾기\n",
    "    start_marker = f\"---PAGE_START_{start_page_num}---\"\n",
    "    start_match = re.search(re.escape(start_marker), full_text_with_pages) # 마커 자체를 찾아야 함\n",
    "\n",
    "    if not start_match:\n",
    "        # print(f\"경고: 시작 마커 '{start_marker}'를 찾을 수 없습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    text_from_start_page = full_text_with_pages[start_match.start():]\n",
    "\n",
    "    # 끝점 찾기 (다음 페이지 마커 ---PAGE_START_{end_page_num + 1}---)\n",
    "    # end_page_num이 문서의 마지막 페이지일 수도 있으므로, end_page_num + 1 마커가 없을 수 있음\n",
    "    end_marker_exclusive = f\"---PAGE_START_{end_page_num + 1}---\"\n",
    "    end_match = re.search(re.escape(end_marker_exclusive), text_from_start_page)\n",
    "\n",
    "    if end_match:\n",
    "        return text_from_start_page[:end_match.start()]\n",
    "    else:\n",
    "        # end_page_num + 1 마커를 찾지 못하면, start_page_num부터 문서 끝까지 반환 (또는 start_page_num ~ end_page_num의 마지막 내용까지)\n",
    "        # 이 경우는 end_page_num이 마지막 페이지이거나, 그 이후 페이지 마커가 없는 경우.\n",
    "        # 좀 더 정확하게 하려면, end_page_num까지의 모든 내용을 가져와야 함.\n",
    "        # 그러나 페이지 마커 구조상, end_page_num의 내용은 end_page_num+1 마커 전까지임.\n",
    "        # 따라서 end_match가 없으면 text_from_start_page 전체가 해당 범위임.\n",
    "        return text_from_start_page\n",
    "\n",
    "\n",
    "def get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages):\n",
    "    \"\"\"\n",
    "    LLM으로 파싱된 목차에서 '상세 요구사항' 및 '보안 요구사항' 관련 섹션 정보를 추출합니다.\n",
    "    \"\"\"\n",
    "    target_sections = []\n",
    "\n",
    "    # 페이지 번호 기준으로 목차 정렬 (LLM이 순서대로 안 줄 수도 있으므로)\n",
    "    sorted_toc = sorted(parsed_toc_entries, key=lambda x: x.get('page', 0))\n",
    "\n",
    "    # 주요 키워드 - 사용자가 제공한 PDF 목차 기반\n",
    "    # \"III. 제안요청 내용\" 안에 \"3. 상세 요구사항\"이 있으므로, \"상세 요구사항\"을 찾는 것이 더 정확함.\n",
    "    keywords_to_find = {\n",
    "        \"상세 요구사항\": {\"min_pages\": 5}, # 최소한 이정도는 될 것이라는 기대\n",
    "        \"보안 요구사항 별표\": {\"min_pages\": 1} # 별표는 짧을 수도 있음\n",
    "        # 필요시 다른 주요 섹션 키워드 추가 가능\n",
    "    }\n",
    "\n",
    "    for i, entry in enumerate(sorted_toc):\n",
    "        entry_title = entry.get('title', '').strip()\n",
    "        entry_page = entry.get('page', 0)\n",
    "\n",
    "        for keyword, props in keywords_to_find.items():\n",
    "            if keyword in entry_title:\n",
    "                start_page = entry_page\n",
    "                end_page = total_pages # 기본값: 문서 끝까지\n",
    "\n",
    "                # 다음 목차 항목의 시작 페이지 - 1을 현재 섹션의 끝 페이지로 설정\n",
    "                # 단, 다음 항목이 현재 항목과 같은 페이지에서 시작하면 안됨 (하위 항목일 수 있으므로)\n",
    "                # 좀 더 정교한 로직: 다음 '주요' 항목을 찾아야 함.\n",
    "                # 여기서는 일단 다음 항목의 시작 페이지를 사용.\n",
    "                # 만약 다음 항목이 현재 항목의 하위 항목처럼 보이면 (예: \"3. 상세 요구사항\" 다음 \"3.1 기능 요구사항\")\n",
    "                # 그 하위 항목의 범위를 포함하도록 확장하거나, 아니면 정말 다음 *다른* 주요 섹션까지 봐야 함.\n",
    "                # 현재 LLM 프롬프트는 is_requirement_related로 판단하므로, 이를 우선적으로 신뢰.\n",
    "\n",
    "                # 다음 'is_requirement_related=False'인 섹션 또는 다음 주요 섹션(로마숫자/대문자 알파벳 등)을 찾아 end_page 설정\n",
    "                # 또는 단순히 다음 목차 항목의 시작 페이지 - 1 로 설정\n",
    "                next_major_section_page = total_pages + 1 # 충분히 큰 값\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page : # 현재 섹션 이후의 페이지만 고려\n",
    "                        # 여기서 '주요 섹션'을 판단하는 기준이 필요함 (예: 로마 숫자, 대문자 번호 등)\n",
    "                        # 또는 is_requirement_related=False 인 첫번째 섹션\n",
    "                        # 또는 단순히 다음 목차 항목\n",
    "                        next_major_section_page = next_entry_page\n",
    "                        break\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page -1)\n",
    "\n",
    "                # 시작 페이지와 끝 페이지 유효성 확보\n",
    "                if end_page < start_page:\n",
    "                    end_page = start_page\n",
    "\n",
    "                # 페이지 수가 너무 적으면 해당 섹션 전체를 포함 (예: 11페이지로 나왔는데 실제로는 62까지일 수 있음)\n",
    "                # 이 부분은 heuristic이므로 주의. 더 좋은 방법은 LLM에게 섹션의 끝을 명확히 묻는 것.\n",
    "                # 여기서는 min_pages 이상은 되어야 유의미하다고 가정.\n",
    "                # if (end_page - start_page + 1) < props.get(\"min_pages\", 1) and (start_page + props.get(\"min_pages\", 1) -1) <= total_pages :\n",
    "                #     pass # end_page = start_page + props.get(\"min_pages\", 1) -1 # 최소 페이지 강제는 위험할 수 있음\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry_title,\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 파싱 목차 기반: '{entry_title}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "                # 찾은 키워드는 중복 추가 방지 (더 구체적인 항목이 먼저 찾아지도록 keywords_to_find 순서 중요)\n",
    "                break\n",
    "\n",
    "    # 만약 아무것도 못찾았지만, is_requirement_related=True 인 항목들이 있다면 그것들을 사용\n",
    "    if not target_sections:\n",
    "        print(\"키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\")\n",
    "        for i, entry in enumerate(sorted_toc):\n",
    "            if entry.get('is_requirement_related'):\n",
    "                start_page = entry.get('page',0)\n",
    "                end_page = total_pages\n",
    "                # 위와 동일한 로직으로 end_page 계산\n",
    "                next_major_section_page = total_pages + 1\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page:\n",
    "                        if not next_entry.get('is_requirement_related', False): # 다음 주요 섹션이 요구사항 관련이 아니면\n",
    "                            next_major_section_page = next_entry_page\n",
    "                            break\n",
    "                        # 또는 다음 항목이 현재 항목보다 상위 레벨이면 (예: \"3.1\" 다음 \"4.\")\n",
    "                        # 이 부분은 제목의 번호 체계를 분석해야 해서 복잡함. LLM의 is_requirement_related를 신뢰.\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page - 1)\n",
    "                if end_page < start_page: end_page = start_page\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry.get('title', '요구사항 관련 섹션'),\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 'is_requirement_related' 플래그 기반: '{entry.get('title')}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "\n",
    "    # 중복 제거 및 병합 (예: \"III. 제안요청 내용\"과 그 하위 \"3. 상세 요구사항\"이 모두 선택된 경우)\n",
    "    # 여기서는 단순화를 위해 중복된 페이지 범위가 있다면 가장 포괄적인 것을 선택하거나,\n",
    "    # 또는 가장 구체적인 \"상세 요구사항\"을 우선. 지금은 일단 나온대로 반환.\n",
    "    # 더 나은 방법은, '상세 요구사항'이 나왔으면 그게 더 우선순위가 높다고 처리.\n",
    "\n",
    "    if not target_sections:\n",
    "        print(\"경고: LLM 파싱 목차에서 주요 요구사항 섹션을 찾지 못했습니다. 전체 문서를 대상으로 할 수 있습니다.\")\n",
    "        return [{'title': '전체 문서 (목차 분석 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    return target_sections\n",
    "\n",
    "\n",
    "def get_toc_raw_text_from_full_text(full_text_with_pages, toc_page_numbers=[2,3]):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 지정된 목차 페이지들의 텍스트만 추출합니다.\n",
    "    \"\"\"\n",
    "    toc_texts = []\n",
    "    for page_num in toc_page_numbers:\n",
    "        # 페이지 마커를 찾아서 해당 페이지의 텍스트를 추출\n",
    "        # (end_page_num + 1) 마커를 찾아서 그 전까지의 내용을 가져옴\n",
    "        page_content = extract_text_for_pages(full_text_with_pages, page_num, page_num)\n",
    "        if page_content:\n",
    "            # 페이지 마커 제거 (이미 extract_text_for_pages가 마커 다음부터 가져오지만, 혹시 몰라서)\n",
    "            # 실제로는 페이지 마커 이후의 텍스트만 필요.\n",
    "            # `extract_text_for_pages`는 마커를 포함해서 반환할 수 있으므로, 마커 이후 내용만 사용.\n",
    "            marker = f\"---PAGE_START_{page_num}---\\n\"\n",
    "            if page_content.startswith(marker):\n",
    "                toc_texts.append(page_content[len(marker):])\n",
    "            else: # 마커가 없는 경우 (예상치 않음)\n",
    "                toc_texts.append(page_content)\n",
    "        else:\n",
    "            print(f\"경고: 목차 페이지로 지정된 {page_num} 페이지에서 텍스트를 찾을 수 없습니다.\")\n",
    "\n",
    "    if not toc_texts:\n",
    "        return None\n",
    "    return \"\\n\".join(toc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decompose_requirement_with_llm(\n",
    "    parent_requirement: Dict[str, Any],\n",
    "    sub_requirement_id_prefix_to_use: str, # 하위 요구사항 ID에 사용할 접두사\n",
    "    sub_req_id_counters: Dict[str, int],    # 접두사별 ID 순번 카운터 (이 함수 호출 간에 상태 유지)\n",
    "    client_instance: OpenAI,\n",
    "    llm_model: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    상위 요구사항을 LLM을 사용하여 세분화된 하위 요구사항 리스트로 변환합니다.\n",
    "    하위 요구사항 ID는 sub_req_id_counters를 참조하여 전체 실행에서 고유하게 생성됩니다.\n",
    "    세분화 수준을 '개발에 적당한 레벨'로 조정합니다.\n",
    "    \"\"\"\n",
    "    parent_id = parent_requirement.get(\"id\", \"UNKNOWN_PARENT\")\n",
    "    parent_description = parent_requirement.get(\"description\", \"\")\n",
    "    parent_acceptance_criteria = parent_requirement.get(\"acceptance_criteria\", \"\")\n",
    "    parent_type = parent_requirement.get(\"type\", \"기능적\")\n",
    "    parent_module = parent_requirement.get(\"responsible_module\", \"미정\")\n",
    "    parent_source_pages = parent_requirement.get(\"source_pages\", []) # 이 필드가 실제 JSON에 있는지 확인 필요\n",
    "\n",
    "\n",
    "    example_sub_tasks_description_style = \"\"\"\n",
    "    예를 들어, \"통계 관리 기능\"을 세분화 한다면 다음과 같은 주요 기능 단위가 나올 수 있습니다 (너무 상세한 개별 항목보다는 기능 그룹에 집중):\n",
    "    - 주요 통계 지표 조회 기능 (교육 과정별, 연도별, 지역별, 기간별 등 주요 필터 포함)\n",
    "    - 웹사이트 방문자 행동 분석 통계 기능 (일자별/단말기별/접속경로별 방문자 수 및 주요 행동 패턴)\n",
    "    - 학습 현황 대시보드 제공 기능 (핵심 지표 시각화 및 요약)\n",
    "    - 통계 데이터 관리 기능 (데이터 수집, 검증, 로그 관리 등)\n",
    "    - 통계 리포팅 및 다운로드 기능 (주요 통계 화면의 보고서 생성 및 데이터 추출)\n",
    "    이처럼 각 하위 요구사항은 개발팀이 하나의 의미 있는 기능 단위로 인식하고 작업을 계획할 수 있는 수준이어야 합니다.\n",
    "    지나치게 많은 수(예: 20개 이상)의 매우 작은 단위로 분해하기보다는, 5~10개 내외의 핵심 하위 기능으로 그룹화하는 것이 좋습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 시스템 요구사항 분석 및 설계 전문가입니다. 주어진 상위 요구사항을 **실제로 개발팀이 작업을 분담하고 진행할 수 있는 적절한 크기의 주요 하위 기능들로 세분화**하는 임무를 받았습니다.\n",
    "    각 하위 요구사항은 그 자체로 의미 있는 기능 단위를 나타내야 하며, 독립적으로 개발 및 테스트가 가능해야 합니다. **너무 과도하게 많은 수의 지나치게 세세한 항목으로 나누는 것은 지양합니다.**\n",
    "\n",
    "    다음은 세분화할 상위 요구사항의 정보입니다:\n",
    "    - 상위 ID: {parent_id}\n",
    "    - 상위 요구사항 명: {parent_description}\n",
    "    - 상위 요구사항 인수 조건: {parent_acceptance_criteria}\n",
    "    - (참고) 상위 요구사항 유형: {parent_type}, 담당 모듈: {parent_module}, 출처 페이지: {parent_source_pages}\n",
    "\n",
    "    아래는 \"{parent_description}\"와 유사한 주제에 대한 세분화 예시입니다. **이 예시에서 제시된 세분화의 '수준'과 '단위의 크기'를 참고**하여 하위 요구사항들을 도출하십시오:\n",
    "    {example_sub_tasks_description_style}\n",
    "\n",
    "    각 하위 요구사항에 대해 다음 JSON 형식을 사용하여 상세 정보를 제공해주십시오.\n",
    "    `id` 필드는 \"TBD\"로 설정해주십시오. (외부에서 `{sub_requirement_id_prefix_to_use}-XXX` 형식으로 부여됨)\n",
    "    다른 필드들은 상위 요구사항 정보와 하위 요구사항의 내용을 바탕으로 적절히 추론하거나 상속하여 채워주십시오.\n",
    "    `description` 필드는 하위 요구사항의 명칭을, `detailed_description` 필드는 그에 대한 상세 설명을 담도록 합니다. (만약 명칭과 설명이 거의 같다면 `detailed_description`은 `description`과 동일하게 작성해도 무방합니다.)\n",
    "\n",
    "    반환 형식은 반드시 하위 요구사항 객체들을 담고 있는 JSON 배열 `[]` 이어야 합니다. 만약 최상위가 배열이 아닌 JSON 객체여야 한다면, **반드시 `sub_requirements` 라는 키의 값으로 하위 요구사항 배열을 제공**하십시오.\n",
    "    주어진 상위 요구사항이 이미 충분히 구체적이어서 더 이상 의미 있는 단위로 세분화하기 어렵다고 판단되면, 빈 배열 `[]`을 반환하십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    상위 요구사항 (ID: {parent_id}, 명칭: \"{parent_description}\")을 위 지침과 예시에 따라, **너무 많지 않은 수의 적절한 개발 단위로** 세분화된 하위 기능 요구사항 리스트로 만들어 주십시오. (이상적으로 5~10개 내외의 주요 하위 기능)\n",
    "    각 하위 요구사항의 JSON 객체는 다음 필드를 포함해야 합니다:\n",
    "    - id: (문자열, \"TBD\"로 설정)\n",
    "    - type: (문자열, 상위 요구사항 유형 '{parent_type}'을 따르거나 \"기능적\"으로 설정)\n",
    "    - description: (문자열, 세분화된 요구사항의 명칭, 예시 스타일 참고)\n",
    "    - acceptance_criteria: (문자열, 세분화된 요구사항의 인수 조건)\n",
    "    - responsible_module: (문자열, 상위 담당 모듈 '{parent_module}' 상속 또는 더 구체적인 모듈)\n",
    "    - parent_id: (문자열, \"{parent_id}\")\n",
    "    - source_pages: (정수 리스트, 상위 출처 페이지 {parent_source_pages} 상속)\n",
    "    \"\"\"\n",
    "\n",
    "    llm_response_str = \"\" # 오류 로깅을 위해 초기화\n",
    "    try:\n",
    "        completion = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2, \n",
    "        )\n",
    "        llm_response_str = completion.choices[0].message.content\n",
    "        logging.debug(f\"LLM Raw Response for parent '{parent_id}':\\n{llm_response_str[:500]}...\")\n",
    "\n",
    "        raw_llm_output_data = json.loads(llm_response_str)\n",
    "        \n",
    "        extracted_sub_reqs_from_llm = []\n",
    "        if isinstance(raw_llm_output_data, dict) and \"sub_requirements\" in raw_llm_output_data and isinstance(raw_llm_output_data[\"sub_requirements\"], list):\n",
    "            extracted_sub_reqs_from_llm = raw_llm_output_data[\"sub_requirements\"]\n",
    "        elif isinstance(raw_llm_output_data, list):\n",
    "             extracted_sub_reqs_from_llm = raw_llm_output_data\n",
    "             logging.warning(f\"LLM이 '{parent_id}'에 대해 직접 리스트를 반환했습니다 (예상: 객체 내 'sub_requirements' 키).\")\n",
    "        else:\n",
    "            logging.warning(f\"LLM이 '{parent_id}'에 대해 예상된 'sub_requirements' 리스트 형식을 반환하지 않음. 응답 타입: {type(raw_llm_output_data)}. 응답 앞부분: {str(raw_llm_output_data)[:200]}\")\n",
    "            return []\n",
    "\n",
    "        final_processed_sub_requirements = []\n",
    "        for sub_req_data_from_llm in extracted_sub_reqs_from_llm:\n",
    "            if not isinstance(sub_req_data_from_llm, dict) or not sub_req_data_from_llm.get(\"description\"):\n",
    "                logging.warning(f\"'{parent_id}'의 하위 요구사항 중 유효하지 않은 항목 발견(description 누락 등): {sub_req_data_from_llm}\")\n",
    "                continue\n",
    "\n",
    "            current_count = sub_req_id_counters.get(sub_requirement_id_prefix_to_use, 0) + 1\n",
    "            sub_req_id_counters[sub_requirement_id_prefix_to_use] = current_count\n",
    "            \n",
    "            processed_sub_req = {\n",
    "                \"id\": f\"{sub_requirement_id_prefix_to_use}-{current_count:03d}\",\n",
    "                \"type\": sub_req_data_from_llm.get(\"type\", parent_type),\n",
    "                \"description\": sub_req_data_from_llm.get(\"description\"),\n",
    "                \"acceptance_criteria\": sub_req_data_from_llm.get(\"acceptance_criteria\", \"세부 인수 조건 정의 필요\"),\n",
    "                \"responsible_module\": sub_req_data_from_llm.get(\"responsible_module\", parent_module),\n",
    "                \"parent_id\": parent_id,\n",
    "                \"source_pages\": parent_source_pages \n",
    "            }\n",
    "            final_processed_sub_requirements.append(processed_sub_req)\n",
    "            \n",
    "        return final_processed_sub_requirements\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"'{parent_id}' 세분화 중 LLM 응답 JSON 파싱 실패: {e}. 응답 내용(앞 500자): {llm_response_str[:500]}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"'{parent_id}' 세분화 중 예기치 않은 오류 발생: {e}\", exc_info=True)\n",
    "        return []\n",
    "    \n",
    "\n",
    "\n",
    "def batch_decompose_requirements_from_file(\n",
    "    input_json_path: str,\n",
    "    output_json_path: str,\n",
    "    default_sub_req_id_prefix: str,\n",
    "    client_instance: OpenAI,\n",
    "    llm_model: str\n",
    "):\n",
    "    \"\"\"\n",
    "    입력 JSON 파일에서 상위 요구사항 리스트를 읽어 각각을 세분화하고,\n",
    "    모든 생성된 하위 요구사항을 취합하여 출력 JSON 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "            all_parent_requirements = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"입력 JSON 파일 '{input_json_path}'를 찾을 수 없습니다.\")\n",
    "        return\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"입력 JSON 파일 '{input_json_path}' 파싱 오류: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logging.error(f\"입력 JSON 파일 '{input_json_path}' 로드 중 오류: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    if not isinstance(all_parent_requirements, list):\n",
    "        logging.error(f\"입력 JSON 데이터가 리스트 형식이 아닙니다 (타입: {type(all_parent_requirements)}).\")\n",
    "        return\n",
    "\n",
    "    all_generated_sub_requirements: List[Dict] = []\n",
    "    sub_req_id_counters_map: Dict[str, int] = {} \n",
    "\n",
    "    for parent_req_index, parent_req_data in enumerate(all_parent_requirements):\n",
    "        if not isinstance(parent_req_data, dict):\n",
    "            logging.warning(f\"입력 파일의 {parent_req_index+1}번째 항목이 딕셔너리가 아닙니다. 건너<0xEB><0x9A><0x84>니다: {parent_req_data}\")\n",
    "            continue\n",
    "        \n",
    "        parent_id_for_log = parent_req_data.get(\"id\", f\"UNKNOWN_PARENT_{parent_req_index+1}\")\n",
    "        logging.info(f\"\\n--- {parent_req_index+1}/{len(all_parent_requirements)}번째 상위 요구사항 '{parent_id_for_log}' 세분화 시작 ---\")\n",
    "        \n",
    "        \n",
    "        decomposed_list = decompose_requirement_with_llm(\n",
    "            parent_requirement=parent_req_data,\n",
    "            sub_requirement_id_prefix_to_use=default_sub_req_id_prefix,\n",
    "            sub_req_id_counters=sub_req_id_counters_map,\n",
    "            client_instance=client_instance,\n",
    "            llm_model=llm_model\n",
    "        )\n",
    "        \n",
    "        if decomposed_list:\n",
    "            all_generated_sub_requirements.extend(decomposed_list)\n",
    "        else:\n",
    "            logging.warning(f\"상위 요구사항 '{parent_id_for_log}'에 대해 하위 요구사항이 생성되지 않았습니다. 원본 요구사항을 유지하거나 다른 처리를 할 수 있습니다.\")\n",
    "\n",
    "    logging.info(f\"\\n--- 총 {len(all_generated_sub_requirements)}개의 하위 요구사항 생성 완료 ---\")\n",
    "\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_generated_sub_requirements, f, ensure_ascii=False, indent=4)\n",
    "        logging.info(f\"모든 세분화된 요구사항이 '{output_json_path}' 파일로 성공적으로 저장되었습니다.\")\n",
    "    except IOError as e:\n",
    "        logging.error(f\"출력 JSON 파일 '{output_json_path}' 쓰기 중 I/O 오류: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"출력 JSON 파일 저장 중 예기치 않은 오류: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 메인 실행 블록 ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"docs/제주은행_RFP.pdf\" # 실제 파일 경로\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"오류: PDF 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "        exit()\n",
    "\n",
    "    print(\"1. PDF 전체 텍스트 추출 중...\")\n",
    "    full_document_text, total_pages = extract_text_with_page_info(pdf_file_path)\n",
    "    if not full_document_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다 ({pdf_file_path}).\")\n",
    "        exit()\n",
    "    print(f\"   PDF 전체 텍스트 추출 완료. 총 {total_pages} 페이지, 전체 텍스트 길이: {len(full_document_text)}자.\")\n",
    "\n",
    "    print(\"\\n2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\")\n",
    "    # 사용자 PDF 분석 결과 PAGE 2, 3에 목차가 있음\n",
    "    toc_raw_text = get_toc_raw_text_from_full_text(full_document_text, toc_page_numbers=[2, 3])\n",
    "\n",
    "    target_sections_for_extraction = []\n",
    "    if toc_raw_text:\n",
    "        print(f\"   목차 원문 텍스트 추출 완료 (길이: {len(toc_raw_text)}자).\")\n",
    "        print(\"\\n3. LLM을 사용하여 목차(ToC) 파싱 중...\")\n",
    "        parsed_toc_entries = parse_toc_with_llm(toc_raw_text, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "        if parsed_toc_entries:\n",
    "            print(f\"   LLM 목차 파싱 완료. {len(parsed_toc_entries)}개의 목차 항목 식별.\")\n",
    "            print(\"\\n4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\")\n",
    "            target_sections_for_extraction = get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages)\n",
    "        else:\n",
    "            print(\"   LLM 목차 파싱 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "            target_sections_for_extraction = [{'title': '전체 문서 (LLM 목차 파싱 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "    else:\n",
    "        print(\"   목차 원문 텍스트 추출 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "        target_sections_for_extraction = [{'title': '전체 문서 (목차 원문 추출 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    if not target_sections_for_extraction: # 만약을 위해 한번 더 체크\n",
    "        print(\"오류: 분석할 대상 섹션을 정의하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n5. 식별된 주요 섹션으로부터 텍스트 결합 중...\")\n",
    "    all_requirements_related_text_parts = []\n",
    "    for section_info in target_sections_for_extraction:\n",
    "        print(f\"   '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']}) 텍스트 추출 시도...\")\n",
    "        section_text = extract_text_for_pages(full_document_text, section_info['start_page'], section_info['end_page'])\n",
    "        if section_text:\n",
    "            all_requirements_related_text_parts.append(section_text)\n",
    "            print(f\"       '{section_info['title']}' 섹션 텍스트 추출 완료 (길이: {len(section_text)}자).\")\n",
    "        else:\n",
    "            print(f\"       경고: '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']})에서 텍스트를 추출하지 못했습니다.\")\n",
    "\n",
    "    if not all_requirements_related_text_parts:\n",
    "        print(\"오류: 주요 요구사항 섹션에서 텍스트를 전혀 추출하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    combined_requirements_text = \"\\n\\n\".join(all_requirements_related_text_parts) # 섹션 간 구분을 위해 두 줄바꿈\n",
    "    print(f\"   주요 섹션 텍스트 결합 완료. 총 길이: {len(combined_requirements_text)}자.\")\n",
    "\n",
    "    print(\"\\n6. 결합된 텍스트 초기 분할 중...\")\n",
    "    # chunk_size는 LLM의 context window와 한글 토큰 소모를 고려하여 설정\n",
    "    initial_chunks = initial_text_split(combined_requirements_text, chunk_size=3500, chunk_overlap=350)\n",
    "    print(f\"   총 {len(initial_chunks)}개의 초기 청크가 생성되었습니다.\")\n",
    "\n",
    "    if not initial_chunks:\n",
    "        print(\"오류: 텍스트 분할 결과 청크가 없습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\")\n",
    "    extracted_requirements = llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "    print(\"\\n8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\")\n",
    "    # (기존 스크립트의 후처리 로직 사용 또는 필요시 개선)\n",
    "    unique_requirements_by_id = {}\n",
    "    processed_requirements = []\n",
    "    if extracted_requirements:\n",
    "        for req in extracted_requirements:\n",
    "            req_id = req.get('id', str(uuid.uuid4())) # ID가 없다면 UUID로 임시 ID\n",
    "            if req_id not in unique_requirements_by_id:\n",
    "                unique_requirements_by_id[req_id] = req\n",
    "            else:\n",
    "                # ID가 중복될 경우, 설명을 합치거나 페이지 정보를 합치는 등의 로직 추가 가능\n",
    "                # 여기서는 간단히 첫 번째 것만 유지하거나, 필요에 따라 업데이트\n",
    "                # 예: 페이지 정보 병합\n",
    "                existing_req = unique_requirements_by_id[req_id]\n",
    "                new_pages = req.get('source_pages', [])\n",
    "                if new_pages:\n",
    "                    existing_req_pages = existing_req.get('source_pages', [])\n",
    "                    existing_req['source_pages'] = sorted(list(set(existing_req_pages + new_pages)))\n",
    "                print(f\"중복 ID '{req_id}' 감지. 정보 업데이트 시도.\")\n",
    "        processed_requirements = list(unique_requirements_by_id.values())\n",
    "    else:\n",
    "        print(\"   추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    # 최종 결과 출력 또는 저장\n",
    "    print(f\"\\n--- 최종 추출된 고유 요구사항 수: {len(processed_requirements)}개 ---\")\n",
    "    if processed_requirements:\n",
    "        print(\"\\n--- 추출된 요구사항 미리보기 (상위 3개) ---\")\n",
    "        for i, req_item in enumerate(processed_requirements[:3]): # 'req' 변수명 충돌 피하기 위해 'req_item'으로 변경\n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        output_filename = \"extracted_requirements_final.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"\\n추출된 요구사항이 '{output_filename}' 파일에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"최종적으로 추출된 요구사항이 없습니다.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI # 실제 실행 시 필요\n",
    "import concurrent.futures\n",
    "import os # For API Key environment variable (recommended)\n",
    "from typing import TypedDict, Dict, Any, List, Optional\n",
    "\n",
    "# 작업 1: 요구사항 분류\n",
    "def generate_classification_prompt_text(description, detailed_description, module):\n",
    "    return f\"\"\"\n",
    "당신은 차세대 정보시스템 구축 프로젝트에서 요구사항을 분석하고, 아래 기준에 따라 대분류, 중분류, 소분류를 분류하는 전문가입니다.\n",
    "\n",
    "다음 요구사항 설명을 읽고 각 분류 항목에 맞게 분류해 주세요:\n",
    "\n",
    "[요구사항 설명]\n",
    "{description}\n",
    "\n",
    "[상세 설명]\n",
    "{detailed_description}\n",
    "\n",
    "[담당 모듈]\n",
    "{module}\n",
    "\n",
    "[분류 기준]\n",
    "1. **대분류**: 차세대 정보시스템 업무 수준\n",
    "   예시: 수신, 여신, 부대/대행, 통합고객 등\n",
    "\n",
    "2. **중분류**: 단위업무 시스템 수준\n",
    "   예시: 예금, 신탁, 상담신청, 심사승인 등\n",
    "\n",
    "3. **소분류**: 단위업무 시스템 하위 수준 (업무 프로세스 3~4레벨)\n",
    "   ※ 소분류는 3레벨 분류가 어려운 경우 선택적으로 작성해도 무방함\n",
    "\n",
    "아래 형식으로 정확히 출력하세요 (불필요한 설명 없이):\n",
    "\n",
    "대분류: <텍스트>\n",
    "중분류: <텍스트>\n",
    "소분류: <텍스트 또는 '해당 없음'>\n",
    "\n",
    "※ 유의사항:\n",
    "- 반드시 대분류 → 중분류 → 소분류 순으로 작성\n",
    "- 각 분류명은 명확하고 직관적인 한국어 명사형 표현을 사용할 것\n",
    "- 기존 분류 체계가 없으므로, 의미적으로 유사한 요구사항끼리 논리적으로 묶어서 계층화할 것\n",
    "- 불필요한 설명 없이 위 형식만 출력\n",
    "\"\"\"\n",
    "\n",
    "def classify_requirement_logic(description: str, detailed_description: str, module: str) -> Dict[str, str]:\n",
    "    prompt = generate_classification_prompt_text(description, detailed_description, module)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", # 또는 gpt-4-turbo, gpt-3.5-turbo 등 사용 가능한 모델\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 소프트웨어 분석 및 분류 전문가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        content = response.choices[0].message.content or \"\"\n",
    "        lines = [line.strip() for line in content.splitlines() if \":\" in line]\n",
    "\n",
    "        def extract_value(prefix):\n",
    "            for line in lines:\n",
    "                if line.startswith(prefix):\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    if len(parts) == 2:\n",
    "                        return parts[1].strip()\n",
    "            return \"미분류\"\n",
    "\n",
    "        return {\n",
    "            \"category_large\": extract_value(\"대분류\"),\n",
    "            \"category_medium\": extract_value(\"중분류\"),\n",
    "            \"category_small\": extract_value(\"소분류\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classify_requirement_logic: {e}\")\n",
    "        return {\n",
    "            \"category_large\": \"Error\",\n",
    "            \"category_medium\": \"Error\",\n",
    "            \"category_small\": \"Error\"\n",
    "        }\n",
    "\n",
    "# 작업 2: 난이도 평가\n",
    "def generate_difficulty_prompt_text(description, detailed_description, module):\n",
    "    return f\"\"\"\n",
    "당신은 소프트웨어 요구사항의 기술적 구현 난이도를 분석하고 평가하는 **수십 년 경력의 베테랑 개발 팀장 또는 시스템 아키텍트**입니다. 제시된 요구사항의 **기술적 복잡성, 필요한 리서치 및 학습량, 구현에 필요한 공수, 외부 시스템과의 연동 복잡성, 테스트의 난해함, 그리고 잠재적인 리스크** 등을 종합적으로 고려하여 난이도를 '상', '중', '하' 중 하나로 매우 신중하고 일관성 있게 평가해야 합니다.\n",
    "\n",
    "다음은 시스템에 대한 요구사항입니다:\n",
    "\n",
    "[요구사항 설명]\n",
    "{description}\n",
    "\n",
    "[상세 설명]\n",
    "{detailed_description}\n",
    "\n",
    "[담당 모듈]\n",
    "{module}\n",
    "\n",
    "요구사항을 분석한 뒤, 다음의 **판단 가이드라인과 세부 평가 기준**을 참고하여 난이도를 평가하세요:\n",
    "\n",
    "**[판단 가이드라인: 난이도에 영향을 미치는 주요 요소]**\n",
    "1.  **요구사항의 명확성 및 구체성:** 요구사항이 모호하거나 해석의 여지가 많을수록 분석 및 설계 단계부터 어려움이 추가되어 난이도가 상승합니다.\n",
    "2.  **기술적 생소함 및 복잡도:** 새로운 프로그래밍 언어, 프레임워크, 라이브러리, 알고리즘의 도입이 필요하거나, 기존에 다뤄보지 않은 매우 복잡한 기술적 구현이 요구될 경우 난이도가 높습니다.\n",
    "3.  **시스템 연동의 범위 및 복잡도:** 연동해야 할 내부/외부 시스템의 수가 많거나, 연동 방식(API, 프로토콜 등)이 복잡하거나, 연동 대상 시스템의 문서화가 미흡하거나 기술 지원이 원활하지 않을 경우 난이도가 크게 상승합니다.\n",
    "4.  **데이터 처리 및 마이그레이션의 복잡성:** 처리해야 할 데이터의 양이 매우 방대하거나, 데이터 구조가 복잡하거나, 기존 시스템과의 데이터 정합성 유지 및 마이그레이션 작업이 까다로울 경우 난이도가 높습니다.\n",
    "5.  **기존 시스템에 대한 영향 (Side Effect):** 요구사항 구현으로 인해 기존 시스템의 다른 부분에 예상치 못한 영향을 미칠 가능성이 높고, 이로 인해 광범위한 테스트와 수정이 필요할 경우 난이도가 증가합니다.\n",
    "6.  **테스트의 복잡성 및 용이성:** 단위 테스트, 통합 테스트, 시스템 테스트 시나리오가 복잡하거나, 테스트 환경 구축이 어렵거나, 테스트 데이터 생성이 까다로운 경우 난이도가 높습니다.\n",
    "7.  **비기능적 요구사항의 달성 난이도:** 매우 높은 수준의 성능(응답 시간, 처리량), 보안(암호화, 접근 제어), 안정성, 확장성 등의 비기능적 요구사항을 만족시켜야 한다면 기술적 도전 과제가 많아져 난이도가 상승합니다.\n",
    "8.  **유지보수성 고려:** 향후 유지보수가 용이하도록 코드를 구조화하고 문서화하는 데 추가적인 노력이 많이 필요할 것으로 예상되면 난이도에 반영될 수 있습니다.\n",
    "\n",
    "**[난이도 평가 기준]**\n",
    "\n",
    "* **상 (H, High):**\n",
    "    * **판단 근거:** 위의 판단 가이드라인 중 **다수 항목에서 높은 수준의 복잡성 또는 불확실성**이 확인되거나, **특정 한두 요소가 프로젝트 일정에 심각한 지연을 초래할 만큼 매우 치명적인 기술적 장벽**을 포함하는 경우.\n",
    "    * **특징적 상황:**\n",
    "        * 핵심 아키텍처 변경 또는 검증되지 않은 신기술의 광범위한 도입/연구가 필요함.\n",
    "        * 매우 복잡한 알고리즘 설계 및 구현, 또는 전례 없는 수준의 시스템 연동이 요구됨.\n",
    "        * 요구사항의 불확실성이 극도로 높아 초기 분석/설계 단계에서부터 상당한 시간과 리서치, PoC(Proof of Concept)가 필요함.\n",
    "        * 구현 실패의 리스크가 높거나, 성공하더라도 사전에 계획된 개발 일정을 현저히 초과할 가능성이 매우 농후함.\n",
    "        * 해결을 위해 팀 내 최고 수준의 전문가 투입 또는 외부 전문 컨설팅이 필요할 수 있음.\n",
    "    * **일정 영향:** 자체 개발 일정에 **심각한 차질(예: 주요 마일스톤의 상당한 지연, 예정된 리소스 초과 등)**을 초래할 정도의 매우 높은 노력과 시간이 필요하며, 별도의 핵심 과제로 관리되어야 하는 수준.\n",
    "\n",
    "* **중 (M, Medium):**\n",
    "    * **판단 근거:** 판단 가이드라인 중 **일부 항목에서 중간 정도의 복잡성**이 관찰되거나, 해결해야 할 몇 가지 기술적 고려사항 및 도전 과제가 명확히 존재하는 경우.\n",
    "    * **특징적 상황:**\n",
    "        * 익숙한 기술 스택을 기반으로 하지만 새로운 기능을 개발하거나 기존 기능에 대한 상당한 수정이 필요함.\n",
    "        * 일부 복잡한 비즈니스 로직, 혹은 예측 가능한 범위 내의 기술적 문제 해결이 요구됨.\n",
    "        * 내부 모듈 간의 복잡한 상호작용 또는 비교적 잘 정의된 외부 시스템과의 연동 작업이 포함됨.\n",
    "        * 어느 정도의 분석/설계 시간이 필요하며, 구현 중 예상치 못한 이슈가 발생할 수 있으나 관리 가능한 수준.\n",
    "    * **일정 영향:** 집중적인 노력과 계획적인 접근을 통해 **자체 개발 일정 내에 충분히 완수 가능**하나, 일정 내에서도 타이트하거나 약간의 도전이 따를 수 있는 수준.\n",
    "\n",
    "* **하 (L, Low):**\n",
    "    * **판단 근거:** 판단 가이드라인의 대부분 항목에서 복잡성이 낮거나, 기술적으로 **매우 명확하고 직접적인 해결 방법**이 존재하는 경우.\n",
    "    * **특징적 상황:**\n",
    "        * 기존 기능의 단순 버그 수정, UI 텍스트 변경, 경미한 디자인 조정, 이미 잘 구축된 컴포넌트의 재활용 또는 매우 간단한 로직의 추가.\n",
    "        * 새로운 기술 학습이나 복잡한 분석/설계 과정이 거의 불필요하며, 구현 경로가 명확함.\n",
    "        * 타 시스템과의 연동이 없거나 매우 단순하며, 테스트가 용이함.\n",
    "    * **일정 영향:** 현재 진행 중인 다른 작업과 병행하거나, **자체 개발 일정의 일부분으로 특별한 부담 없이 충분히 흡수**되어 별도의 추가 공수 산정 없이 진행 가능한 수준.\n",
    "\n",
    "아래와 같이 **정확히 이 형식**으로만 출력하세요 (불필요한 설명 없이):\n",
    "\n",
    "난이도: <상|중|하>\n",
    "\"\"\"\n",
    "\n",
    "def get_difficulty_logic(description: str, detailed_description: str, module: str) -> str:\n",
    "    prompt = generate_difficulty_prompt_text(description, detailed_description, module)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", # 또는 gpt-4-turbo, gpt-3.5-turbo 등 사용 가능한 모델\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 소프트웨어 분석 전문가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4\n",
    "        )\n",
    "        content = response.choices[0].message.content or \"\"\n",
    "        difficulty = next((line.split(\":\")[1].strip() for line in content.splitlines() if \"난이도\" in line), \"중\") # 기본값을 '중'으로 설정\n",
    "        return difficulty\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_difficulty_logic: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# 작업 3: 중요도 평가\n",
    "def generate_importance_prompt_text(description, detailed_description, module):\n",
    "    return f\"\"\"\n",
    "당신은 소프트웨어 요구사항을 분석하여 중요도를 판단하는 **매우 숙련되고 비판적인 시스템 분석가**입니다. 제시된 기준과 판단 가이드라인에 따라 각 요구사항의 중요도를 '상', '중', '하' 중 하나로 **극도로 신중하고 일관성 있게** 평가해야 합니다. **'상' 등급은 매우 제한적으로 사용되어야 함**을 명심하십시오.\n",
    "\n",
    "다음은 시스템에 대한 요구사항입니다:\n",
    "\n",
    "[요구사항 설명]\n",
    "{description}\n",
    "\n",
    "[상세 설명]\n",
    "{detailed_description}\n",
    "\n",
    "[담당 모듈]\n",
    "{module}\n",
    "\n",
    "요구사항을 분석한 뒤, 아래의 **세분화된 기준과 판단 가이드라인**에 따라 중요도를 평가하세요:\n",
    "\n",
    "**[판단 가이드라인]**\n",
    "1.  **가장 먼저 '상' (Critical)에 해당하는지 극도로 보수적으로 판단합니다.** 이 요구사항이 없으면 시스템 자체가 완전히 무너지거나 법적/보안적으로 회복 불가능한 치명적 문제가 발생하는지 자문하십시오. **대부분의 요구사항은 '상'에 해당하지 않을 가능성이 높습니다.**\n",
    "2.  '상'이 아니라면, '중' (Important)에 해당하는지 검토합니다.\n",
    "3.  '상'도 '중'도 아니라면 '하' (Useful)로 평가합니다.\n",
    "4.  요구사항의 단어나 문구에 현혹되지 말고, **실제 시스템 전체에 미치는 파급 효과와 해당 요구사항 실패 시의 구체적인 결과를 기준으로 냉정하게 판단**하십시오. 모든 요구사항이 중요해 보일 수 있지만, 자원은 한정되어 있으므로 상대적인 중요도를 엄격히 구분해야 합니다.\n",
    "\n",
    "**[중요도 평가 기준]**\n",
    "\n",
    "* **상 (C, Critical):**\n",
    "    * **판단 기준:** 해당 요구사항의 미구현이 **시스템 전체의 핵심 기능 마비, 서비스 불가능 상태 초래, 심각한 법적/규제적 문제 야기, 대규모 중요 데이터의 영구적 손실 또는 오염, 회복 불가능한 치명적 보안 사고 발생**과 같이 프로젝트의 존립을 위협하거나 시스템 전체의 실패를 의미하는 경우에만 해당합니다. **대체 수단이 전혀 없거나, 그 영향이 조직/서비스 전체에 즉각적이고 치명적인 경우**에만 극히 제한적으로 부여합니다.\n",
    "    * **'상'이 아닌 경우 (예시):** 단순히 \"필수적\"이라고 언급되거나, 중요한 기능처럼 보이더라도, 위와 같은 수준의 치명적이고 즉각적인 결과로 이어지지 않는다면 '상'으로 평가해서는 안 됩니다. 예를 들어, 특정 기능의 부재가 큰 불편을 야기하지만 시스템의 다른 핵심 기능은 정상 동작한다면 '상'이 아닙니다.\n",
    "\n",
    "* **중 (I, Important):**\n",
    "    * **판단 기준:** 시스템의 기능적 완성도, 운영 효율성, 사용자 만족도에 **상당한 영향을 미치지만, 그것이 없다고 해서 시스템 전체가 즉시 마비되거나 사용 불가능 상태가 되지는 않는 경우**입니다. 미구현 시 서비스 중단까지는 아니지만, 주요 사용자의 큰 불편을 초래하거나, 기업의 수익/평판에 측정 가능한 부정적 영향을 미치거나, 핵심 업무 프로세스에 심각한 차질을 주는 경우 해당됩니다.\n",
    "    * **'중'이 아닌 경우 (예시):** 사소한 불편함, 일부 제한된 사용자에게만 영향, 또는 있으면 좋지만 없어도 큰 지장이 없는 경우는 '중'이 아닙니다.\n",
    "\n",
    "* **하 (U, Useful):**\n",
    "    * **판단 기준:** 구현되면 유용하고 사용자 경험을 개선할 수 있지만, 미구현되어도 시스템의 핵심 기능, 안정성, 보안 및 주요 사용자 그룹의 전반적인 만족도에 **심각한 영향을 주지 않는 사항**입니다. 약간의 불편함이 있거나, 특정 소수의 사용자에게만 영향을 미치거나, 다른 기능으로 비교적 쉽게 대체 가능하거나, 장기적으로 고려할 만한 개선 사항인 경우 해당됩니다.\n",
    "\n",
    "아래와 같이 **정확히 이 형식**으로만 출력하세요 (불필요한 설명 없이):\n",
    "\n",
    "중요도: <상|중|하>\n",
    "\"\"\"\n",
    "\n",
    "def get_importance_logic(description: str, detailed_description: str, module: str) -> str:\n",
    "    prompt = generate_importance_prompt_text(description, detailed_description, module)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", # 또는 gpt-4-turbo, gpt-3.5-turbo 등 사용 가능한 모델\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 소프트웨어 분석 전문가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4\n",
    "        )\n",
    "        content = response.choices[0].message.content or \"\"\n",
    "        importance = next((line.split(\":\")[1].strip() for line in content.splitlines() if \"중요도\" in line), \"중\") # 기본값을 '중'으로 설정\n",
    "        return importance\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_importance_logic: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# --- LangGraph 부분 시작 ---\n",
    "# langgraph 라이브러리가 설치되어 있어야 합니다: pip install langgraph\n",
    "try:\n",
    "    from langgraph.graph import StateGraph, END\n",
    "except ImportError:\n",
    "    print(\"langgraph 라이브러리가 설치되지 않았습니다. 'pip install langgraph'로 설치해주세요.\")\n",
    "    exit()\n",
    "\n",
    "class RequirementAnalysisState(TypedDict, total=False):\n",
    "    # Fields from your input JSON\n",
    "    id: str\n",
    "    type: str\n",
    "    description: str\n",
    "    detailed_description: str\n",
    "    acceptance_criteria: str\n",
    "    responsible_module: str\n",
    "    parent_id: str\n",
    "    source_pages: List[int]\n",
    "\n",
    "    # Fields populated by LLM tasks\n",
    "    # classification: Dict[str, str]  # 이 줄을 삭제합니다.\n",
    "    category_large: str             # 다음 세 줄을 추가합니다.\n",
    "    category_medium: str\n",
    "    category_small: str\n",
    "    difficulty: str\n",
    "    importance: str\n",
    "\n",
    "    # Final aggregated output for each item\n",
    "    combined_results: Dict[str, Any]\n",
    "# LangGraph 노드 정의\n",
    "# 각 노드는 상태(state)를 입력으로 받고, 업데이트할 상태 부분을 담은 딕셔너리를 반환합니다.\n",
    "\n",
    "# (node_classify_requirement, node_get_difficulty, node_get_importance는 병렬 실행 노드에서 직접 호출되므로 여기서는 생략 가능)\n",
    "\n",
    "# 병렬 실행을 위한 통합 노드\n",
    "# 이 노드 내에서 ThreadPoolExecutor를 사용하여 세 가지 작업을 병렬로 실행합니다.\n",
    "def node_parallel_assessments(state: RequirementAnalysisState) -> Dict[str, Any]:\n",
    "    description = state[\"description\"]\n",
    "    detailed_description = state[\"detailed_description\"]\n",
    "    module = state[\"responsible_module\"]\n",
    "\n",
    "    # results 딕셔너리는 각 로직 함수의 반환 값을 임시 저장합니다.\n",
    "    # classify_requirement_logic의 반환 값은 여전히 딕셔너리입니다.\n",
    "    classification_dict: Dict[str, str] = {} # 타입 힌트 추가\n",
    "    difficulty_str: str = \"\"\n",
    "    importance_str: str = \"\"\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_classify = executor.submit(classify_requirement_logic, description, detailed_description, module)\n",
    "        future_difficulty = executor.submit(get_difficulty_logic, description, detailed_description, module)\n",
    "        future_importance = executor.submit(get_importance_logic, description, detailed_description, module)\n",
    "\n",
    "        classification_dict = future_classify.result()\n",
    "        difficulty_str = future_difficulty.result()\n",
    "        importance_str = future_importance.result()\n",
    "\n",
    "    # 반환하는 딕셔너리가 RequirementAnalysisState의 개별 키와 일치하도록 수정\n",
    "    return {\n",
    "        \"category_large\": classification_dict.get(\"category_large\", \"미분류\"),\n",
    "        \"category_medium\": classification_dict.get(\"category_medium\", \"미분류\"),\n",
    "        \"category_small\": classification_dict.get(\"category_small\", \"미분류\"),\n",
    "        \"difficulty\": difficulty_str,\n",
    "        \"importance\": importance_str,\n",
    "    }\n",
    "\n",
    "# 모든 결과를 취합하는 노드\n",
    "def node_combine_results(state: RequirementAnalysisState) -> Dict[str, Any]:\n",
    "\n",
    "    # combined_data는 현재 state의 모든 항목 (입력 + LLM 결과)을 포함해야 합니다.\n",
    "    # 'combined_results' 키 자체는 최종 상태 업데이트를 위한 것이므로 제외합니다.\n",
    "    \n",
    "    combined_data_for_output: Dict[str, Any] = {}\n",
    "    for key, value in state.items():\n",
    "        if key != \"combined_results\": # 'combined_results'는 이 노드가 채울 필드이므로 복사 대상에서 제외\n",
    "            combined_data_for_output[key] = value\n",
    "    \n",
    "    # LLM 분석 결과 필드가 명시적으로 포함되었는지 확인 (이미 state.items()에 포함되어 있을 것임)\n",
    "    # 이 부분은 state.items() 반복으로 이미 처리되므로 중복될 수 있으나,\n",
    "    # 명시적으로 값을 가져오거나 기본값을 설정하고 싶다면 유지할 수 있습니다.\n",
    "    # combined_data_for_output[\"classification\"] = state.get(\"classification\", {\"Error\": \"Not processed\"})\n",
    "    # combined_data_for_output[\"difficulty\"] = state.get(\"difficulty\", \"Error\")\n",
    "    # combined_data_for_output[\"importance\"] = state.get(\"importance\", \"Error\")\n",
    "\n",
    "    # 이 노드는 상태의 'combined_results' 필드를 업데이트할 딕셔너리를 반환합니다.\n",
    "    return {\"combined_results\": combined_data_for_output}\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "workflow = StateGraph(RequirementAnalysisState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"parallel_processor\", node_parallel_assessments)\n",
    "workflow.add_node(\"final_combiner\", node_combine_results) # 병렬 처리된 결과를 최종 정리\n",
    "\n",
    "# 엣지 연결\n",
    "workflow.set_entry_point(\"parallel_processor\")\n",
    "workflow.add_edge(\"parallel_processor\", \"final_combiner\")\n",
    "workflow.add_edge(\"final_combiner\", END)\n",
    "\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크립트 시작...\n",
      "\n",
      "총 6개의 요구사항 처리를 시작합니다...\n",
      "\n",
      "[1/6] 처리 중: 'UI/UX 디자인 가이드라인 개발...'\n",
      "\n",
      "[2/6] 처리 중: '컴포넌트 라이브러리 구축...'\n",
      "\n",
      "[3/6] 처리 중: '사용자 인터페이스 표준화...'\n",
      "\n",
      "[4/6] 처리 중: '접근성 표준 준수...'\n",
      "\n",
      "[5/6] 처리 중: '반응형 디자인 구현...'\n",
      "\n",
      "[6/6] 처리 중: '사용자 피드백 수집 및 반영...'\n",
      "\n",
      "결과가 성공적으로 processed_requirements_output.json 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 새로운 메인 로직 ---\n",
    "def load_requirements_from_json(filepath: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"지정된 경로에서 JSON 파일을 로드하여 요구사항 목록을 반환합니다.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "            else:\n",
    "                print(f\"Error: JSON 파일 ({filepath})이 리스트 형태가 아닙니다.\")\n",
    "                return []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: JSON 파일을 찾을 수 없습니다 - {filepath}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: JSON 파일 디코딩 중 오류 발생 - {filepath}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file {filepath}: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_results_to_json(results: List[Dict[str, Any]], filepath: str):\n",
    "    \"\"\"결과 목록을 지정된 경로에 JSON 파일로 저장합니다.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\n결과가 성공적으로 {filepath} 파일에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results to JSON file {filepath}: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    JSON 파일에서 요구사항을 로드하고, 각 요구사항을 처리한 후,\n",
    "    모든 결과를 단일 JSON 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    # 실제 API 사용 시 API 키 확인\n",
    "    # 이 코드는 MockClient를 사용하므로 이 부분을 주석 처리하거나 실제 client 초기화 로직에 맞게 수정합니다.\n",
    "    # if not isinstance(client, MockOpenAIClient) and not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    #     print(\"Error: OPENAI_API_KEY 환경 변수가 설정되지 않았습니다.\")\n",
    "    #     print(\"실제 OpenAI API를 사용하려면 API 키를 설정해주세요.\")\n",
    "    #     print(\"스크립트를 종료합니다.\")\n",
    "    #     return\n",
    "\n",
    "    input_json_path = \"docs/test_lv3.json\"\n",
    "    output_json_path = \"processed_requirements_output.json\"\n",
    "\n",
    "    requirements_to_process = load_requirements_from_json(input_json_path)\n",
    "\n",
    "    if not requirements_to_process:\n",
    "        print(\"처리할 요구사항이 없습니다. 스크립트를 종료합니다.\")\n",
    "        return\n",
    "\n",
    "    all_combined_results = []\n",
    "    total_requirements = len(requirements_to_process)\n",
    "\n",
    "    print(f\"\\n총 {total_requirements}개의 요구사항 처리를 시작합니다...\")\n",
    "\n",
    "    for i, req_data in enumerate(requirements_to_process):\n",
    "        print(f\"\\n[{i+1}/{total_requirements}] 처리 중: '{req_data.get('description', 'N/A')[:70]}...'\")\n",
    "\n",
    "        # LangGraph에 전달할 초기 상태 구성\n",
    "        # req_data는 input JSON 파일의 각 객체입니다.\n",
    "        inputs_for_graph: RequirementAnalysisState = {\n",
    "            # Map all fields from req_data to the state\n",
    "            \"id\": req_data.get(\"id\"),\n",
    "            \"type\": req_data.get(\"type\"),\n",
    "            \"description\": req_data.get(\"description\", \"내용 없음\"), # Used by LLMs\n",
    "            \"detailed_description\": req_data.get(\"detailed_description\", \"상세 내용 없음\"), # Used by LLMs\n",
    "            \"acceptance_criteria\": req_data.get(\"acceptance_criteria\"),\n",
    "            \"responsible_module\": req_data.get(\"responsible_module\"), # Original module field\n",
    "            \"parent_id\": req_data.get(\"parent_id\"),\n",
    "            \"source_pages\": req_data.get(\"source_pages\"),\n",
    "            \n",
    "            # classification, difficulty, importance, combined_results는 그래프 내에서 채워집니다.\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # LangGraph 실행\n",
    "            final_state = app.invoke(inputs_for_graph)\n",
    "\n",
    "            if final_state and \"combined_results\" in final_state:\n",
    "                all_combined_results.append(final_state[\"combined_results\"])\n",
    "            else:\n",
    "                print(f\"    ⚠️ [{i+1}/{total_requirements}] 요구사항 처리 후 'combined_results'를 찾을 수 없습니다. Skipping.\")\n",
    "                # 에러 상황에 대한 대체 결과 추가 가능\n",
    "                error_result = {\n",
    "                    \"input_description\": inputs_for_graph[\"description\"],\n",
    "                    \"error\": \"Processing failed or combined_results not found in final state.\",\n",
    "                    \"details\": final_state\n",
    "                }\n",
    "                all_combined_results.append(error_result)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ [{i+1}/{total_requirements}] 요구사항 처리 중 오류 발생: {e}\")\n",
    "            traceback.print_exc()\n",
    "            # 오류 발생 시에도 입력 정보를 포함한 에러 메시지를 결과에 추가\n",
    "            error_result = {\n",
    "                \"input_description\": inputs_for_graph[\"description\"],\n",
    "                \"input_detailed_description\": inputs_for_graph[\"detailed_description\"],\n",
    "                \"input_module\": inputs_for_graph[\"module\"],\n",
    "                \"error\": str(e),\n",
    "                \"classification\": \"Error\",\n",
    "                \"difficulty\": \"Error\",\n",
    "                \"importance\": \"Error\"\n",
    "            }\n",
    "            all_combined_results.append(error_result)\n",
    "\n",
    "    # 모든 결과를 JSON 파일로 저장\n",
    "    save_results_to_json(all_combined_results, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"스크립트 시작...\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
