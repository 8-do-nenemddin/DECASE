{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817d8b95",
   "metadata": {},
   "source": [
    "## 요구사항 정의서 초안"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197aa45",
   "metadata": {},
   "source": [
    "- extracted_additional_requirements.json 파일의 요구사항을 extracted_requirements.json에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1743e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d16f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b93aa92d524a9fabcaab7c8d769b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0114dbb987254ff29a57ca4a19ec8fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6ddf10b8e54241a8c45c358f70b8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3571a94e094c438cb649aee1c7d2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9daa49742d74274b71204e8de8b9bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918a75e484f1420aa16aabb712d39134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 104/104 [00:10<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: requirements_index.faiss, 메타데이터: metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Hugging Face 로컬 모델 로드\n",
    "hf_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts, desc=\"Embedding chunks\"):\n",
    "        try:\n",
    "            embedding = hf_model.encode(text)\n",
    "            embeddings.append(embedding.tolist())  # numpy → list로 변환\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding error: {e}\")\n",
    "            embeddings.append(None)\n",
    "    return embeddings\n",
    "\n",
    "def chunk_requirements(json_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    chunks = []\n",
    "    for item in data:\n",
    "        # 임베딩에 사용되는 text 데이터\n",
    "        chunk_text = f\"\"\"[ID] {item.get('id', '')}\n",
    "[유형] {item.get('type', '')}\n",
    "[설명] {item.get('description', '')}\n",
    "[요구사항 상세] {item.get('detailed_description', '')}\n",
    "[수용 조건] {item.get('acceptance_criteria', '')}\n",
    "[모듈] {item.get('module', '')}\n",
    "[대분류] {item.get('category_large', '')}\n",
    "[중분류] {item.get('category_medium', '')}\n",
    "[소분류] {item.get('category_small', '')}\n",
    "[중요도] {item.get('importance', '')}\n",
    "[난이도] {item.get('difficulty', '')}\n",
    "\"\"\"     \n",
    "        # 요구사항 검색 시 사용되는 key값 추가\n",
    "        chunks.append({\n",
    "            \"id\": item.get(\"id\", \"\"),\n",
    "            \"type\": item.get('type', ''),\n",
    "            \"description\": item.get('description', ''),\n",
    "            \"detailed_description\": item.get('detailed_description', ''),\n",
    "            \"acceptance_criteria\": item.get('acceptance_criteria', ''),\n",
    "            \"module\": item.get('module', ''),\n",
    "            \"source_pages\": item.get('source_pages', ''),\n",
    "            \"raw_text_snippet\": item.get('raw_text_snippet', ''),\n",
    "            \"status\": item.get('status', ''),\n",
    "            \"mod_reason\": item.get('mod_reason', ''),\n",
    "            \"category_large\": item.get('category_large', ''),\n",
    "            \"category_medium\": item.get('category_medium', ''),\n",
    "            \"category_small\": item.get('category_small', ''),\n",
    "            \"difficulty\": item.get('difficulty', ''),\n",
    "            \"importance\": item.get('importance', ''),\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "def embed_and_save_to_faiss(json_file_path, faiss_index_path=\"requirements_index.faiss\", metadata_path=\"metadata.json\"):\n",
    "    # 1. chunk & 텍스트 추출\n",
    "    chunks = chunk_requirements(json_file_path)\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    ids = [chunk[\"id\"] for chunk in chunks]\n",
    "\n",
    "    # 2. 임베딩\n",
    "    embeddings = get_embeddings(texts)\n",
    "    valid_embeddings = []\n",
    "    valid_ids = []\n",
    "\n",
    "    for emb, id_ in zip(embeddings, ids):\n",
    "        if emb is not None:\n",
    "            valid_embeddings.append(emb)\n",
    "            valid_ids.append(id_)\n",
    "\n",
    "    # 3. FAISS 인덱스 생성\n",
    "    dim = len(valid_embeddings[0])\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(valid_embeddings).astype('float32'))\n",
    "\n",
    "    # 4. 저장\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "    with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(valid_ids, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ 저장 완료: {faiss_index_path}, 메타데이터: {metadata_path}\")\n",
    "\n",
    "# 사용\n",
    "embed_and_save_to_faiss(\"./extracted_requirements.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103e6a4",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3289be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 검색 결과:\n",
      "\n",
      "🔹 Top 1\n",
      "ID: TCON-003\n",
      "거리: 1.092711329460144\n",
      "요구사항 내용:\n",
      "[ID] TCON-003\n",
      "[유형] 기술적 제약\n",
      "[설명] 도입되는 솔루션은 JRE 1.7.0을 사용해야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "도입되는 솔루션은 JRE 1.7.0을 사용해야 한다.\n",
      "\n",
      "[대상업무]  \n",
      "전체 시스템 - 환경 설정 및 배포 관리\n",
      "\n",
      "[요건처리 상세]  \n",
      "전체 시스템의 개발 및 운영 환경에서 Java Runtime Environment(JRE) 1.7.0을 사용하도록 설정한다. 이를 위해 다음과 같은 작업을 수행한다:\n",
      "1. 개발 환경 설정: 모든 개발자의 로컬 개발 환경에 JRE 1.7.0이 설치되어 있는지 확인하고, 필요한 경우 설치를 지원한다. 개발 도구(예: IDE)에서 JRE 1.7.0을 기본 런타임으로 설정한다.\n",
      "2. 빌드 및 배포 환경 설정: 빌드 서버 및 배포 서버에 JRE 1.7.0이 설치되어 있는지 확인하고, 설치되지 않은 경우 설치를 진행한다. 빌드 스크립트 및 배포 자동화 도구에서 JRE 1.7.0을 사용하도록 설정을 수정한다.\n",
      "3. 테스트 환경 설정: 테스트 환경에서 JRE 1.7.0을 사용하여 모든 테스트가 수행되도록 설정한다. 테스트 자동화 도구가 JRE 1.7.0을 사용하도록 설정을 조정한다.\n",
      "4. 문서화: JRE 1.7.0 사용에 대한 설정 및 설치 절차를 문서화하여 모든 팀원이 참조할 수 있도록 한다. 또한, JRE 버전 변경 시의 영향 분석 및 대응 방안을 포함한다.\n",
      "[수용 조건] 솔루션이 JRE 1.7.0 환경에서 정상적으로 작동해야 한다.\n",
      "[모듈] 전체 시스템\n",
      "[대분류] 시스템 관리\n",
      "[중분류] 환경 설정 및 배포 관리\n",
      "[소분류] JRE 설정 및 관리\n",
      "[중요도] 하\n",
      "[난이도] 하\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Top 2\n",
      "ID: NFR-020\n",
      "거리: 1.147341251373291\n",
      "요구사항 내용:\n",
      "[ID] NFR-020\n",
      "[유형] 비기능적\n",
      "[설명] 도입되는 솔루션은 당행 인프라 환경과 호환 및 연계 가능한 제품이어야 하며, OS는 AIX 7.2, DBMS는 Oracle 12.2.0 SE, JAVA는 JRE 1.7.0을 사용해야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "도입되는 솔루션은 당행 인프라 환경과 호환 및 연계 가능한 제품이어야 하며, OS는 AIX 7.2, DBMS는 Oracle 12.2.0 SE, JAVA는 JRE 1.7.0을 사용해야 한다.\n",
      "\n",
      "[대상업무]  \n",
      "인프라 관리 - 배치 및 시스템 연계 기능\n",
      "\n",
      "[요건처리 상세]  \n",
      "1. 솔루션은 AIX 7.2 운영체제에서 원활히 작동해야 하며, 해당 OS에 대한 설치 및 운영 가이드를 제공해야 한다.  \n",
      "2. 데이터베이스는 Oracle 12.2.0 SE와 호환되어야 하며, 데이터베이스 연결 및 쿼리 실행에 문제가 없도록 JDBC 드라이버를 포함한 설정을 제공해야 한다.  \n",
      "3. JAVA 환경은 JRE 1.7.0을 사용하여야 하며, 솔루션의 모든 JAVA 기반 모듈이 해당 버전에서 정상적으로 실행되는지 검증해야 한다.  \n",
      "4. 시스템 연계 시, 기존 인프라와의 통신 프로토콜 및 데이터 포맷이 호환되어야 하며, 필요 시 변환 로직을 포함하여 연계 모듈을 설계한다.  \n",
      "5. 각 환경에 대한 테스트 계획을 수립하고, 테스트 결과를 문서화하여 솔루션의 호환성을 검증한다.  \n",
      "6. 인프라 변경 시 발생할 수 있는 리스크를 식별하고, 이를 최소화하기 위한 대응 방안을 마련한다.\n",
      "[수용 조건] 솔루션은 AIX 7.2, Oracle 12.2.0 SE, JRE 1.7.0 환경에서 정상적으로 작동해야 한다.\n",
      "[모듈] 전체 시스템\n",
      "[대분류] 인프라 관리\n",
      "[중분류] 시스템 호환성\n",
      "[소분류] 운영체제 및 소프트웨어 호환성\n",
      "[중요도] 중\n",
      "[난이도] 중\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Top 3\n",
      "ID: TCON-004\n",
      "거리: 1.2697120904922485\n",
      "요구사항 내용:\n",
      "[ID] TCON-004\n",
      "[유형] 기술적 제약\n",
      "[설명] 구독형 Java 사용을 배제해야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "구독형 Java 사용을 배제한다.\n",
      "\n",
      "[대상업무]  \n",
      "전체 시스템 - 시스템 아키텍처 및 개발 환경 설정\n",
      "\n",
      "[요건처리 상세]  \n",
      "1. **기존 시스템 분석**: 현재 시스템에서 사용 중인 Java 버전 및 라이선스 유형을 분석한다. 구독형 Java 라이선스를 사용하는 모든 모듈과 의존성을 식별한다.\n",
      "   \n",
      "2. **대체 Java 버전 선정**: 구독형 Java를 대체할 수 있는 오픈소스 또는 무료 라이선스의 Java 버전을 선정한다. 예를 들어, OpenJDK를 고려할 수 있다.\n",
      "\n",
      "3. **호환성 테스트**: 대체 Java 버전으로 전환 시 발생할 수 있는 호환성 문제를 사전에 식별하기 위해 테스트 환경을 구축하고, 주요 기능 및 모듈에 대한 테스트를 수행한다.\n",
      "\n",
      "4. **개발 환경 설정**: 개발팀의 모든 개발 환경에서 구독형 Java를 제거하고, 선정된 대체 Java 버전을 설치 및 설정한다. 빌드 및 배포 파이프라인도 이에 맞게 수정한다.\n",
      "\n",
      "5. **문서화 및 교육**: 변경된 Java 환경에 대한 문서를 작성하고, 개발팀 및 관련 부서에 교육을 실시하여 새로운 환경에 대한 이해도를 높인다.\n",
      "\n",
      "6. **모니터링 및 지원**: 전환 후 초기 운영 기간 동안 시스템 모니터링을 강화하여 문제 발생 시 신속히 대응할 수 있도록 지원 체계를 마련한다.\n",
      "[수용 조건] 구독형 Java가 사용되지 않았음을 확인해야 한다.\n",
      "[모듈] 전체 시스템\n",
      "[대분류] 시스템 아키텍처 관리\n",
      "[중분류] 개발 환경 설정\n",
      "[소분류] Java 라이선스 관리\n",
      "[중요도] 중\n",
      "[난이도] 중\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Top 4\n",
      "ID: FUNC-025\n",
      "거리: 1.3147470951080322\n",
      "요구사항 내용:\n",
      "[ID] FUNC-025\n",
      "[유형] 기능적\n",
      "[설명] AI 인사 솔루션은 인사발령 초안을 생성하고, 인사상담 데이터를 연동하여 직원 개인 만족도를 향상시켜야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "AI 인사 솔루션은 주소, 성별, 직무, 인원수에 따라 인사발령 초안을 생성하고, 인사상담 데이터를 연동하여 직원 개인 만족도를 향상시킨다.\n",
      "\n",
      "[대상업무]  \n",
      "인사발령 관리 - 배치 및 온라인 기능\n",
      "\n",
      "[요건처리 상세]  \n",
      "1. 인사발령 초안 생성:\n",
      "   - 인사 데이터베이스에서 직원의 주소, 성별, 직무, 인원수 정보를 수집합니다.\n",
      "   - 수집된 데이터를 기반으로 AI 알고리즘을 활용하여 인사발령 초안을 자동 생성합니다.\n",
      "   - 생성된 초안은 관리자 검토를 위해 인사발령 관리 화면에 표시됩니다.\n",
      "\n",
      "2. 인사상담 데이터 연동:\n",
      "   - 직원의 인사상담 데이터를 분석하여 개인의 만족도 지표를 산출합니다.\n",
      "   - 만족도 지표는 인사발령 초안 생성 시 고려 요소로 반영됩니다.\n",
      "   - 인사상담 데이터는 주기적으로 업데이트되며, 최신 데이터를 기반으로 만족도 지표를 실시간으로 갱신합니다.\n",
      "\n",
      "3. 직원 개인 만족도 향상:\n",
      "   - 인사발령 초안에 반영된 만족도 지표를 통해 직원의 개인적 요구와 선호를 최대한 반영합니다.\n",
      "   - 만족도 향상 결과는 인사발령 후 피드백 시스템을 통해 모니터링하며, 지속적인 개선을 위한 데이터로 활용됩니다.\n",
      "[수용 조건] 시스템은 인사발령 초안을 생성하고, 인사상담 데이터를 연동하여 인사 체계를 마련해야 한다.\n",
      "[모듈] 인사발령 모듈\n",
      "[대분류] 인사관리\n",
      "[중분류] 인사발령\n",
      "[소분류] 인사발령 초안 생성 및 만족도 연동\n",
      "[중요도] 중\n",
      "[난이도] 중\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Top 5\n",
      "ID: FUNC-005\n",
      "거리: 1.3497471809387207\n",
      "요구사항 내용:\n",
      "[ID] FUNC-005\n",
      "[유형] 기능적\n",
      "[설명] 출퇴근 소요시간을 고려하여 근거리 인력을 추천해야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "출퇴근 소요시간을 고려하여 근거리 인력을 추천한다.\n",
      "\n",
      "[대상업무]  \n",
      "AI 인사 솔루션 - 온라인 기능\n",
      "\n",
      "[요건처리 상세]  \n",
      "1. 출퇴근 소요시간 데이터를 수집하기 위해, 직원들의 주소 정보를 기반으로 교통 정보 API(예: 구글 맵스, 네이버 지도 등)를 활용하여 각 직원의 출퇴근 예상 시간을 계산한다.  \n",
      "2. 계산된 출퇴근 시간을 기준으로, 특정 위치(예: 회사 주소)로부터 일정 시간 이내에 위치한 직원들을 필터링한다.  \n",
      "3. 필터링된 직원 목록을 근거리 인력 추천 리스트로 생성하며, 이 리스트는 사용자가 조회할 수 있는 온라인 화면에 제공된다.  \n",
      "4. 사용자가 특정 조건(예: 최대 출퇴근 시간, 교통수단 등)을 입력할 수 있는 필터 기능을 제공하여, 추천 리스트를 동적으로 조정할 수 있도록 한다.  \n",
      "5. 추천 리스트는 실시간으로 업데이트되며, 사용자가 요청할 때마다 최신 데이터를 기반으로 결과를 제공한다.  \n",
      "6. 모든 추천 과정은 개인정보 보호 규정을 준수하여 처리되며, 민감한 정보는 암호화하여 저장 및 전송한다.\n",
      "[수용 조건] AI가 출퇴근 소요시간을 고려하여 근거리 인력을 추천해야 한다.\n",
      "[모듈] AI 인사 솔루션\n",
      "[대분류] 인사관리\n",
      "[중분류] 인력추천\n",
      "[소분류] 근거리 인력 추천\n",
      "[중요도] 중\n",
      "[난이도] 중\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 정의 및 임베딩 생성\n",
    "query = \"JRE 관련 기능\"\n",
    "query_emb = hf_model.encode(query).astype('float32')\n",
    "\n",
    "# FAISS 인덱스 및 메타데이터(ID 리스트) 로드\n",
    "index = faiss.read_index(\"requirements_index.faiss\")\n",
    "metadata = json.load(open(\"metadata.json\", encoding=\"utf-8\"))\n",
    "\n",
    "# ID → 텍스트 매핑 로드 (chunk_requirements로부터 생성 가능)\n",
    "# 원본 JSON에서 id와 함께 텍스트를 다시 생성\n",
    "chunks = chunk_requirements(\"extracted_requirements.json\")\n",
    "id_to_text = {chunk[\"id\"]: chunk[\"text\"] for chunk in chunks}\n",
    "\n",
    "# 검색\n",
    "D, I = index.search(np.array([query_emb]).astype(\"float32\"), k=5)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"🔍 검색 결과:\")\n",
    "for i, idx in enumerate(I[0]):\n",
    "    req_id = metadata[idx]\n",
    "    req_text = id_to_text.get(req_id, \"(텍스트 없음)\")\n",
    "\n",
    "    print(f\"\\n🔹 Top {i+1}\")\n",
    "    print(f\"ID: {req_id}\")\n",
    "    print(f\"거리: {D[0][i]}\")\n",
    "    print(\"요구사항 내용:\")\n",
    "    print(req_text)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e89b8",
   "metadata": {},
   "source": [
    "## 추가 요구사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043a51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_requirements(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def save_requirements(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def extract_similar_id(base_file, query):\n",
    "    query_emb = hf_model.encode(query).astype(\"float32\")\n",
    "    index = faiss.read_index(\"requirements_index.faiss\")\n",
    "    metadata = json.load(open(\"metadata.json\", encoding=\"utf-8\"))\n",
    "    extracted_chunks = chunk_requirements(base_file)\n",
    "    id_to_text = {ext_chunk[\"id\"]: ext_chunk[\"text\"] for ext_chunk in extracted_chunks}\n",
    "\n",
    "    D, I = index.search(np.array([query_emb]).astype(\"float32\"), k=1)\n",
    "    top_idx = I[0][0]\n",
    "    top_dist = D[0][0]\n",
    "\n",
    "    existing_id = metadata[top_idx]\n",
    "    existing_text = id_to_text.get(existing_id, \"\")\n",
    "    print(f\"\\n📄 유사한 기존 요구사항 ID: {existing_id}\")\n",
    "    print(f\"📂 유사한 기존 요구사항:\\n{existing_text}\")\n",
    "\n",
    "    return existing_id, existing_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb759906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_existing_requirement(current_text, updated):\n",
    "    prompt = f\"\"\"\n",
    "당신은 시스템 분석 전문가이며, 회의록을 바탕으로 **요구사항을 변경 또는 업데이트**하는 전문가입니다.\n",
    "\n",
    "아래 \"기존 요구사항\"을 기준으로 \"변경된 요구사항\"의 내용을 반영해 **최종 업데이트된 요구사항 카드**를 작성하십시오.  \n",
    "각 항목은 시스템의 설계, 개발, 테스트, 배포, 운영에 실질적으로 사용될 수 있어야 하며, **사람이 읽기 좋은 카드 형식**으로 구성되어야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 출력 형식 예시\n",
    "\n",
    "[유형] 요구사항 유형: \"기능적\", \"비기능적\" \n",
    "[설명] 요구사항 요약 (시스템이 수행해야 하는 기능, 조건 등)\n",
    "[요구사항 상세] 상세 설명\n",
    "[수용 조건] 요구사항 충족 여부를 판단할 수 있는 구체적 기준 (없으면 \"세부 설계 시 정의\"로 표기)\n",
    "[모듈] 관련 시스템 모듈 (예: \"인증 모듈\", \"전체 시스템\"). 불분명하면 \"미정\"\n",
    "[대분류] / [중분류] /[소분류] 기능 분류 (예: \"보안\" / \"접근 제어\" / \"권한 등급 설정\")\n",
    "[중요도] 시스템 성공에 대한 영향도 (\"상\", \"중\", \"하\")  \n",
    "[난이도] 구현 난이도 (\"상\", \"중\", \"하\")\n",
    "\n",
    "---\n",
    "\n",
    "## 🔻 입력\n",
    "\n",
    "### 1. 기존 요구사항\n",
    "{current_text}\n",
    "\n",
    "### 2. 변경된 요구사항\n",
    "{updated}\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠 출력 지침\n",
    "\n",
    "- 출력은 반드시 위와 같은 구조의 **요구사항 카드 형식**으로 작성하십시오.\n",
    "- 출력은 하나의 요구사항 카드만 작성하십시오.\n",
    "- 출력 앞뒤에 다른 문장, 마크다운, JSON, 해설을 절대 붙이지 마십시오.\n",
    "- 누락된 항목이 있다면 빈칸 없이 **\"미정\"** 으로 채우십시오.\n",
    "- \"요구사항 상세\"와 \"요건처리 상세\" 항목은 중복되지 않도록 구성하십시오.\n",
    "- 회의록에서 다음 항목은 요구사항으로 간주하지 말고 무시하십시오:\n",
    "  - 목차, 업체선정 기준, 제안서 작성 요령, 일반 행정적 절차\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69252454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 시스템 분석 전문가이며, 요구사항을 업데이트하는 역할입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d057da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 각 필드를 파싱하는 정규식 패턴\n",
    "patterns = {\n",
    "    \"id\": r\"\\[ID\\] (.+)\",\n",
    "    \"type\": r\"\\[유형\\] (.+)\",\n",
    "    \"description\": r\"\\[설명\\] (.+)\",\n",
    "    \"detailed_description\": r\"\\[요구사항 상세\\]([\\s\\S]+?)\\[수용 조건\\]\",\n",
    "    \"acceptance_criteria\": r\"\\[수용 조건\\] (.+)\",\n",
    "    \"module\": r\"\\[모듈\\] (.+)\",\n",
    "    \"category_large\": r\"\\[대분류\\] (.+)\",\n",
    "    \"category_medium\": r\"\\[중분류\\] (.+)\",\n",
    "    \"category_small\": r\"\\[소분류\\] (.+)\",\n",
    "    \"importance\": r\"\\[중요도\\] (.+)\",\n",
    "    \"difficulty\": r\"\\[난이도\\] (.+)\"\n",
    "}\n",
    "\n",
    "# 항목 추출 함수\n",
    "def extract_field(text, pattern):\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1).strip() if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c8593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "🔍 추가 요구사항 ID: FUNC-001\n",
      "📥 신규 입력 요구사항:\n",
      "[ID] FUNC-001\n",
      "[유형] 기능적\n",
      "[설명] 상담 이력을 기반으로 한 만족도 점수 반영\n",
      "[요구사항 상세] 상담 이력에서 문항별 점수, 상담 횟수, 상담 후 개선요청 이행 여부 등을 통해 가중치를 적용하여 만족도 점수를 반영\n",
      "[수용 조건] 추천 인력 선정 시 만족도 점수가 정상적으로 반영되어야 함\n",
      "[모듈] 인사상담 모듈\n",
      "[대분류] 인사상담\n",
      "[중분류] 상담 이력\n",
      "[소분류] 만족도 점수 반영\n",
      "[중요도] 상\n",
      "[난이도] 중\n",
      "\n",
      "✅ 신규 요구사항으로 등록됨\n",
      "\n",
      "==============================\n",
      "🔍 추가 요구사항 ID: FUNC-002\n",
      "📥 신규 입력 요구사항:\n",
      "[ID] FUNC-002\n",
      "[유형] 기능적\n",
      "[설명] 직무 적합성 지수 산출\n",
      "[요구사항 상세] 내부 평가결과와 이직률 데이터를 조합하여 직무 적합성 지수를 산출\n",
      "[수용 조건] 추천 인력에 직무 적합성 지수가 정상적으로 보여져야 함\n",
      "[모듈] 직무 적합도 모듈\n",
      "[대분류] 직무 적합도\n",
      "[중분류] 직무 적합성 지수\n",
      "[소분류] 직무 적합성 지수 산출\n",
      "[중요도] 상\n",
      "[난이도] 상\n",
      "\n",
      "✅ 신규 요구사항으로 등록됨\n",
      "\n",
      "==============================\n",
      "🔍 추가 요구사항 ID: FUNC-003\n",
      "📥 신규 입력 요구사항:\n",
      "[ID] FUNC-003\n",
      "[유형] 기능적\n",
      "[설명] 인사 발령안 자동 생성 로직 변경\n",
      "[요구사항 상세] 인사 발령안을 주소, 성별, 인원수 기준에서 우선순위 필터 기준으로 변경\n",
      "[수용 조건] 우선순위 필터에 따라 인사 발령안이 자동으로 생성되어야 함\n",
      "[모듈] 인사 발령안 모듈\n",
      "[대분류] 인사 발령안\n",
      "[중분류] 자동 생성 로직\n",
      "[소분류] 우선순위 필터 적용\n",
      "[중요도] 상\n",
      "[난이도] 중\n",
      "\n",
      "\n",
      "📄 유사한 기존 요구사항 ID: FUNC-007\n",
      "📂 유사한 기존 요구사항:\n",
      "[ID] FUNC-007\n",
      "[유형] 기능적\n",
      "[설명] 인사발령을 위한 데이터 취합, 기초데이터 생성, 불일치 검증, 발령 반영 기능을 구현해야 한다.\n",
      "[요구사항 상세] [요구사항]  \n",
      "인사발령을 위한 데이터 취합, 기초데이터 생성, 불일치 검증, 발령 반영 기능을 구현한다.\n",
      "\n",
      "[대상업무]  \n",
      "AI 인사 솔루션 - 배치 및 화면 기능\n",
      "\n",
      "[요건처리 상세]  \n",
      "1. **데이터 취합**:  \n",
      "   - 인사발령에 필요한 데이터를 사내 인사 시스템 및 외부 데이터 소스(예: 정부 인사 데이터베이스)에서 주기적으로 수집한다.\n",
      "   - 데이터 취합은 배치 프로세스를 통해 매일 정해진 시간에 자동으로 수행되며, 수집된 데이터는 중앙 데이터베이스에 저장된다.\n",
      "\n",
      "2. **기초데이터 생성**:  \n",
      "   - 수집된 데이터를 기반으로 인사발령에 필요한 기초데이터를 생성한다.  \n",
      "   - 기초데이터에는 직원의 기본 정보, 현재 직급, 부서 정보, 발령 이력 등이 포함된다.\n",
      "   - 생성된 기초데이터는 인사발령 관리 화면에서 조회 및 수정 가능하도록 한다.\n",
      "\n",
      "3. **불일치 검증**:  \n",
      "   - 기초데이터와 기존 인사 데이터 간의 불일치를 검증하는 기능을 구현한다.\n",
      "   - 불일치 항목은 자동으로 검출되며, 검출된 불일치 항목은 관리자에게 알림을 통해 통보된다.\n",
      "   - 불일치 검증 결과는 인사발령 관리 화면에 표시되며, 관리자가 수동으로 검토 및 수정할 수 있도록 한다.\n",
      "\n",
      "4. **발령 반영**:  \n",
      "   - 검증된 기초데이터를 기반으로 인사발령을 시스템에 반영한다.\n",
      "   - 발령 반영은 승인된 발령 요청에 한해 수행되며, 발령 내역은 인사 시스템에 기록된다.\n",
      "   - 발령 반영 후, 관련 부서 및 직원에게 발령 결과를 이메일 및 시스템 알림으로 통보한다.\n",
      "\n",
      "이 모든 과정은 인사발령 관리 화면에서 사용자가 직관적으로 조작할 수 있도록 UI/UX를 설계하며, 데이터의 무결성과 보안을 보장하기 위해 권한 관리 및 로그 기록 기능을 포함한다.\n",
      "[수용 조건] 인사발령 프로세스가 데이터 취합, 생성, 검증, 반영을 정확하게 수행해야 한다.\n",
      "[모듈] AI 인사 솔루션\n",
      "[대분류] 인사관리\n",
      "[중분류] 인사발령\n",
      "[소분류] 데이터 취합 및 검증\n",
      "[중요도] 중\n",
      "[난이도] 중\n",
      "\n",
      "♻ 기존 요구사항 'FUNC-007'을(를) 갱신합니다.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "additional_path = \"./extracted_additional_requirements.json\"\n",
    "update_results = []\n",
    "classified_list = []\n",
    "base_file = \"./extracted_requirements.json\"\n",
    "base_requirements = load_requirements(base_file)\n",
    "\n",
    "for add_chunk in chunk_requirements(additional_path):\n",
    "    query = add_chunk[\"text\"]\n",
    "    query_id = add_chunk[\"id\"]\n",
    "    status = add_chunk[\"status\"]\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"🔍 추가 요구사항 ID: {query_id}\")\n",
    "    print(f\"📥 신규 입력 요구사항:\\n{query}\")\n",
    "    \n",
    "    if status == \"신규\":\n",
    "        tmp = {\n",
    "            \"acceptance_criteria\": add_chunk[\"acceptance_criteria\"],\n",
    "            \"category_large\": add_chunk[\"category_large\"],\n",
    "            \"category_medium\": add_chunk[\"category_medium\"],\n",
    "            \"category_small\": add_chunk[\"category_small\"],\n",
    "            \"description\": add_chunk[\"description\"],\n",
    "            \"detailed_description\": add_chunk[\"detailed_description\"],\n",
    "            \"difficulty\": add_chunk[\"difficulty\"],\n",
    "            \"id\": add_chunk[\"id\"],\n",
    "            \"importance\": add_chunk[\"importance\"],\n",
    "            \"module\": add_chunk[\"module\"],\n",
    "            \"source_page\": add_chunk[\"source_pages\"],\n",
    "            \"type\": add_chunk[\"type\"],\n",
    "            \"raw_text_snippet\": add_chunk[\"raw_text_snippet\"],\n",
    "            \"status\": add_chunk[\"status\"],\n",
    "            \"mod_reason\": add_chunk[\"mod_reason\"]\n",
    "        }\n",
    "        base_requirements.append(tmp)\n",
    "        print(f\"✅ 신규 요구사항으로 등록됨\")\n",
    "\n",
    "    elif status == \"변경\":\n",
    "        similar_id, similar_text = extract_similar_id(base_file, query)\n",
    "        print(f\"♻ 기존 요구사항 '{similar_id}'을(를) 갱신합니다.\")\n",
    "\n",
    "        prompt = update_existing_requirement(similar_text, query)\n",
    "        text_result = call_llm(prompt)\n",
    "\n",
    "        # JSON 객체 생성\n",
    "        item = {key: extract_field(text_result, pat) for key, pat in patterns.items()}\n",
    "\n",
    "        # 기본값 설정\n",
    "        item[\"source_pages\"] = add_chunk[\"source_pages\"]\n",
    "        item[\"raw_text_snippet\"] = add_chunk[\"raw_text_snippet\"]\n",
    "        item[\"status\"] = add_chunk[\"status\"]\n",
    "        item[\"mod_reason\"] = add_chunk[\"mod_reason\"]\n",
    "        chunk_text = text_result\n",
    "\n",
    "        # 최종 리스트에 추가\n",
    "        chunks = []\n",
    "        chunks.append({\n",
    "            \"id\": similar_id,\n",
    "            \"type\": item.get(\"type\", \"\"),\n",
    "            \"description\": item.get(\"description\", \"\"),\n",
    "            \"detailed_description\": item.get(\"detailed_description\", \"\"),\n",
    "            \"acceptance_criteria\": item.get(\"acceptance_criteria\", \"\"),\n",
    "            \"module\": item.get(\"module\", \"\"),\n",
    "            \"source_pages\": item.get(\"source_pages\", \"\"),\n",
    "            \"raw_text_snippet\": item.get(\"raw_text_snippet\", \"\"),\n",
    "            \"status\": item.get(\"status\", \"\"),\n",
    "            \"mod_reason\": item.get(\"mod_reason\", \"\"),\n",
    "            \"category_large\": item.get(\"category_large\", \"\"),\n",
    "            \"category_medium\": item.get(\"category_medium\", \"\"),\n",
    "            \"category_small\": item.get(\"category_small\", \"\"),\n",
    "            \"difficulty\": item.get(\"difficulty\", \"\"),\n",
    "            \"importance\": item.get(\"importance\", \"\"),\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "\n",
    "        for i, req in enumerate(base_requirements):\n",
    "            print(\"i: \", i, \" req: \", req)\n",
    "            if req.get(\"id\", \"\") == similar_id:\n",
    "                base_requirements[i] = chunks[0]\n",
    "                pprint(base_requirements[i])\n",
    "\n",
    "        print(f\"✅ 요구사항 '{similar_id}' 갱신 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ece9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_requirements('./updated_requirements.json', base_requirements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-YNZJsH64-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
