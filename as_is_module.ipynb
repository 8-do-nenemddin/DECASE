{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # For chunking\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 ---\n",
    "# 환경 변수에서 API 키를 불러옵니다.\n",
    "# 실제 사용 시에는 사용자 본인의 OPENAI_API_KEY를 환경 변수로 설정해야 합니다.\n",
    "# 예시: os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL_FOR_REPORTING = \"gpt-4o\"  # 보고서 생성에 사용할 모델\n",
    "\n",
    "\n",
    "# --- Helper Functions (개선된 부분) ---\n",
    "\n",
    "def extract_text_with_page_info(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 페이지별로 추출하여 리스트로 반환합니다.\n",
    "    각 리스트 항목은 한 페이지의 텍스트이며, 내부적으로 페이지 번호 정보가 유지됩니다.\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    page_texts = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        page_texts.append(text.strip())  # 각 페이지 텍스트를 리스트에 저장\n",
    "    return page_texts, document.page_count  # 전체 텍스트를 하나의 문자열이 아닌 리스트로 반환\n",
    "\n",
    "\n",
    "def extract_text_for_pages(page_texts_list, start_page_num, end_page_num):\n",
    "    \"\"\"\n",
    "    페이지 텍스트 리스트에서 특정 페이지 범위의 텍스트를 추출합니다.\n",
    "    \"\"\"\n",
    "    # PDF 페이지는 1부터 시작하므로 리스트 인덱스를 맞춥니다.\n",
    "    start_idx = max(0, start_page_num - 1)\n",
    "    end_idx = min(len(page_texts_list), end_page_num)  # end_page_num 포함\n",
    "\n",
    "    if start_idx >= end_idx:\n",
    "        return \"\"\n",
    "\n",
    "    # 원하는 페이지 범위의 텍스트만 결합\n",
    "    combined_text = \"\\n\".join(page_texts_list[start_idx:end_idx])\n",
    "    return combined_text\n",
    "\n",
    "\n",
    "def get_toc_raw_text_from_full_text(page_texts_list, toc_page_numbers=[2, 3]):\n",
    "    \"\"\"\n",
    "    전체 텍스트 리스트에서 지정된 목차 페이지들의 텍스트만 추출합니다.\n",
    "    \"\"\"\n",
    "    toc_texts = []\n",
    "    for page_num in toc_page_numbers:\n",
    "        # extract_text_for_pages 함수는 1-based page numbers를 처리\n",
    "        page_content = extract_text_for_pages(page_texts_list, page_num, page_num)\n",
    "        if page_content:\n",
    "            toc_texts.append(page_content)\n",
    "        else:\n",
    "            print(f\"경고: 목차 페이지로 지정된 {page_num} 페이지에서 텍스트를 찾을 수 없습니다.\")\n",
    "    if not toc_texts:\n",
    "        return None\n",
    "    # 추출된 목차 텍스트를 LLM에 전달하기 전 간단히 정제\n",
    "    raw_toc = \"\\n\".join(toc_texts)\n",
    "    # 불필요한 공백, 탭, 연속 줄바꿈 제거 (이후 LLM이 파싱하기 좋게)\n",
    "    raw_toc = re.sub(r'\\s+', ' ', raw_toc).strip()  # 여러 공백을 하나로, 줄바꿈을 공백으로\n",
    "    raw_toc = re.sub(r'\\.{2,}', '', raw_toc)  # 페이지 번호 앞의 점선 제거 (예: ...5 -> 5)\n",
    "    raw_toc = re.sub(r'\\n{2,}', '\\n', raw_toc)  # 2개 이상의 줄바꿈을 1개로\n",
    "    return raw_toc\n",
    "\n",
    "\n",
    "def parse_toc_with_llm(toc_raw_text, client_instance, llm_model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 목차 원문 텍스트를 파싱하여 구조화된 목차 항목을 추출합니다.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 PDF 문서에서 추출된 목차(Table of Contents)의 원시 텍스트를 분석하는 전문가입니다.\n",
    "    주어진 텍스트를 파싱하여 각 목차 항목의 제목, 페이지 번호, 그리고 해당 항목이 '요구사항' 관련 내용을 담고 있을 가능성을 분석하여 JSON 형태로 반환해야 합니다.\n",
    "    JSON의 최상위 레벨은 \"toc_entries\"라는 키를 가진 객체여야 하고, 그 키의 값은 목차 항목 객체들의 리스트여야 합니다.\n",
    "    **매우 중요: JSON 형식 외에 다른 어떠한 추가적인 설명이나 문장도 포함하지 마십시오.** 당신의 응답은 오직 JSON 객체여야 합니다.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    다음은 PDF에서 추출한 목차로 추정되는 텍스트입니다:\n",
    "\n",
    "    --- 목차 원문 텍스트 시작 ---\n",
    "    {toc_raw_text}\n",
    "    --- 목차 원문 텍스트 끝 ---\n",
    "\n",
    "    이 텍스트를 분석하여 JSON 객체를 반환해주세요. 이 객체는 \"toc_entries\"라는 키를 가져야 하며,\n",
    "    이 키의 값은 각 목차 항목을 나타내는 객체들의 리스트여야 합니다.\n",
    "    각 목차 항목 객체는 다음 키를 가져야 합니다:\n",
    "    - \"title\": (문자열) 목차 항목의 전체 제목. 제목 앞의 번호(예: \"1.\", \"II.\", \"가.\", \"1.1.\", \"제1장.\")도 포함해주세요.\n",
    "    - \"page\": (정수) 해당 항목의 시작 페이지 번호.\n",
    "    - \"is_requirement_related\": (불리언) 제목이나 내용을 볼 때, 해당 항목이 '요구사항', '과업 범위', '제안 요청 상세', '기능 명세', '기술 요건', '현황', 'AS-IS', '재구축', '현재 시스템', '개선 방안' 등과 관련된 내용을 다룰 가능성이 높으면 true, 그렇지 않으면 false로 설정해주세요.\n",
    "\n",
    "    예시 JSON 출력 형식:\n",
    "    {{\n",
    "      \"toc_entries\": [\n",
    "        {{\n",
    "          \"title\": \"1. 사업 개요\",\n",
    "          \"page\": 5,\n",
    "          \"is_requirement_related\": false\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"III. 제안요청 내용\",\n",
    "          \"page\": 6,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"3. 상세 요구사항\",\n",
    "          \"page\": 11,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"* 보안 요구사항 별표\",\n",
    "          \"page\": 63,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"IV. 현행 시스템 분석\",\n",
    "          \"page\": 20,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"5. As-Is 시스템 현황\",\n",
    "          \"page\": 25,\n",
    "          \"is_requirement_related\": true\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    만약 주어진 텍스트가 유효한 목차로 보이지 않거나 항목을 전혀 파싱할 수 없다면,\n",
    "    \"toc_entries\" 키의 값으로 빈 리스트 `[]`를 포함하는 JSON 객체를 반환해주세요. (예: {{\"toc_entries\": []}})\n",
    "    \"\"\"\n",
    "    llm_response_content = \"\"\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0  # 일관된 결과를 위해 0.0 유지\n",
    "        )\n",
    "\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        parsed_data = json.loads(llm_response_content)\n",
    "\n",
    "        extracted_list = []\n",
    "        if isinstance(parsed_data, dict) and \"toc_entries\" in parsed_data and isinstance(parsed_data[\"toc_entries\"], list):\n",
    "            extracted_list = parsed_data[\"toc_entries\"]\n",
    "        else:\n",
    "            print(f\"LLM 응답이 예상된 'toc_entries' 리스트를 포함하는 객체 형식이 아닙니다. 응답: {llm_response_content[:200]}\")\n",
    "            return []\n",
    "\n",
    "        valid_entries = []\n",
    "        for entry in extracted_list:\n",
    "            if isinstance(entry, dict) and 'title' in entry and 'page' in entry:\n",
    "                try:\n",
    "                    entry['page'] = int(entry['page'])\n",
    "                    entry['is_requirement_related'] = bool(entry.get('is_requirement_related', False))\n",
    "                    valid_entries.append(entry)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: 페이지 번호 '{entry.get('page')}'를 정수로 변환할 수 없습니다. 항목 건너뜀: {entry.get('title')}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"경고: 필수 키(title, page)가 누락된 항목입니다. 건너뜀: {entry}\")\n",
    "\n",
    "        return valid_entries\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 목차 파싱 응답 JSON 파싱 오류: {e}. 응답 미리보기: {llm_response_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 목차 파싱 중 예상치 못한 오류 발생: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages):\n",
    "    \"\"\"\n",
    "    LLM으로 파싱된 목차에서 As-Is 정보가 포함될 가능성이 있는 섹션 정보를 추출합니다.\n",
    "    \"\"\"\n",
    "    target_sections = []\n",
    "    # 페이지 번호 기준으로 정렬 (필수)\n",
    "    sorted_toc = sorted(parsed_toc_entries, key=lambda x: x.get('page', 0))\n",
    "\n",
    "    # 명시적으로 As-Is 정보를 포함할 가능성이 높은 키워드들 (소문자 비교를 위해 미리 소문자로 변환)\n",
    "    keywords_to_find = [\n",
    "        \"현황 분석\", \"시스템 현황\", \"현행 시스템\", \"시스템 개요\",\n",
    "        \"제안요청 내용\", \"상세 요구사항\", \"기능 요구사항\", \"비기능 요구사항\",\n",
    "        \"보안 요구사항\", \"기술 현황\", \"아키텍처 현황\",\n",
    "        \"현재 시스템\", \"as-is\", \"재구축\", \"목표시스템\", \"개선 방안\",  # '개선 방안'에 현재 시스템의 문제점이 암시될 수 있음\n",
    "        \"사업 목표\", \"사업 내용\"  # RFP의 초반부에 현황이 언급될 수 있음\n",
    "    ]\n",
    "\n",
    "    # As-Is 관련으로 식별된 모든 항목을 일차적으로 수집\n",
    "    as_is_candidate_entries = []\n",
    "    for entry in sorted_toc:\n",
    "        entry_title_lower = entry.get('title', '').strip().lower()\n",
    "        is_relevant_by_keyword = any(keyword in entry_title_lower for keyword in keywords_to_find)\n",
    "        is_relevant_by_llm_flag = entry.get('is_requirement_related', False)\n",
    "\n",
    "        if is_relevant_by_keyword or is_relevant_by_llm_flag:\n",
    "            as_is_candidate_entries.append(entry)\n",
    "\n",
    "    # 수집된 후보 항목들을 기반으로 실제 섹션 범위 결정 및 병합\n",
    "    final_target_sections = []\n",
    "    if not as_is_candidate_entries:  # 후보 섹션이 없으면 전체 문서를 대상으로\n",
    "        print(\"경고: LLM 파싱 목차에서 주요 As-Is 관련 섹션을 찾지 못했습니다. 전체 문서를 대상으로 As-Is 분석을 시도합니다.\")\n",
    "        return [{'title': '전체 문서 (As-Is 섹션 식별 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    current_start_page = as_is_candidate_entries[0].get('page', 1)\n",
    "    current_end_page = current_start_page\n",
    "    current_title = as_is_candidate_entries[0].get('title', 'AS-IS 관련 섹션')\n",
    "\n",
    "    for i in range(len(as_is_candidate_entries)):\n",
    "        entry = as_is_candidate_entries[i]\n",
    "        entry_page = entry.get('page', 0)\n",
    "\n",
    "        # 다음 섹션이 현재 처리 중인 범위에 바로 이어서 나오거나 겹칠 경우\n",
    "        # 다음 섹션이 없거나, 다음 섹션의 페이지가 현재 섹션의 끝 페이지 + 1 보다 클 경우\n",
    "        if i + 1 < len(as_is_candidate_entries):\n",
    "            next_entry_page = as_is_candidate_entries[i + 1].get('page', total_pages + 1)\n",
    "        else:\n",
    "            next_entry_page = total_pages + 1  # 마지막 항목 이후는 문서 끝까지\n",
    "\n",
    "        # 현재 항목의 끝 페이지는 다음 항목의 시작 페이지 -1 또는 문서 끝까지\n",
    "        potential_end_page = min(total_pages, next_entry_page - 1)\n",
    "\n",
    "        # 현재 entry_page가 current_end_page에 가깝거나, 현재 범위 내에 있다면 범위 확장\n",
    "        if entry_page <= current_end_page + 1:  # 1페이지 차이까지는 연속으로 간주\n",
    "            current_end_page = max(current_end_page, potential_end_page)\n",
    "        else:  # 새로운 연속되지 않는 섹션 시작\n",
    "            final_target_sections.append({\n",
    "                'title': current_title,\n",
    "                'start_page': current_start_page,\n",
    "                'end_page': current_end_page\n",
    "            })\n",
    "            current_start_page = entry_page\n",
    "            current_end_page = potential_end_page\n",
    "            current_title = entry.get('title', 'AS-IS 관련 섹션')\n",
    "\n",
    "    # 마지막 섹션 추가\n",
    "    final_target_sections.append({\n",
    "        'title': current_title,\n",
    "        'start_page': current_start_page,\n",
    "        'end_page': current_end_page\n",
    "    })\n",
    "\n",
    "    # 최종 결과 출력 및 정렬\n",
    "    for section in final_target_sections:\n",
    "        print(f\"식별된 As-Is 관련 섹션: '{section['title']}' (페이지 {section['start_page']}-{section['end_page']})\")\n",
    "\n",
    "    return sorted(final_target_sections, key=lambda x: x['start_page'])\n",
    "\n",
    "\n",
    "def summarize_chunk_for_as_is(chunk_text, client_instance, llm_model_name):\n",
    "    \"\"\"\n",
    "    단일 청크에서 As-Is 보고서의 각 섹션에 해당하는 내용을 추출하고 요약하여 JSON으로 반환합니다.\n",
    "    이때, 기능 목록은 동적으로 파악합니다.\n",
    "    \"\"\"\n",
    "    extraction_system_prompt = \"\"\"\n",
    "    당신은 RFP 문서의 한 부분을 분석하여 **현재 시스템(AS-IS)의 현황과 특징에만 집중**하여 보고서의 각 섹션별로 정보를 추출하고 요약하는 전문가입니다.\n",
    "    주어진 텍스트 청크에서 아래 JSON 구조에 맞춰 현재 시스템의 현황을 **최대한 상세하고 구체적으로** 추출하십시오.\n",
    "\n",
    "    - **절대 추측하거나 없는 내용을 만들어내지 마십시오.** 오직 주어진 텍스트 청크에 **명시적/암시적으로 언급된 현재 상태(AS-IS) 정보만** 작성합니다.\n",
    "    - 특히, \"필요합니다\", \"개선 예정\", \"목표\", \"해야 한다\"와 같은 **미래(To-Be) 지향적인 내용은 철저히 제외**하십시오.\n",
    "    - \"현재 이러이러한 문제가 있습니다\", \"현재 이러이러한 제약사항이 있습니다\", \"현재 이러이러한 기능만 지원합니다\", \"현재 이러이러한 방식입니다\"와 같이 **현재 상태를 설명하는 부정적인 표현, 한계점, 결함, 또는 특정 방식에 대한 언급이 있다면, 이는 중요한 AS-IS 정보이므로 반드시 상세히 기술**하십시오.\n",
    "    - 해당 섹션에 대한 AS-IS 정보가 텍스트 청크에 없으면, 해당 JSON 필드는 **\"정보 없음\"**으로 명확히 남겨 두십시오. 빈 문자열(\"\")보다 \"정보 없음\"이 더 명확합니다.\n",
    "    - 모든 추출 내용은 요약하거나 중요한 부분을 발췌하되, 가능한 한 원문의 의미를 살려 구체적으로 작성하십시오.\n",
    "    - **'dynamic_functional_areas'에는 RFP에 언급된 현재 시스템의 모든 핵심 기능들을 기능별로 상세히 설명하십시오.** 각 기능의 **현재 운영 방식, 특징, 한계점** 등을 구체적으로 서술해야 합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt_chunk = f\"\"\"\n",
    "    다음 RFP 텍스트 청크에서 현재 시스템(As-Is) 관련 정보를 위 JSON 구조에 맞춰 추출하여 반환해 주십시오.\n",
    "\n",
    "    --- 추출할 정보 구조 (JSON 형식) ---\n",
    "    {{\n",
    "        \"overview\": \"현재 JBANK 시스템의 목적, 구축 배경, 시스템 구성, 재구축 목표 중 현행 시스템과 관련된 부분, 현재 거래 처리량(TPS), 향후 거래량 증가 예측 등 현행 시스템의 전반적인 특징을 상세히 요약합니다. '재구축을 통해 성능 향상 및 보안 강화'와 같은 목표 언급이 있더라도, 이것이 현재 시스템의 한계를 내포한다면 AS-IS 정보로 볼 수 있습니다. (예: 현재 시스템은 50 TPS를 처리하며, 특정 이벤트 시 성능 저하 우려가 있음)\",\n",
    "        \"dynamic_functional_areas\": {{\n",
    "            \"기능명1\": \"기능1의 현재 운영 방식, 특징, 한계점 등 상세 설명 (예: (O2O) 비대면 대출 연장 신청 프로세스 개발 적용, (O2O) 비대면 서류 작성 시스템 개발 적용, 신한은행 마이데이터 서비스(머니버스) 연동(웹뷰 방식) 등 RFP에 언급된 현재 구현된 기능 중심으로 상세히 작성)\",\n",
    "            \"기능명2\": \"기능2에 대한 현재 상세 설명\",\n",
    "            \"기능명N\": \"기능N에 대한 현재 상세 설명\"\n",
    "        }},\n",
    "        \"non_functional_aspects\": {{\n",
    "            \"performance\": \"현재 시스템의 성능 관련 특징 (예: 현재 거래 처리량 50TPS, 향후 5년간 100TPS 증가 예상, 서비스의 성능 및 속도 보장 필요성 언급을 통해 현재의 잠재적 한계점 유추, 이벤트 시 사용자 급증에 따른 성능 저하 우려 등 현재 상황에 대한 언급)을 구체적인 수치와 함께 상세히 기술\",\n",
    "            \"security\": \"현재 시스템의 보안 체계 (예: 로그 적재 시 비밀번호 마스킹 처리, 계정계 시스템과의 통신 시 암호화 방식 적용), 금융감독원 보안성 심의 가이드 준수 필요성 언급을 통해 현재 보안 수준 유추, 보안 취약점 예방 및 앱 접근성 인증마크 획득 방안 필요성 언급을 통해 현재의 부족한 부분을 AS-IS로 명시\",\n",
    "            \"data\": \"현재 데이터 관리 방식 (예: 데이터 이행 계획 수립 여부, 데이터 매핑/초기 이행/변경 이행 포함 여부, 데이터 검증 및 정비 절차 유무, 데이터 오류 유형별 대응 방안 제시 여부)의 상세 현황을 기술\",\n",
    "            \"ui_ux\": \"현재 모바일 뱅킹 앱의 사용자 인터페이스 및 사용자 경험에 대한 RFP의 언급 (예: 모바일 최적화 웹 개발 프레임워크 사용 권장이라는 문구를 통해 현재 최적화가 부족할 수 있음을 유추, 웹표준/웹접근성 자동 검증 기능 유무, UX 개선안 정의 및 사용자 검증 필요성 언급을 통해 현재 UX의 부족함 유추)을 상세히 설명\",\n",
    "            \"stability\": \"시스템의 가용성 (예: 이중화 및 HA(Active-Active) 구성 원칙, DR 시스템은 싱글 구조로 제안되어 운영 환경과 동일한 시스템 구조와 소프트웨어 구성 갖춤), 서비스 오류 감지 및 원인 파악을 위한 거래 추적 구조 필요성 언급을 통해 현재 추적 기능의 부족함 유추 등 안정성 관련 현황을 구체적으로 설명\",\n",
    "            \"constraints\": \"현재 시스템이 가진 기술적 (예: 개방형 구조의 Linux 기반, DB 서버는 Oracle RAC 구성), 운영적 한계 또는 외부 제약사항 (예: 프로젝트 진행 중 금융 관련 법규의 신설/변경, 감독당국의 지시사항 수용 필요)을 상세히 기술\"\n",
    "        }},\n",
    "        \"tech_architecture\": {{\n",
    "            \"tech_stack\": \"현재 시스템이 사용하는 주요 기술 스택 (예: 운영체제 - 개방형 구조의 Linux 기반, 데이터베이스 - Oracle RAC 구성, 모바일 웹 개발 프레임워크 사용 권장(react.js, vue.js, spring boot)을 통해 현재 어떤 기술이 사용되거나 부족한지 유추)을 구체적으로 나열\",\n",
    "            \"architecture\": \"현재 시스템의 전반적인 아키텍처 (예: 3 Tier(WEB-AP-DB) 구조, 주요 시스템 구간별 고가용성 확보, 컨텐츠 관리 방식(일괄 다운로드 방식 추정)) 및 구성 방식(다중화, 상호백업)을 상세히 설명\",\n",
    "            \"integration_systems\": \"현재 연동하고 있는 주요 내부/외부 시스템 (예: 신한은행 마이데이터 서비스(머니버스) 연동(웹뷰 방식), 당행 통합모니터링(H/W, 어플리케이션, 네트워크 전구간 모니터링, 장애감지, 실시간 모니터링, 장애처리, 백업/복구 대응)과 연동) 현황 및 연동 방식을 구체적으로 설명\"\n",
    "        }}\n",
    "    }}\n",
    "    ---\n",
    "\n",
    "    --- 텍스트 청크 시작 ---\n",
    "    {chunk_text}\n",
    "    --- 텍스트 청크 끝 ---\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model_name,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": extraction_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt_chunk}\n",
    "            ],\n",
    "            temperature=0.0  # 일관된 결과를 위해 0.0 유지\n",
    "        )\n",
    "        extracted_info_str = response.choices[0].message.content\n",
    "        extracted_info = json.loads(extracted_info_str)\n",
    "        return extracted_info\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"   경고: 청크 처리 중 JSON 파싱 오류: {e}. 응답 미리보기: {extracted_info_str[:200]}...\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"   오류: 청크 처리 중 LLM API 호출 또는 처리 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def consolidate_section_content(section_title, all_extracted_texts, client_instance, llm_model_name, is_dynamic_functional=False):\n",
    "    \"\"\"\n",
    "    주어진 섹션 제목과 해당 섹션에 대해 모든 청크에서 추출된 텍스트들을 통합하여 상세 보고서 내용을 생성합니다.\n",
    "    동적 기능 섹션의 경우 별도 처리가 필요합니다.\n",
    "    (주의: 이 함수는 더 이상 마크다운 헤딩을 자체적으로 추가하지 않습니다. 내용은 일반 텍스트로 반환합니다.)\n",
    "    \"\"\"\n",
    "    if not all_extracted_texts:\n",
    "        # 섹션 제목 자체를 포함하지 않음. 호출하는 곳에서 헤딩을 추가할 것이기 때문\n",
    "        return \"RFP 텍스트에서 관련 정보를 충분히 찾을 수 없습니다.\"\n",
    "\n",
    "    if is_dynamic_functional:\n",
    "        combined_functions = {}\n",
    "        for func_dict in all_extracted_texts:\n",
    "            if isinstance(func_dict, dict):\n",
    "                for func_name, func_desc in func_dict.items():\n",
    "                    func_name = func_name.strip()\n",
    "                    func_desc = func_desc.strip()\n",
    "                    if func_name and func_desc not in [\"정보 없음\", \"\"]:\n",
    "                        if func_name in combined_functions:\n",
    "                            if func_desc and func_desc not in combined_functions[func_name]:\n",
    "                                if combined_functions[func_name]:\n",
    "                                    combined_functions[func_name] += f\"\\n- {func_desc}\"\n",
    "                                else:\n",
    "                                    combined_functions[func_name] = func_desc\n",
    "                        elif func_desc:\n",
    "                            combined_functions[func_name] = func_desc\n",
    "\n",
    "        if not combined_functions:\n",
    "            return \"RFP 텍스트에서 주요 기능을 찾을 수 없습니다.\"\n",
    "\n",
    "        functions_list_for_llm = []\n",
    "        for name, desc in combined_functions.items():\n",
    "            # 여기서는 '### {name}'과 같이 기능별 서브-서브-서브 헤딩을 유지하여 기능 구분\n",
    "            functions_list_for_llm.append(f\"### {name}\")\n",
    "            functions_list_for_llm.append(desc if desc else \"현재 상세 정보 없음.\")\n",
    "            functions_list_for_llm.append(\"\")\n",
    "\n",
    "        combined_texts_for_llm = \"\\n\".join(functions_list_for_llm)\n",
    "        if len(combined_texts_for_llm) > 40000:\n",
    "            combined_texts_for_llm = combined_texts_for_llm[:40000] + \"\\n... (생략됨)\"\n",
    "\n",
    "        # ... (이전 코드와 동일한 LLM 호출 로직)\n",
    "        section_consolidation_prompt = f\"\"\"\n",
    "        당신은 RFP 문서의 '현황 분석(As-Is) 보고서' 중 '**{section_title}**' 섹션에 대한 전문 작성자입니다.\n",
    "        다음은 RFP 문서의 여러 부분에서 추출된 현재 시스템의 주요 기능들에 대한 정보들입니다.\n",
    "        이 정보들을 종합하고, 중복을 제거하며, 가장 상세하고 구체적인 내용만을 선별하여 Markdown 형식으로 **전문적이고 상세한 보고서 내용**을 작성해 주십시오.\n",
    "\n",
    "        - **각 기능을 독립적인 서브 섹션(####)으로 나누어 현재 운영 방식, 특징, 한계점 등을 상세히 설명하십시오.**\n",
    "        - **절대 추측하거나 없는 내용을 만들어내지 마십시오.** 오직 제공된 정보 내에서만 내용을 구성하십시오.\n",
    "        - 내용이 불충분하더라도, 제공된 정보 내에서 최대한 상세하게 작성하십시오.\n",
    "        - 제목을 따로 작성하지 않습니다.\n",
    "\n",
    "        --- 추출된 '{section_title}' 관련 정보들 ---\n",
    "        {combined_texts_for_llm}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": section_consolidation_prompt},\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"   오류: '{section_title}' 섹션 통합 생성 중 LLM API 호출 실패: {e}\")\n",
    "            return f\"RFP 텍스트에서 주요 기능을 찾을 수 없습니다. (처리 오류: {e})\"\n",
    "\n",
    "    else:\n",
    "        unique_texts = list(set([text.strip() for text in all_extracted_texts if text.strip()]))\n",
    "        unique_texts = [text for text in unique_texts if text not in [\"정보 없음\", \"\"]]\n",
    "\n",
    "        if not unique_texts:\n",
    "            return \"RFP 텍스트에서 관련 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "        combined_texts_for_llm = \"\\n- \".join(unique_texts)\n",
    "        if len(combined_texts_for_llm) > 40000:\n",
    "            combined_texts_for_llm = combined_texts_for_llm[:40000] + \"\\n... (생략됨)\"\n",
    "\n",
    "        # ... (이전 코드와 동일한 LLM 호출 로직)\n",
    "        section_consolidation_prompt = f\"\"\"\n",
    "        당신은 RFP 문서의 '현황 분석(As-Is) 보고서' 중 '**{section_title}**' 섹션에 대한 전문 작성자입니다.\n",
    "        다음은 RFP 문서의 여러 부분에서 추출된 '{section_title}' 관련 정보들입니다.\n",
    "        이 정보들을 종합하고, 중복을 제거하며, 가장 상세하고 정확한 내용만을 선별하여 Markdown 형식으로 **전문적이고 구체적인 보고서 내용**을 작성해 주십시오.\n",
    "\n",
    "        - **절대 추측하거나 없는 내용을 만들어내지 마십시오.** 오직 제공된 정보 내에서만 내용을 구성하십시오.\n",
    "        - 특히, \"필요합니다\", \"개선 예정\", \"목표\", \"해야 한다\"와 같은 **미래(To-Be) 지향적인 내용은 철저히 제외**하십시오.\n",
    "        - \"현재 이러이러한 문제가 있습니다\", \"현재 이러이러한 제약사항이 있습니다\", \"현재 이러이러한 기능만 지원합니다\", \"현재 이러이러한 방식입니다\"와 같이 **현재 상태를 설명하는 부정적인 표현, 한계점, 결함, 또는 특정 방식에 대한 언급이 있다면, 이는 중요한 AS-IS 정보이므로 반드시 상세히 기술**하십시오.\n",
    "        - 내용이 불충분하더라도, 제공된 정보 내에서 최대한 상세하게 작성하십시오.\n",
    "        - 제목을 따로 작성하지 않습니다.\n",
    "\n",
    "        --- 추출된 '{section_title}' 관련 정보들 ---\n",
    "        {combined_texts_for_llm}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": section_consolidation_prompt},\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"   오류: '{section_title}' 섹션 통합 생성 중 LLM API 호출 실패: {e}\")\n",
    "            return f\"RFP 텍스트에서 관련 정보를 찾을 수 없습니다. (처리 오류: {e})\"\n",
    "\n",
    "def generate_as_is_report_from_rfp_text(\n",
    "    page_texts_list,\n",
    "    total_pages,\n",
    "    client_instance,\n",
    "    llm_model_name,\n",
    "    target_sections_for_analysis,\n",
    "):\n",
    "    \"\"\"\n",
    "    RFP 전체 텍스트(리스트 형태)를 청크로 나누고, 각 청크에서 As-Is 정보를 추출/요약하여\n",
    "    최종 As-Is 분석 보고서를 생성합니다. 섹션별 구분을 제거하고, 하나의 통합된 보고서를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n[As-Is 보고서 생성] LLM을 사용하여 현황 분석 보고서를 생성합니다...\")\n",
    "\n",
    "    # AS-IS 분석 대상 섹션들의 텍스트만 추출하여 하나의 긴 텍스트로 결합\n",
    "    all_as_is_relevant_text_parts = []\n",
    "    for section_info in target_sections_for_analysis:\n",
    "        section_text = extract_text_for_pages(\n",
    "            page_texts_list, section_info[\"start_page\"], section_info[\"end_page\"]\n",
    "        )\n",
    "        if section_text:\n",
    "            all_as_is_relevant_text_parts.append(section_text)\n",
    "        else:\n",
    "            print(\n",
    "                f\"      경고: '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']})에서 텍스트를 추출하지 못했습니다.\"\n",
    "            )\n",
    "\n",
    "    if not all_as_is_relevant_text_parts:\n",
    "        print(\"오류: As-Is 분석을 위한 텍스트를 전혀 추출하지 못했습니다. 보고서 생성을 중단합니다.\")\n",
    "        return \"As-Is 보고서 생성이 실패했습니다: 분석할 텍스트가 없습니다.\"\n",
    "\n",
    "    combined_rfp_text_for_as_is = \"\\n\\n\".join(all_as_is_relevant_text_parts)\n",
    "    print(\n",
    "        f\"   As-Is 분석을 위한 RFP 텍스트 결합 완료. 총 길이: {len(combined_rfp_text_for_as_is)}자.\"\n",
    "    )\n",
    "\n",
    "    # 텍스트 청크 분할 설정 (청크 오버랩 500자)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=15000,  # 청크 크기를 15000으로 줄여 더 잘게 쪼갬\n",
    "        chunk_overlap=500,  # 청크 간 오버랩\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],  # 페이지 마커는 이미 제거되었으므로 일반적인 구분자 사용\n",
    "        keep_separator=False,\n",
    "    )\n",
    "    rfp_chunks = text_splitter.split_text(combined_rfp_text_for_as_is)\n",
    "    print(f\"   AS-IS 관련 텍스트를 총 {len(rfp_chunks)}개의 청크로 분할했습니다 (오버랩 포함).\")\n",
    "\n",
    "    # 모든 청크에서 추출된 정보를 저장할 구조\n",
    "    all_extracted_data = {\n",
    "        \"overview\": [],\n",
    "        \"dynamic_functional_areas\": [],\n",
    "        \"non_functional_aspects\": {\n",
    "            \"performance\": [],\n",
    "            \"security\": [],\n",
    "            \"data\": [],\n",
    "            \"ui_ux\": [],\n",
    "            \"stability\": [],\n",
    "            \"constraints\": [],\n",
    "        },\n",
    "        \"tech_architecture\": {\n",
    "            \"tech_stack\": [],\n",
    "            \"architecture\": [],\n",
    "            \"integration_systems\": [],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # 1단계: 각 청크에서 As-Is 관련 정보 추출 (JSON 형식)\n",
    "    for i, chunk in enumerate(rfp_chunks):\n",
    "        print(f\"   청크 {i+1}/{len(rfp_chunks)}에서 정보 추출 중...\")\n",
    "        extracted_info = summarize_chunk_for_as_is(\n",
    "            chunk, client_instance, llm_model_name\n",
    "        )\n",
    "\n",
    "        if extracted_info:\n",
    "            # '정보 없음' 또는 빈 문자열이 아닌 경우에만 추가\n",
    "            if extracted_info.get(\"overview\") not in [\"정보 없음\", \"\"]:\n",
    "                all_extracted_data[\"overview\"].append(extracted_info[\"overview\"])\n",
    "\n",
    "            if extracted_info.get(\"dynamic_functional_areas\"):\n",
    "                all_extracted_data[\"dynamic_functional_areas\"].append(\n",
    "                    extracted_info[\"dynamic_functional_areas\"]\n",
    "                )\n",
    "\n",
    "            for key, val in extracted_info.get(\"non_functional_aspects\", {}).items():\n",
    "                if val not in [\"정보 없음\", \"\"]:\n",
    "                    all_extracted_data[\"non_functional_aspects\"][key].append(val)\n",
    "\n",
    "            for key, val in extracted_info.get(\"tech_architecture\", {}).items():\n",
    "                if val not in [\"정보 없음\", \"\"]:\n",
    "                    all_extracted_data[\"tech_architecture\"][key].append(val)\n",
    "\n",
    "    print(\"\\n[2단계: 추출된 정보 통합 및 보고서 생성]\")\n",
    "    final_as_is_report_parts = []\n",
    "\n",
    "    # 2.1 개요 통합\n",
    "    overview_content = consolidate_section_content(\n",
    "        \"시스템 개요\", all_extracted_data[\"overview\"], client_instance, llm_model_name\n",
    "    )\n",
    "    final_as_is_report_parts.append(\"## 1. 현행 시스템 개요\\n\")\n",
    "    final_as_is_report_parts.append(overview_content)\n",
    "\n",
    "    # 2.2 주요 기능 현황 통합 (Dynamic Functional Areas)\n",
    "    functional_content = consolidate_section_content(\n",
    "        \"주요 기능 현황\",\n",
    "        all_extracted_data[\"dynamic_functional_areas\"],\n",
    "        client_instance,\n",
    "        llm_model_name,\n",
    "        is_dynamic_functional=True,\n",
    "    )\n",
    "    final_as_is_report_parts.append(\"\\n\\n## 2. 주요 기능 현황\\n\")\n",
    "    final_as_is_report_parts.append(functional_content)\n",
    "\n",
    "    # 2.3 비기능 요구사항 현황 통합\n",
    "    final_as_is_report_parts.append(\"\\n\\n## 3. 비기능 요구사항 현황\\n\")\n",
    "    non_functional_titles = {\n",
    "        \"performance\": \"가. 성능\",\n",
    "        \"security\": \"나. 보안\",\n",
    "        \"data\": \"다. 데이터\",\n",
    "        \"ui_ux\": \"라. UI/UX\",\n",
    "        \"stability\": \"마. 안정성\",\n",
    "        \"constraints\": \"바. 제약사항\",\n",
    "    }\n",
    "    for key, title in non_functional_titles.items():\n",
    "        content = consolidate_section_content(\n",
    "            title, # consolidate_section_content로 전달하는 title은 LLM 프롬프트에 사용\n",
    "            all_extracted_data[\"non_functional_aspects\"][key],\n",
    "            client_instance,\n",
    "            llm_model_name,\n",
    "        )\n",
    "        # 여기서 헤딩을 명확히 추가\n",
    "        final_as_is_report_parts.append(f\"\\n### {title}\\n{content}\") # <-- 이 부분이 중요\n",
    "\n",
    "    # 2.4 기술 아키텍처 현황 통합\n",
    "    final_as_is_report_parts.append(\"\\n\\n## 4. 기술 아키텍처 현황\\n\")\n",
    "    tech_arch_titles = {\n",
    "        \"tech_stack\": \"가. 기술 스택\",\n",
    "        \"architecture\": \"나. 아키텍처\",\n",
    "        \"integration_systems\": \"다. 연동 시스템\",\n",
    "    }\n",
    "    for key, title in tech_arch_titles.items():\n",
    "        content = consolidate_section_content(\n",
    "            title, # consolidate_section_content로 전달하는 title은 LLM 프롬프트에 사용\n",
    "            all_extracted_data[\"tech_architecture\"][key],\n",
    "            client_instance,\n",
    "            llm_model_name,\n",
    "        )\n",
    "        # 여기서 헤딩을 명확히 추가\n",
    "        final_as_is_report_parts.append(f\"\\n### {title}\\n{content}\") # <-- 이 부분이 중요\n",
    "\n",
    "    final_report = \"\\n\".join(final_as_is_report_parts)\n",
    "    print(\"\\n[As-Is 보고서 생성 완료]\")\n",
    "    return final_report\n",
    "\n",
    "\n",
    "# --- 메인 실행 함수 (예시) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 이 부분은 실제 PDF 파일 경로로 대체해야 합니다.\n",
    "    pdf_file_path = \"docs/제주은행_RFP.pdf\"  # 예시 파일명\n",
    "\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"오류: PDF 파일 '{pdf_file_path}'을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    else:\n",
    "        print(f\"PDF 파일 '{pdf_file_path}'에서 텍스트를 추출 중...\")\n",
    "        page_texts, total_pages = extract_text_with_page_info(pdf_file_path)\n",
    "\n",
    "        if not page_texts:\n",
    "            print(\"PDF에서 텍스트를 추출하는 데 실패했습니다. 파일이 유효한지 확인해주세요.\")\n",
    "        else:\n",
    "            print(f\"총 {total_pages} 페이지의 텍스트를 추출했습니다.\")\n",
    "\n",
    "            # 1. 목차 페이지 텍스트 추출\n",
    "            # RFP 문서의 실제 목차 페이지 번호를 확인하여 필요시 조정하세요.\n",
    "            toc_raw_text = get_toc_raw_text_from_full_text(page_texts, toc_page_numbers=[2, 3])\n",
    "\n",
    "            if toc_raw_text:\n",
    "                print(\"\\n[목차 파싱] LLM을 사용하여 목차를 파싱합니다...\")\n",
    "                parsed_toc = parse_toc_with_llm(toc_raw_text, client, LLM_MODEL_FOR_REPORTING)\n",
    "\n",
    "                if parsed_toc:\n",
    "                    print(\"\\n[대상 섹션 식별] 파싱된 목차에서 As-Is 관련 섹션을 식별합니다...\")\n",
    "                    target_sections = get_target_sections_from_llm_parsed_toc(parsed_toc, total_pages)\n",
    "\n",
    "                    if target_sections:\n",
    "                        # 현황 분석 보고서 생성\n",
    "                        as_is_report = generate_as_is_report_from_rfp_text(\n",
    "                            page_texts, total_pages, client, LLM_MODEL_FOR_REPORTING, target_sections\n",
    "                        )\n",
    "\n",
    "                        # 결과 출력 또는 파일 저장\n",
    "                        output_filename = \"As_Is_Analysis_Report_Integrated.md\"\n",
    "                        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                            f.write(as_is_report)\n",
    "                        print(f\"\\n성공적으로 현황 분석 보고서를 '{output_filename}' 파일로 저장했습니다.\")\n",
    "                        print(\"\\n--- 현황 분석 보고서 내용 미리보기 ---\")\n",
    "                        print(as_is_report[:2000]) # 보고서의 처음 2000자만 출력하여 미리보기\n",
    "                        print(\"\\n----------------------------------\")\n",
    "                    else:\n",
    "                        print(\"As-Is 분석을 위한 목차 섹션을 식별할 수 없습니다. 보고서 생성을 건너뜜.\")\n",
    "                else:\n",
    "                    print(\"목차 파싱에 실패했습니다. 보고서 생성을 건너뜜.\")\n",
    "            else:\n",
    "                print(\"목차 원시 텍스트를 추출할 수 없습니다. 보고서 생성을 건너뛰고 전체 문서를 대상으로 시도할 수 있습니다.\")\n",
    "                # 목차 추출 실패 시 전체 문서를 대상으로 As-Is 분석 시도\n",
    "                print(\"\\n[목차 추출 실패] 전체 문서를 대상으로 As-Is 분석을 시도합니다...\")\n",
    "                target_sections_full_document = [{'title': '전체 문서', 'start_page': 1, 'end_page': total_pages}]\n",
    "                as_is_report_full = generate_as_is_report_from_rfp_text(\n",
    "                    page_texts, total_pages, client, LLM_MODEL_FOR_REPORTING, target_sections_full_document\n",
    "                )\n",
    "                output_filename_full = \"As_Is_Analysis_Report_Full_Document.md\"\n",
    "                with open(output_filename_full, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(as_is_report_full)\n",
    "                print(f\"\\n성공적으로 전체 문서를 기반으로 한 현황 분석 보고서를 '{output_filename_full}' 파일로 저장했습니다.\")\n",
    "                print(\"\\n--- 현황 분석 보고서 내용 미리보기 (전체 문서 기반) ---\")\n",
    "                print(as_is_report_full[:2000]) # 보고서의 처음 2000자만 출력하여 미리보기\n",
    "                print(\"\\n----------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
