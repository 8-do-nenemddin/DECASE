{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 버전1(초기설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. PDF 전체 텍스트 추출 중...\n",
      "   PDF 전체 텍스트 추출 완료. 총 54 페이지, 전체 텍스트 길이: 49066자.\n",
      "\n",
      "2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\n",
      "   목차 원문 텍스트 추출 완료 (길이: 8670자).\n",
      "\n",
      "3. LLM을 사용하여 목차(ToC) 파싱 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 459\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   목차 원문 텍스트 추출 완료 (길이: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(toc_raw_text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m자).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    458\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m3. LLM을 사용하여 목차(ToC) 파싱 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m parsed_toc_entries = \u001b[43mparse_toc_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoc_raw_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLLM_MODEL_FOR_PARSING\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parsed_toc_entries:\n\u001b[32m    462\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   LLM 목차 파싱 완료. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(parsed_toc_entries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개의 목차 항목 식별.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mparse_toc_with_llm\u001b[39m\u001b[34m(toc_raw_text, client_instance, llm_model)\u001b[39m\n\u001b[32m    216\u001b[39m llm_response_content = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# 오류 발생 시 로깅을 위해 미리 선언\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     response = \u001b[43mclient_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     llm_response_content = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# print(f\"DEBUG: LLM RAW RESPONSE FOR TOC: {llm_response_content}\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-nqLnFQ7l-py3.11\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # initial_text_split 에서 사용\n",
    "import os\n",
    "import json\n",
    "import uuid # llm_based_semantic_chunking_for_dev_reqs 에서 사용\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 (사용자 기존 코드) ---\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL_FOR_PARSING = \"gpt-4o\" # 목차 파싱 및 요구사항 추출에 사용할 모델\n",
    "\n",
    "# --- 사용자 기존 함수 정의 부분 (여기에 extract_text_with_page_info, initial_text_split, llm_based_semantic_chunking_for_dev_reqs 가 있어야 함) ---\n",
    "\n",
    "def extract_text_with_page_info(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 페이지별로 추출하고, 각 페이지 시작에 페이지 번호를 표기합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        # 페이지 마커를 맨 앞에 추가하고, 실제 텍스트 내용과 명확히 구분되도록 줄바꿈 추가\n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def initial_text_split(text, chunk_size=4000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 LLM이 처리할 수 있는 크기로 초기 분할합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "        keep_separator=True # 페이지 마커 유지를 위해 True 권장\n",
    "    )\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs\n",
    "\n",
    "# llm_based_semantic_chunking_for_dev_reqs 함수 정의 (사용자 스크립트 내용)\n",
    "# def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=\"gpt-4o\"): ...\n",
    "# (이전에 제공된 프롬프트와 로직을 그대로 사용한다고 가정)\n",
    "def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    final_semantic_chunks = []\n",
    "    req_id_counter = 0\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 시스템 요구사항을 전문적으로 분석하고 개발 표준에 맞춰 구조화하는 시니어 비즈니스 분석가입니다.\n",
    "    사용자가 제공하는 텍스트는 RFP 문서의 특정 섹션이며, 여기서 모든 기능적, 비기능적, 성능, 보안, 데이터 요구사항을 추출해야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "\n",
    "    -   **id**: 고유 식별자. 예를 들어, 기능적 요구사항은 \"FUNC-001\", 비기능적은 \"NFR-001\", 보안은 \"SEC-001\"과 같이 유형 접두사와 일련번호를 결합하여 생성하십시오. (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. 다음 중 하나를 선택: \"기능적\", \"비기능적\", \"성능\", \"보안\", \"데이터\", \"시스템 장비 구성\", \"컨설팅\", \"테스트\", \"품질\" 텍스트에 명시된 내용에 따라 가장 적합한 유형을 선택하십시오. (예: \"시스템 장비 구성요구사항\", \"컨설팅 요구사항\" 등 PDF의 분류명 활용)\n",
    "    -   **description**: 요구사항에 대한 명확하고 간결한 설명. 원본 PDF의 '요구사항 명칭'과 '정의', '상세설명/세부내용'을 종합하여 개발 친화적인 형태로 작성하십시오. 하나의 요구사항은 하나의 독립적인 기능 또는 특성을 나타내야 합니다.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 검증할 수 있는 구체적인 테스트 조건이나 결과. 1~2개의 명확한 문장으로 서술하십시오. 원본 텍스트에 직접적인 검증 기준이 없더라도, 요구사항의 내용에 기반하여 합리적으로 추론하여 작성하십시오. (예: \"사용자가 [기능]을 수행했을 때, [예상 결과]가 나타난다.\")\n",
    "    -   **priority**: 요구사항의 중요도. 다음 중 하나를 선택: \"필수\", \"높음\", \"중간\", \"낮음\". (텍스트에 명시되어 있다면 그대로 사용, 아니면 일반적으로 \"필수\"로 추정)\n",
    "    -   **responsible_module**: 이 요구사항이 주로 영향을 미치거나 구현될 것으로 예상되는 시스템/애플리케이션의 주요 모듈 또는 영역 (예: \"로그인 모듈\", \"결제 시스템\", \"관리자 페이지\", \"데이터베이스\"). 텍스트 내용을 기반으로 추론하십시오.\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트. 페이지 구분자(`---PAGE_START_N---`)를 참조하여 정확한 페이지 번호를 파싱하십시오.\n",
    "    -   **raw_text_snippet**: 이 요구사항이 포함된 원본 텍스트 스니펫. 해당 요구사항을 추출하는 데 사용된 원본 문장 또는 단락(예: 표의 해당 행 전체 내용)을 포함하십시오.\n",
    "\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 요구사항이 없다면 빈 배열 `[]`을 반환하십시오.\n",
    "    불필요한 서론, 사업 배경, 계약 조건, 제안 지침 등은 요구사항으로 추출하지 마십시오. PDF의 '상세 요구사항' 목록에 있는 구조화된 항목들 위주로 추출해주십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, chunk_doc in enumerate(initial_chunks):\n",
    "        chunk_text = chunk_doc.page_content\n",
    "        print(f\"--- LLM 처리 중 (요구사항 상세 추출): 청크 {i+1}/{len(initial_chunks)} (길이: {len(chunk_text)}자) ---\")\n",
    "\n",
    "        page_numbers_in_chunk = sorted(list(set(\n",
    "            int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text)\n",
    "        )))\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부입니다. 이 부분에서 모든 시스템 요구사항을 개발자 표준에 맞춰 JSON 형식으로 추출해 주세요.\n",
    "        주어진 텍스트 내의 \"요구사항 고유번호\", \"요구사항 명칭\", \"요구사항 분류\", \"정의\", \"상세설명/세부내용\" 등의 명시적 필드를 최대한 활용하여 JSON 객체를 구성해주십시오.\n",
    "\n",
    "        --- 텍스트 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            llm_response_content = response.choices[0].message.content\n",
    "            try:\n",
    "                extracted_data_outer = json.loads(llm_response_content)\n",
    "                extracted_data_list = []\n",
    "                if isinstance(extracted_data_outer, list):\n",
    "                    extracted_data_list = extracted_data_outer\n",
    "                elif isinstance(extracted_data_outer, dict):\n",
    "                    # 딕셔너리 값 중에 리스트를 찾아 첫 번째 것을 사용 (일반적인 LLM 응답 패턴)\n",
    "                    for key_in_dict in extracted_data_outer:\n",
    "                        if isinstance(extracted_data_outer[key_in_dict], list):\n",
    "                            extracted_data_list = extracted_data_outer[key_in_dict]\n",
    "                            break\n",
    "                    if not extracted_data_list: # 그래도 못찾으면 경고\n",
    "                        print(f\"경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: {list(extracted_data_outer.keys())}\")\n",
    "                else:\n",
    "                    print(f\"경고: LLM으로부터 예상치 못한 JSON 형식 응답 (리스트 또는 객체 내 리스트가 아님). {llm_response_content[:100]}...\")\n",
    "                    continue\n",
    "            except json.JSONDecodeError as e_inner:\n",
    "                print(f\"LLM 응답 내용 JSON 파싱 오류 (내부 시도): {e_inner}. 응답: {llm_response_content[:500]}...\")\n",
    "                continue\n",
    "\n",
    "            for req_idx, req in enumerate(extracted_data_list):\n",
    "                # 'id'가 없거나 비어있으면 생성, 또는 원본 ID 우선 사용\n",
    "                original_id = req.get('id') # LLM이 원본 ID (ECR-001 등)를 id 필드에 넣어줬길 기대\n",
    "                if not original_id:\n",
    "                    req_type_prefix = \"REQ\"\n",
    "                    req_type = req.get('type', '기타').strip()\n",
    "                    if \"기능\" in req_type: req_type_prefix = \"FUNC\"\n",
    "                    elif \"비기능\" in req_type: req_type_prefix = \"NFR\"\n",
    "                    elif \"성능\" in req_type: req_type_prefix = \"PERF\"\n",
    "                    elif \"보안\" in req_type: req_type_prefix = \"SEC\"\n",
    "                    elif \"데이터\" in req_type: req_type_prefix = \"DATA\"\n",
    "                    elif \"제약\" in req_type: req_type_prefix = \"CONST\"\n",
    "                    elif \"장비\" in req_type: req_type_prefix = \"ECR\"\n",
    "                    elif \"품질\" in req_type: req_type_prefix = \"QUR\" \n",
    "                    req_id_counter += 1\n",
    "                    req['id'] = f\"{req_type_prefix}-{req_id_counter:03d}\"\n",
    "\n",
    "                if 'source_pages' not in req or not req['source_pages']:\n",
    "                    req['source_pages'] = page_numbers_in_chunk if page_numbers_in_chunk else []\n",
    "\n",
    "                if 'raw_text_snippet' not in req or not req['raw_text_snippet']:\n",
    "                    req['raw_text_snippet'] = f\"청크 {i+1}에서 추출됨. 원본 청크 일부: {chunk_text[:200]}...\" # 개선 필요\n",
    "\n",
    "                req['type'] = req.get('type', '기타')\n",
    "                req['description'] = req.get('description', '설명 없음')\n",
    "                req['acceptance_criteria'] = req.get('acceptance_criteria', '해당하는 경우 명시')\n",
    "                req['priority'] = req.get('priority', '필수')\n",
    "                req['responsible_module'] = req.get('responsible_module', '미정')\n",
    "                final_semantic_chunks.append(req)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"LLM API 호출 또는 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    return final_semantic_chunks\n",
    "\n",
    "\n",
    "# --- LLM으로 목차 파싱하는 함수 (이전 답변에서 제공 및 개선된 버전) ---\n",
    "def parse_toc_with_llm(toc_raw_text, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 목차 원문 텍스트를 파싱하여 구조화된 목차 항목을 추출합니다.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 PDF 문서에서 추출된 목차(Table of Contents)의 원시 텍스트를 분석하는 전문가입니다.\n",
    "    주어진 텍스트를 파싱하여 각 목차 항목의 제목, 페이지 번호, 그리고 해당 항목이 '요구사항' 관련 내용을 담고 있을 가능성을 분석하여 JSON 형태로 반환해야 합니다.\n",
    "    JSON의 최상위 레벨은 \"toc_entries\"라는 키를 가진 객체여야 하고, 그 키의 값은 목차 항목 객체들의 리스트여야 합니다.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    다음은 PDF에서 추출한 목차로 추정되는 텍스트입니다:\n",
    "\n",
    "    --- 목차 원문 텍스트 시작 ---\n",
    "    {toc_raw_text}\n",
    "    --- 목차 원문 텍스트 끝 ---\n",
    "\n",
    "    이 텍스트를 분석하여 JSON 객체를 반환해주세요. 이 객체는 \"toc_entries\"라는 키를 가져야 하며,\n",
    "    이 키의 값은 각 목차 항목을 나타내는 객체들의 리스트여야 합니다.\n",
    "    각 목차 항목 객체는 다음 키를 가져야 합니다:\n",
    "    - \"title\": (문자열) 목차 항목의 전체 제목. 제목 앞의 번호(예: \"1.\", \"II.\", \"가.\")도 포함해주세요.\n",
    "    - \"page\": (정수) 해당 항목의 시작 페이지 번호.\n",
    "    - \"is_requirement_related\": (불리언) 제목이나 내용을 볼 때, 해당 항목이 '요구사항', '과업 범위', '제안 요청 상세', '기능 명세', '기술 요건' 등과 관련된 내용을 다룰 가능성이 높으면 true, 그렇지 않으면 false로 설정해주세요.\n",
    "\n",
    "    예시 JSON 출력 형식:\n",
    "    {{\n",
    "      \"toc_entries\": [\n",
    "        {{\n",
    "          \"title\": \"1. 사업 개요\",\n",
    "          \"page\": 5,\n",
    "          \"is_requirement_related\": false\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"III. 제안요청 내용\",\n",
    "          \"page\": 6,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"3. 상세 요구사항\",\n",
    "          \"page\": 11,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"* 보안 요구사항 별표\",\n",
    "          \"page\": 63,\n",
    "          \"is_requirement_related\": true\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    만약 주어진 텍스트가 유효한 목차로 보이지 않거나 항목을 전혀 파싱할 수 없다면,\n",
    "    \"toc_entries\" 키의 값으로 빈 리스트 `[]`를 포함하는 JSON 객체를 반환해주세요. (예: {{\"toc_entries\": []}})\n",
    "    \"\"\"\n",
    "    llm_response_content = \"\" # 오류 발생 시 로깅을 위해 미리 선언\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        # print(f\"DEBUG: LLM RAW RESPONSE FOR TOC: {llm_response_content}\")\n",
    "\n",
    "        parsed_data = json.loads(llm_response_content)\n",
    "\n",
    "        extracted_list = []\n",
    "        if isinstance(parsed_data, dict) and \"toc_entries\" in parsed_data and isinstance(parsed_data[\"toc_entries\"], list):\n",
    "            extracted_list = parsed_data[\"toc_entries\"]\n",
    "        else:\n",
    "            print(f\"LLM 응답이 예상된 'toc_entries' 리스트를 포함하는 객체 형식이 아닙니다. 응답: {llm_response_content[:200]}\")\n",
    "            return [] # 빈 리스트 반환\n",
    "\n",
    "        valid_entries = []\n",
    "        for entry in extracted_list:\n",
    "            if isinstance(entry, dict) and 'title' in entry and 'page' in entry:\n",
    "                try:\n",
    "                    entry['page'] = int(entry['page'])\n",
    "                    entry['is_requirement_related'] = bool(entry.get('is_requirement_related', False)) # 명확히 불리언으로\n",
    "                    valid_entries.append(entry)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: 페이지 번호 '{entry.get('page')}'를 정수로 변환할 수 없습니다. 항목 건너뜀: {entry.get('title')}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"경고: 필수 키(title, page)가 누락된 항목입니다. 건너뜀: {entry}\")\n",
    "\n",
    "        return valid_entries\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 목차 파싱 응답 JSON 파싱 오류: {e}. 응답 미리보기: {llm_response_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생 (목차 파싱): {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 새로운 헬퍼 함수들 ---\n",
    "def extract_text_for_pages(full_text_with_pages, start_page_num, end_page_num):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 특정 페이지 범위의 텍스트만 추출합니다.\n",
    "    페이지 마커 '---PAGE_START_N---'를 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 페이지 범위 유효성 검사 (end_page_num이 start_page_num보다 작을 수 없음)\n",
    "    if end_page_num < start_page_num:\n",
    "        # print(f\"경고: 끝 페이지({end_page_num})가 시작 페이지({start_page_num})보다 작습니다. 빈 텍스트를 반환합니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    # 패턴 구성: 시작 페이지부터 (끝 페이지 + 1) 직전까지 모든 내용을 포함\n",
    "    # re.escape를 사용하여 페이지 마커의 특수 문자를 이스케이프할 필요는 여기서는 없음\n",
    "    # DOTALL 플래그를 사용하여 \\n도 .에 매치되도록 함\n",
    "\n",
    "    # 시작점 찾기\n",
    "    start_marker = f\"---PAGE_START_{start_page_num}---\"\n",
    "    start_match = re.search(re.escape(start_marker), full_text_with_pages) # 마커 자체를 찾아야 함\n",
    "\n",
    "    if not start_match:\n",
    "        # print(f\"경고: 시작 마커 '{start_marker}'를 찾을 수 없습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    text_from_start_page = full_text_with_pages[start_match.start():]\n",
    "\n",
    "    # 끝점 찾기 (다음 페이지 마커 ---PAGE_START_{end_page_num + 1}---)\n",
    "    # end_page_num이 문서의 마지막 페이지일 수도 있으므로, end_page_num + 1 마커가 없을 수 있음\n",
    "    end_marker_exclusive = f\"---PAGE_START_{end_page_num + 1}---\"\n",
    "    end_match = re.search(re.escape(end_marker_exclusive), text_from_start_page)\n",
    "\n",
    "    if end_match:\n",
    "        return text_from_start_page[:end_match.start()]\n",
    "    else:\n",
    "        # end_page_num + 1 마커를 찾지 못하면, start_page_num부터 문서 끝까지 반환 (또는 start_page_num ~ end_page_num의 마지막 내용까지)\n",
    "        # 이 경우는 end_page_num이 마지막 페이지이거나, 그 이후 페이지 마커가 없는 경우.\n",
    "        # 좀 더 정확하게 하려면, end_page_num까지의 모든 내용을 가져와야 함.\n",
    "        # 그러나 페이지 마커 구조상, end_page_num의 내용은 end_page_num+1 마커 전까지임.\n",
    "        # 따라서 end_match가 없으면 text_from_start_page 전체가 해당 범위임.\n",
    "        return text_from_start_page\n",
    "\n",
    "\n",
    "def get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages):\n",
    "    \"\"\"\n",
    "    LLM으로 파싱된 목차에서 '상세 요구사항' 및 '보안 요구사항' 관련 섹션 정보를 추출합니다.\n",
    "    \"\"\"\n",
    "    target_sections = []\n",
    "\n",
    "    # 페이지 번호 기준으로 목차 정렬 (LLM이 순서대로 안 줄 수도 있으므로)\n",
    "    sorted_toc = sorted(parsed_toc_entries, key=lambda x: x.get('page', 0))\n",
    "\n",
    "    # 주요 키워드 - 사용자가 제공한 PDF 목차 기반\n",
    "    # \"III. 제안요청 내용\" 안에 \"3. 상세 요구사항\"이 있으므로, \"상세 요구사항\"을 찾는 것이 더 정확함.\n",
    "    keywords_to_find = {\n",
    "        \"상세 요구사항\": {\"min_pages\": 5}, # 최소한 이정도는 될 것이라는 기대\n",
    "        \"보안 요구사항 별표\": {\"min_pages\": 1} # 별표는 짧을 수도 있음\n",
    "        # 필요시 다른 주요 섹션 키워드 추가 가능\n",
    "    }\n",
    "\n",
    "    for i, entry in enumerate(sorted_toc):\n",
    "        entry_title = entry.get('title', '').strip()\n",
    "        entry_page = entry.get('page', 0)\n",
    "\n",
    "        for keyword, props in keywords_to_find.items():\n",
    "            if keyword in entry_title:\n",
    "                start_page = entry_page\n",
    "                end_page = total_pages # 기본값: 문서 끝까지\n",
    "\n",
    "                # 다음 목차 항목의 시작 페이지 - 1을 현재 섹션의 끝 페이지로 설정\n",
    "                # 단, 다음 항목이 현재 항목과 같은 페이지에서 시작하면 안됨 (하위 항목일 수 있으므로)\n",
    "                # 좀 더 정교한 로직: 다음 '주요' 항목을 찾아야 함.\n",
    "                # 여기서는 일단 다음 항목의 시작 페이지를 사용.\n",
    "                # 만약 다음 항목이 현재 항목의 하위 항목처럼 보이면 (예: \"3. 상세 요구사항\" 다음 \"3.1 기능 요구사항\")\n",
    "                # 그 하위 항목의 범위를 포함하도록 확장하거나, 아니면 정말 다음 *다른* 주요 섹션까지 봐야 함.\n",
    "                # 현재 LLM 프롬프트는 is_requirement_related로 판단하므로, 이를 우선적으로 신뢰.\n",
    "\n",
    "                # 다음 'is_requirement_related=False'인 섹션 또는 다음 주요 섹션(로마숫자/대문자 알파벳 등)을 찾아 end_page 설정\n",
    "                # 또는 단순히 다음 목차 항목의 시작 페이지 - 1 로 설정\n",
    "                next_major_section_page = total_pages + 1 # 충분히 큰 값\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page : # 현재 섹션 이후의 페이지만 고려\n",
    "                        # 여기서 '주요 섹션'을 판단하는 기준이 필요함 (예: 로마 숫자, 대문자 번호 등)\n",
    "                        # 또는 is_requirement_related=False 인 첫번째 섹션\n",
    "                        # 또는 단순히 다음 목차 항목\n",
    "                        next_major_section_page = next_entry_page\n",
    "                        break\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page -1)\n",
    "\n",
    "                # 시작 페이지와 끝 페이지 유효성 확보\n",
    "                if end_page < start_page:\n",
    "                    end_page = start_page\n",
    "\n",
    "                # 페이지 수가 너무 적으면 해당 섹션 전체를 포함 (예: 11페이지로 나왔는데 실제로는 62까지일 수 있음)\n",
    "                # 이 부분은 heuristic이므로 주의. 더 좋은 방법은 LLM에게 섹션의 끝을 명확히 묻는 것.\n",
    "                # 여기서는 min_pages 이상은 되어야 유의미하다고 가정.\n",
    "                # if (end_page - start_page + 1) < props.get(\"min_pages\", 1) and (start_page + props.get(\"min_pages\", 1) -1) <= total_pages :\n",
    "                #     pass # end_page = start_page + props.get(\"min_pages\", 1) -1 # 최소 페이지 강제는 위험할 수 있음\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry_title,\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 파싱 목차 기반: '{entry_title}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "                # 찾은 키워드는 중복 추가 방지 (더 구체적인 항목이 먼저 찾아지도록 keywords_to_find 순서 중요)\n",
    "                break\n",
    "\n",
    "    # 만약 아무것도 못찾았지만, is_requirement_related=True 인 항목들이 있다면 그것들을 사용\n",
    "    if not target_sections:\n",
    "        print(\"키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\")\n",
    "        for i, entry in enumerate(sorted_toc):\n",
    "            if entry.get('is_requirement_related'):\n",
    "                start_page = entry.get('page',0)\n",
    "                end_page = total_pages\n",
    "                # 위와 동일한 로직으로 end_page 계산\n",
    "                next_major_section_page = total_pages + 1\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page:\n",
    "                        if not next_entry.get('is_requirement_related', False): # 다음 주요 섹션이 요구사항 관련이 아니면\n",
    "                            next_major_section_page = next_entry_page\n",
    "                            break\n",
    "                        # 또는 다음 항목이 현재 항목보다 상위 레벨이면 (예: \"3.1\" 다음 \"4.\")\n",
    "                        # 이 부분은 제목의 번호 체계를 분석해야 해서 복잡함. LLM의 is_requirement_related를 신뢰.\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page - 1)\n",
    "                if end_page < start_page: end_page = start_page\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry.get('title', '요구사항 관련 섹션'),\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 'is_requirement_related' 플래그 기반: '{entry.get('title')}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "\n",
    "    # 중복 제거 및 병합 (예: \"III. 제안요청 내용\"과 그 하위 \"3. 상세 요구사항\"이 모두 선택된 경우)\n",
    "    # 여기서는 단순화를 위해 중복된 페이지 범위가 있다면 가장 포괄적인 것을 선택하거나,\n",
    "    # 또는 가장 구체적인 \"상세 요구사항\"을 우선. 지금은 일단 나온대로 반환.\n",
    "    # 더 나은 방법은, '상세 요구사항'이 나왔으면 그게 더 우선순위가 높다고 처리.\n",
    "\n",
    "    if not target_sections:\n",
    "        print(\"경고: LLM 파싱 목차에서 주요 요구사항 섹션을 찾지 못했습니다. 전체 문서를 대상으로 할 수 있습니다.\")\n",
    "        return [{'title': '전체 문서 (목차 분석 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    return target_sections\n",
    "\n",
    "\n",
    "def get_toc_raw_text_from_full_text(full_text_with_pages, toc_page_numbers=[2,3]):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 지정된 목차 페이지들의 텍스트만 추출합니다.\n",
    "    \"\"\"\n",
    "    toc_texts = []\n",
    "    for page_num in toc_page_numbers:\n",
    "        # 페이지 마커를 찾아서 해당 페이지의 텍스트를 추출\n",
    "        # (end_page_num + 1) 마커를 찾아서 그 전까지의 내용을 가져옴\n",
    "        page_content = extract_text_for_pages(full_text_with_pages, page_num, page_num)\n",
    "        if page_content:\n",
    "            # 페이지 마커 제거 (이미 extract_text_for_pages가 마커 다음부터 가져오지만, 혹시 몰라서)\n",
    "            # 실제로는 페이지 마커 이후의 텍스트만 필요.\n",
    "            # `extract_text_for_pages`는 마커를 포함해서 반환할 수 있으므로, 마커 이후 내용만 사용.\n",
    "            marker = f\"---PAGE_START_{page_num}---\\n\"\n",
    "            if page_content.startswith(marker):\n",
    "                toc_texts.append(page_content[len(marker):])\n",
    "            else: # 마커가 없는 경우 (예상치 않음)\n",
    "                toc_texts.append(page_content)\n",
    "        else:\n",
    "            print(f\"경고: 목차 페이지로 지정된 {page_num} 페이지에서 텍스트를 찾을 수 없습니다.\")\n",
    "\n",
    "    if not toc_texts:\n",
    "        return None\n",
    "    return \"\\n\".join(toc_texts)\n",
    "\n",
    "# --- 메인 실행 블록 ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"./docs/제주은행 모바일뱅킹 재구축사업.pdf\" # 실제 파일 경로\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"오류: PDF 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "        exit()\n",
    "\n",
    "    print(\"1. PDF 전체 텍스트 추출 중...\")\n",
    "    full_document_text, total_pages = extract_text_with_page_info(pdf_file_path)\n",
    "    if not full_document_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다 ({pdf_file_path}).\")\n",
    "        exit()\n",
    "    print(f\"   PDF 전체 텍스트 추출 완료. 총 {total_pages} 페이지, 전체 텍스트 길이: {len(full_document_text)}자.\")\n",
    "\n",
    "    print(\"\\n2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\")\n",
    "    # 사용자 PDF 분석 결과 PAGE 2, 3에 목차가 있음\n",
    "    toc_raw_text = get_toc_raw_text_from_full_text(full_document_text, toc_page_numbers=[2, 3])\n",
    "\n",
    "    target_sections_for_extraction = []\n",
    "    if toc_raw_text:\n",
    "        print(f\"   목차 원문 텍스트 추출 완료 (길이: {len(toc_raw_text)}자).\")\n",
    "        print(\"\\n3. LLM을 사용하여 목차(ToC) 파싱 중...\")\n",
    "        parsed_toc_entries = parse_toc_with_llm(toc_raw_text, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "        if parsed_toc_entries:\n",
    "            print(f\"   LLM 목차 파싱 완료. {len(parsed_toc_entries)}개의 목차 항목 식별.\")\n",
    "            print(\"\\n4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\")\n",
    "            target_sections_for_extraction = get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages)\n",
    "        else:\n",
    "            print(\"   LLM 목차 파싱 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "            target_sections_for_extraction = [{'title': '전체 문서 (LLM 목차 파싱 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "    else:\n",
    "        print(\"   목차 원문 텍스트 추출 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "        target_sections_for_extraction = [{'title': '전체 문서 (목차 원문 추출 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    if not target_sections_for_extraction: # 만약을 위해 한번 더 체크\n",
    "        print(\"오류: 분석할 대상 섹션을 정의하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n5. 식별된 주요 섹션으로부터 텍스트 결합 중...\")\n",
    "    all_requirements_related_text_parts = []\n",
    "    for section_info in target_sections_for_extraction:\n",
    "        print(f\"   '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']}) 텍스트 추출 시도...\")\n",
    "        section_text = extract_text_for_pages(full_document_text, section_info['start_page'], section_info['end_page'])\n",
    "        if section_text:\n",
    "            all_requirements_related_text_parts.append(section_text)\n",
    "            print(f\"       '{section_info['title']}' 섹션 텍스트 추출 완료 (길이: {len(section_text)}자).\")\n",
    "        else:\n",
    "            print(f\"       경고: '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']})에서 텍스트를 추출하지 못했습니다.\")\n",
    "\n",
    "    if not all_requirements_related_text_parts:\n",
    "        print(\"오류: 주요 요구사항 섹션에서 텍스트를 전혀 추출하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    combined_requirements_text = \"\\n\\n\".join(all_requirements_related_text_parts) # 섹션 간 구분을 위해 두 줄바꿈\n",
    "    print(f\"   주요 섹션 텍스트 결합 완료. 총 길이: {len(combined_requirements_text)}자.\")\n",
    "\n",
    "    print(\"\\n6. 결합된 텍스트 초기 분할 중...\")\n",
    "    # chunk_size는 LLM의 context window와 한글 토큰 소모를 고려하여 설정\n",
    "    initial_chunks = initial_text_split(combined_requirements_text, chunk_size=3500, chunk_overlap=350)\n",
    "    print(f\"   총 {len(initial_chunks)}개의 초기 청크가 생성되었습니다.\")\n",
    "\n",
    "    if not initial_chunks:\n",
    "        print(\"오류: 텍스트 분할 결과 청크가 없습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\")\n",
    "    extracted_requirements = llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "    print(\"\\n8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\")\n",
    "    # (기존 스크립트의 후처리 로직 사용 또는 필요시 개선)\n",
    "    unique_requirements_by_id = {}\n",
    "    processed_requirements = []\n",
    "    if extracted_requirements:\n",
    "        for req in extracted_requirements:\n",
    "            req_id = req.get('id', str(uuid.uuid4())) # ID가 없다면 UUID로 임시 ID\n",
    "            if req_id not in unique_requirements_by_id:\n",
    "                unique_requirements_by_id[req_id] = req\n",
    "            else:\n",
    "                # ID가 중복될 경우, 설명을 합치거나 페이지 정보를 합치는 등의 로직 추가 가능\n",
    "                # 여기서는 간단히 첫 번째 것만 유지하거나, 필요에 따라 업데이트\n",
    "                # 예: 페이지 정보 병합\n",
    "                existing_req = unique_requirements_by_id[req_id]\n",
    "                new_pages = req.get('source_pages', [])\n",
    "                if new_pages:\n",
    "                    existing_req_pages = existing_req.get('source_pages', [])\n",
    "                    existing_req['source_pages'] = sorted(list(set(existing_req_pages + new_pages)))\n",
    "                print(f\"중복 ID '{req_id}' 감지. 정보 업데이트 시도.\")\n",
    "        processed_requirements = list(unique_requirements_by_id.values())\n",
    "    else:\n",
    "        print(\"   추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    # 최종 결과 출력 또는 저장\n",
    "    print(f\"\\n--- 최종 추출된 고유 요구사항 수: {len(processed_requirements)}개 ---\")\n",
    "    if processed_requirements:\n",
    "        print(\"\\n--- 추출된 요구사항 미리보기 (상위 3개) ---\")\n",
    "        for i, req_item in enumerate(processed_requirements[:3]): # 'req' 변수명 충돌 피하기 위해 'req_item'으로 변경\n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        output_filename = \"extracted_requirements_final.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"\\n추출된 요구사항이 '{output_filename}' 파일에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"최종적으로 추출된 요구사항이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 버전2(개발자 관점에서 출력 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RFP 요구사항 추출 전문가 시스템 (개발자 관점) 시작 (입력 파일: ./docs/제주은행 모바일뱅킹 재구축사업.pdf) ---\n",
      "1. PDF 텍스트 추출 완료: 총 54 페이지, 전체 텍스트 길이 57553자.\n",
      "2. 문서 청킹 완료: 총 19개 청크 생성 (overlap: 800).\n",
      "\n",
      "--- 패스 1: 개발자 관점의 포괄적 요구사항 식별 시작 ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 1/19 (원본 페이지: [1, 2]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 2/19 (원본 페이지: [3]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 3/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 4/19 (원본 페이지: [4]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 5/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 6/19 (원본 페이지: [5, 6, 7]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 7/19 (원본 페이지: [8, 9]) ---\n",
      "LLM 응답 JSON 파싱 오류: Unterminated string starting at: line 296 column 28 (char 11712). 응답: {\n",
      "    \"requirements_extracted\": [\n",
      "        {\n",
      "            \"id\": \"FUNC-001\",\n",
      "            \"type\": \"기능적\",\n",
      "            \"description\": \"앱 구동 및 로그인, 조회, 이체에 대한 속도 개선을 포함한 기능을 제공해야 한다.\",\n",
      "            \"acceptance_criteria\": \"앱 구동, 로그인, 조회, 이체 시 평균 응답 시간이 X초 이내여야 한다.\",\n",
      "            \"priority\": \"필수\",\n",
      "            \"responsible_module\": \"전체 시스템\",\n",
      "            \"source_pages\": [8, 9],\n",
      "            \"raw_text_snippet\": \"앱 구동 및 로그인, 조회, 이체에 대한 속도 개선\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"FUNC-002\",\n",
      "            \"type\"...\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 8/19 (원본 페이지: [10, 11, 12, 13, 14]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 9/19 (원본 페이지: [15, 16, 17, 18]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 10/19 (원본 페이지: [19, 20, 21, 22]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 11/19 (원본 페이지: [22, 23, 24, 25, 26, 27]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 12/19 (원본 페이지: [27, 28, 29, 30, 31]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 13/19 (원본 페이지: [31, 32, 33, 34]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 14/19 (원본 페이지: [35, 36, 37]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 15/19 (원본 페이지: [38, 39, 40]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 16/19 (원본 페이지: [41, 42, 43]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 17/19 (원본 페이지: [44, 45, 46, 47, 48, 49]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 18/19 (원본 페이지: [48, 49, 50, 51, 52, 53]) ---\n",
      "--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 19/19 (원본 페이지: [54]) ---\n",
      "--- 전문가 패스 1 (개발자 관점) 완료: 총 123개의 요구사항 후보 식별 ---\n",
      "\n",
      "--- 패스 2: 개발자 관점의 추가/보완 요구사항 추출 시작 ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 1/19 (원본 페이지: [1, 2]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 2/19 (원본 페이지: [3]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 3/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 4/19 (원본 페이지: [4]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 5/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 6/19 (원본 페이지: [5, 6, 7]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 7/19 (원본 페이지: [8, 9]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 8/19 (원본 페이지: [10, 11, 12, 13, 14]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 9/19 (원본 페이지: [15, 16, 17, 18]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 10/19 (원본 페이지: [19, 20, 21, 22]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 11/19 (원본 페이지: [22, 23, 24, 25, 26, 27]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 12/19 (원본 페이지: [27, 28, 29, 30, 31]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 13/19 (원본 페이지: [31, 32, 33, 34]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 14/19 (원본 페이지: [35, 36, 37]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 15/19 (원본 페이지: [38, 39, 40]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 16/19 (원본 페이지: [41, 42, 43]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 17/19 (원본 페이지: [44, 45, 46, 47, 48, 49]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 18/19 (원본 페이지: [48, 49, 50, 51, 52, 53]) ---\n",
      "--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 19/19 (원본 페이지: [54]) ---\n",
      "--- 전문가 패스 2 (개발자 관점) 완료: 54개의 추가/보완 요구사항 식별 ---\n",
      "\n",
      "모든 패스에서 총 177개의 요구사항 후보 수집 (중복 포함).\n",
      "\n",
      "--- 후처리 작업 시작 (제외할 타입: ['기타', '산출물', '정책준수', '프로젝트 지원']) ---\n",
      "\n",
      "--- 전문가 후처리 시작: 초기 177개 항목 ---\n",
      "    타입 기반 필터링: '기타, 산출물, 정책준수, 프로젝트 지원' 타입 제외 후 177개 항목 (이전: 177개)\n",
      "    내용 기반 중복 발견. 키: '시스템은차세대아키텍처표준을준수해야한다._6.6.차세대아키텍처표준준수__p3...'. 기존ID: 'TECH-001', 새ID후보: 'NFR-002'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '재해복구시스템은운영시스템의최소50%성능에준하도록용량설계되어야한다._재해복구시스템은운영시스템...'. 기존ID: 'NFR-002', 새ID후보: 'NFR-004'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '개발/테스트시스템은운영시스템의최소30%성능에준하도록용량설계되어야한다._개발/테스트시스템은운...'. 기존ID: 'NFR-003', 새ID후보: 'NFR-005'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '대량/대용량거래처리에따른응답속도보장및해당거래통제방안을제시해야한다._대량/대용량거래처리에따른...'. 기존ID: 'NFR-004', 새ID후보: 'NFR-006'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '데이터이행시고객정보에대한보안성확보방안을제시해야한다._데이터이행시고객정보에대한보안성확보방안제...'. 기존ID: 'DATA-001', 새ID후보: 'NFR-008'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '제안관련문의는반드시e-mail을사용해야하며,전화또는구두로질의및응답한사항은법적효력을갖지못한다...'. 기존ID: 'TECH-003', 새ID후보: 'NFR-003'. 정보 병합.\n",
      "    내용 기반 중복 발견. 키: '제안서제출은인편접수에한하며,제출장소는제주특별자치도제주시연삼로5113층ict지원부앞이다._제...'. 기존ID: 'TECH-004', 새ID후보: 'NFR-004'. 정보 병합.\n",
      "    내용 기반 중복 제거 후: 170개 항목\n",
      "--- 전문가 후처리 완료: 최종 170개 요구사항 ---\n",
      "\n",
      "--- 최종 추출된 고유 요구사항: 170개 ---\n",
      "\n",
      "--- 상위 5개 요구사항 미리보기 ---\n",
      "{\n",
      "  \"id\": \"DATA-001\",\n",
      "  \"type\": \"데이터\",\n",
      "  \"description\": \"JBANK 시스템은 데이터 이행을 수행해야 한다.\",\n",
      "  \"acceptance_criteria\": \"모든 기존 데이터가 새로운 시스템으로 정확하게 이전되어야 하며, 데이터 무결성이 유지되어야 한다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"데이터 마이그레이션 모듈\",\n",
      "  \"source_pages\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"데이터 이행\"\n",
      "}\n",
      "--------------------\n",
      "{\n",
      "  \"id\": \"FUNC-001\",\n",
      "  \"type\": \"기능적\",\n",
      "  \"description\": \"JBANK 시스템은 UI/UX 표준 체계를 마련해야 한다.\",\n",
      "  \"acceptance_criteria\": \"UI/UX 표준 체계가 문서화되어 있으며, 모든 UI 컴포넌트가 이 표준을 준수해야 한다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"UI/UX 모듈\",\n",
      "  \"source_pages\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"JBANK 시스템 UI/UX 표준 체계 마련\"\n",
      "}\n",
      "--------------------\n",
      "{\n",
      "  \"id\": \"FUNC-002\",\n",
      "  \"type\": \"기능적\",\n",
      "  \"description\": \"JBANK 시스템은 GRC(거버넌스, 리스크 관리, 컴플라이언스) 체계를 마련해야 한다.\",\n",
      "  \"acceptance_criteria\": \"GRC 체계가 문서화되어 있으며, 시스템 내 모든 관련 프로세스가 이 체계를 준수해야 한다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"GRC 모듈\",\n",
      "  \"source_pages\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"JBANK 시스템 GRC 체계 마련\"\n",
      "}\n",
      "--------------------\n",
      "{\n",
      "  \"id\": \"OPS-001\",\n",
      "  \"type\": \"운영환경\",\n",
      "  \"description\": \"JBANK 시스템은 새로운 인프라를 도입해야 한다.\",\n",
      "  \"acceptance_criteria\": \"새로운 인프라가 설치 및 구성되어 있으며, 시스템이 정상적으로 운영되어야 한다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"인프라 모듈\",\n",
      "  \"source_pages\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"JBANK 시스템 인프라 도입\"\n",
      "}\n",
      "--------------------\n",
      "{\n",
      "  \"id\": \"OPS-002\",\n",
      "  \"type\": \"운영환경\",\n",
      "  \"description\": \"JBANK 시스템은 DR(재해 복구) 환경을 구축해야 한다.\",\n",
      "  \"acceptance_criteria\": \"DR 환경이 구축되어 있으며, 주기적인 DR 테스트를 통해 복구 가능성을 검증해야 한다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"DR 모듈\",\n",
      "  \"source_pages\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"JBANK 시스템 DR 구축\"\n",
      "}\n",
      "\n",
      "최종 추출된 요구사항이 'extracted_requirements_developer_focused_v5_dev_focused.json' 파일에 성공적으로 저장되었습니다.\n",
      "--- RFP 요구사항 추출 전문가 시스템 (개발자 관점) 종료 ---\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 ---\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "# === 1. 전처리 함수 ===\n",
    "def expert_extract_text_with_pages(pdf_path: str) -> Tuple[str, int]:\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text(\"text\", sort=True) \n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def expert_create_chunks(full_text: str, chunk_size: int = 4000, chunk_overlap: int = 500) -> List[Dict[str, Any]]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\\n\", \"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    docs_langchain = text_splitter.create_documents([full_text])\n",
    "    \n",
    "    chunks = []\n",
    "    for i, doc_lc in enumerate(docs_langchain):\n",
    "        chunk_text = doc_lc.page_content\n",
    "        page_numbers = sorted(list(set(int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text))))\n",
    "        chunks.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk_text,\n",
    "            \"source_pages_in_chunk\": page_numbers\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# === 2. LLM 호출 헬퍼 함수 ===\n",
    "def expert_llm_call(system_prompt: str, user_prompt: str, client_instance: OpenAI, model: str, expect_single_object: bool = False) -> Union[List[Dict[str, Any]], Dict[str, Any], None]:\n",
    "    llm_response_content = \"\"\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=4000 \n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        parsed_output = json.loads(llm_response_content)\n",
    "\n",
    "        if expect_single_object:\n",
    "            if isinstance(parsed_output, dict):\n",
    "                return parsed_output\n",
    "            else:\n",
    "                if isinstance(parsed_output, list) and len(parsed_output) == 1 and isinstance(parsed_output[0], dict):\n",
    "                    print(f\"정보: 단일 JSON 객체를 예상했으나 리스트로 감싸인 객체를 받았습니다. 첫 번째 항목 사용. 내용: {str(parsed_output[0])[:100]}\")\n",
    "                    return parsed_output[0]\n",
    "                print(f\"경고: 단일 JSON 객체를 예상했으나 다른 타입/구조를 받았습니다: {type(parsed_output)}. 내용: {llm_response_content[:200]}\")\n",
    "                return None \n",
    "        else: \n",
    "            if isinstance(parsed_output, dict):\n",
    "                # LLM이 {\"some_key\": [...]} 형태로 반환하는 것을 처리\n",
    "                for key, value in parsed_output.items(): # 첫 번째 키의 리스트 값을 사용하도록 단순화 또는 특정 키 지정\n",
    "                    if isinstance(value, list):\n",
    "                        if all(isinstance(item, dict) for item in value):\n",
    "                            return value\n",
    "                        else:\n",
    "                            print(f\"경고: LLM 반환 객체 내 리스트 ('{key}')에 딕셔너리가 아닌 항목 포함.\")\n",
    "                            return [item for item in value if isinstance(item, dict)] # 딕셔너리만 필터링\n",
    "                print(f\"경고: LLM이 JSON 객체를 반환했으나, 내부에 예상된 리스트를 찾지 못했습니다. 키: {list(parsed_output.keys())}, 내용: {str(parsed_output)[:200]}\")\n",
    "                return []\n",
    "            elif isinstance(parsed_output, list):\n",
    "                if all(isinstance(item, dict) for item in parsed_output):\n",
    "                    return parsed_output\n",
    "                else:\n",
    "                    print(f\"경고: LLM이 리스트를 반환했으나, 일부 항목이 딕셔너리가 아닙니다.\")\n",
    "                    return [item for item in parsed_output if isinstance(item, dict)]\n",
    "            else:\n",
    "                print(f\"경고: LLM으로부터 예상치 못한 JSON 루트 형식 응답 (리스트 또는 객체가 아님): {llm_response_content[:200]}...\")\n",
    "                return []\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        return None if expect_single_object else []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생: {type(e).__name__} {e}\")\n",
    "        if llm_response_content:\n",
    "            print(f\"오류 발생 시 LLM 응답 일부: {llm_response_content[:500]}...\")\n",
    "        return None if expect_single_object else []\n",
    "\n",
    "# === 3. 패스별 시스템 프롬프트 정의 (개발자 관점 반영) ===\n",
    "def get_expert_system_prompt(pass_number=1):\n",
    "    # --- 공통 JSON 구조 및 기본 지침 ---\n",
    "    common_guidance = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 **시스템 개발자 관점에서 직접적으로 필요한 요구사항**을 추출하고 구조화하는 전문가입니다.\n",
    "    추출된 요구사항은 시스템의 설계, 개발, 테스트, 배포, 운영에 직접적으로 활용될 수 있어야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "    -   **id**: 고유 식별자 (예: \"FUNC-001\", \"NFR-001\"). (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. 다음 중 선택: \"기능적\", \"비기능적\"(성능, 보안, 사용성, 안정성, 호환성 등 포함), \"데이터\", \"인터페이스\", \"기술적 제약\", \"운영환경\", \"테스트 조건\". (단순 행정절차, 일반 계약조건 등은 제외)\n",
    "    -   **description**: 개발자가 이해할 수 있도록 요구사항에 대한 명확하고 간결한 설명. 원본 텍스트의 핵심을 반영하되, 시스템의 행동, 속성, 제약 등을 명시.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 개발팀 또는 QA팀이 검증할 수 있는 구체적이고 측정 가능한 기준. 1~3개의 명확한 문장으로 서술. (예: \"[특정 입력] 시 시스템은 [예상 출력/행동]을 보여야 한다\", \"응답 시간은 평균 X초 이내여야 한다\", \"[특정 표준]을 준수해야 하며, [검증 방법]으로 확인\"). 추론이 매우 어려우면 \"구체적인 검증 방법은 세부 설계 시 정의\" 등으로 명시.\n",
    "    -   **priority**: 요구사항의 중요도. \"필수\", \"높음\", \"중간\", \"낮음\" 중 선택. 텍스트에 명시 없으면 \"필수\"로 간주.\n",
    "    -   **responsible_module**: 이 요구사항이 주로 구현되거나 영향을 미칠 시스템의 모듈 또는 구성요소. (예: \"인증 모듈\", \"데이터베이스 스키마\", \"API 게이트웨이\"). 추론 어려우면 \"전체 시스템\" 또는 \"미정\".\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트.\n",
    "    -   **raw_text_snippet**: 추출 근거가 된 핵심 원본 텍스트 조각.\n",
    "\n",
    "    응답은 JSON 배열 형태 (`{\"requirements_extracted\": [...]}` 또는 `{\"additional_requirements_extracted\": [...]}` 객체 내 배열)로 제공해야 합니다. 요구사항이 없다면 빈 배열 `[]`을 값으로 포함하여 반환하십시오.\n",
    "    **목차, 제안서 작성 요령, 업체 선정 기준, 일반적인 계약 조건 등 시스템의 기술적 구현과 직접 관련 없는 내용은 요구사항으로 추출하지 마십시오.**\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 패스 1: 개발자 관점의 포괄적 요구사항 식별 ---\n",
    "    system_prompt_pass1 = common_guidance + \"\"\"\n",
    "    **패스 1 중요 지침 (개발자 관점에서 포괄적 식별, 재현율 중시):**\n",
    "    1.  텍스트 전체에서 **개발자가 시스템을 구축하거나 기술적 결정을 내리는 데 필요한 모든 정보**를 요구사항 후보로 식별하십시오.\n",
    "    2.  명시적 기능 외에도, 시스템이 특정 기술을 사용해야 하거나(예: \"OS: AIX 7.2\"), 특정 표준을 따라야 하거나(예: \"금융보안원 가이드라인 준수\"), 특정 방식으로 데이터를 처리해야 하는(예: \"주요정보는 마스킹 처리 및 암호화하여 저장\") 모든 내용을 포함하십시오.\n",
    "    3.  **모호하거나 경계선에 있는 내용이라도, 개발자에게 영향을 줄 수 있다면 일단 후보로 포함**하고, `type`을 가장 적절하게 분류하십시오.\n",
    "    4.  **주요 식별 대상:**\n",
    "        a.  **시스템 기능:** 사용자와 시스템의 상호작용, 시스템이 수행해야 할 작업, 처리 로직 등.\n",
    "        b.  **데이터 처리:** 데이터 구조, 저장, 암호화, 마스킹, 이전, 백업/복구 관련 요건.\n",
    "        c.  **시스템 인터페이스:** 외부 시스템과의 연동 방식, API 명세, 프로토콜, 데이터 형식 등.\n",
    "        d.  **기술 스택 및 환경:** 사용해야 할 OS, DBMS, 프로그래밍 언어, 프레임워크, H/W 요구사항 또는 제약.\n",
    "        e.  **비기능적 특성:** 성능 목표(응답속도, 처리량), 보안 요건(인증, 권한, 취약점 조치, 암호화 표준), 가용성(업타임), 확장성, 사용성(특정 UI/UX 가이드라인이 있다면).\n",
    "        f.  **개발 및 테스트 관련 의무/조건:** 특정 개발 방법론 준수, 테스트 종류(단위, 통합, 성능 등) 수행 의무, 테스트 환경 구축, 소스코드 제출 등 개발팀이 직접 수행하거나 결과물에 영향을 주는 내용.\n",
    "    5.  `description`은 원본 내용을 바탕으로 개발자가 이해하기 쉽게 작성하고, `acceptance_criteria`는 가능한 테스트 가능한 형태로 추론하여 작성하십시오.\n",
    "\n",
    "    LLM 응답은 `{\"requirements_extracted\": [...]}` 형태의 JSON 객체여야 하며, `requirements_extracted` 키의 값이 실제 요구사항 객체들의 배열입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 패스 2: 개발자 관점에서 누락된 기술적/비기능적 요구사항 추가 탐색 ---\n",
    "    system_prompt_pass2 = common_guidance + \"\"\"\n",
    "    **패스 2 중요 지침 (개발자 관점에서 누락된 기술/비기능적 세부사항 집중 탐색):**\n",
    "    1.  이 텍스트는 이전 분석에서 일부 요구사항이 이미 추출되었을 수 있습니다. **이번에는 개발자에게 특히 중요한 기술적 세부사항, 비기능적 품질 속성, 또는 암묵적인 제약 조건 등 이전 패스에서 놓쳤을 가능성이 있는 요구사항에 집중**해주십시오.\n",
    "    2.  예를 들어, 특정 암호화 알고리즘 사용, 특정 버전의 라이브러리 호환성, 예외 처리 방식, 로깅 정책, 상세한 성능 KPI, 시스템 운영 및 유지보수 관련 기술 요건 등을 다시 한번 면밀히 검토하십시오.\n",
    "    3.  요구사항으로 판단되면, Pass 1과 동일한 상세 JSON 구조로 모든 필드를 채워주십시오. `description`과 `acceptance_criteria`를 최대한 구체적으로 작성하십시오.\n",
    "    \n",
    "    LLM 응답은 `{\"additional_requirements_extracted\": [...]}` 형태의 JSON 객체여야 하며, `additional_requirements_extracted` 키의 값이 실제 요구사항 객체들의 배열입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    if pass_number == 1:\n",
    "        return system_prompt_pass1\n",
    "    elif pass_number == 2:\n",
    "        return system_prompt_pass2\n",
    "    else: \n",
    "        return system_prompt_pass1 # 기본값\n",
    "\n",
    "\n",
    "# === 4. 패스 1 실행 함수 ===\n",
    "def expert_pass1_extract_developer_reqs(chunks: List[Dict[str, Any]], client_instance: OpenAI, model: str) -> List[Dict[str, Any]]:\n",
    "    system_prompt = get_expert_system_prompt(pass_number=1)\n",
    "    all_extracted_reqs = []\n",
    "    for i, chunk_data in enumerate(chunks):\n",
    "        chunk_text = chunk_data[\"text\"]\n",
    "        chunk_pages = chunk_data[\"source_pages_in_chunk\"]\n",
    "        print(f\"--- 전문가 패스 1 (개발자 관점): 요구사항 식별 중 - 청크 {i+1}/{len(chunks)} (원본 페이지: {chunk_pages}) ---\")\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        시스템 프롬프트의 '개발자 관점' 지침에 따라, 다음 RFP 문서 일부 텍스트 청크에서 해당하는 모든 시스템 요구사항을 JSON 형식으로 추출해 주십시오.\n",
    "        `source_pages` 필드에는 이 청크에 해당하는 원본 페이지 번호인 {chunk_pages}를 사용하십시오.\n",
    "\n",
    "        --- 텍스트 청크 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        extracted_list = expert_llm_call(system_prompt, user_prompt, client_instance, model, expect_single_object=False) \n",
    "        \n",
    "        if isinstance(extracted_list, list):\n",
    "            for req_idx, req in enumerate(extracted_list):\n",
    "                if isinstance(req, dict) and \"description\" in req and \"type\" in req:\n",
    "                    req[\"pass_info\"] = {\"pass\": 1, \"chunk_id\": chunk_data[\"chunk_id\"], \"item_index_in_chunk\": req_idx}\n",
    "                    if not req.get(\"source_pages\") or not isinstance(req.get(\"source_pages\"), list) :\n",
    "                        req[\"source_pages\"] = chunk_pages \n",
    "                    all_extracted_reqs.append(req)\n",
    "                else:\n",
    "                    print(f\"경고 (패스1, 청크 {i+1}): 항목에 주요 키 또는 올바른 타입 누락. 항목: {str(req)[:100]}\")\n",
    "        else:\n",
    "            print(f\"경고 (패스1, 청크 {i+1}): expert_llm_call로부터 리스트가 아닌 결과 반환. 결과: {str(extracted_list)[:100]}\")\n",
    "\n",
    "    print(f\"--- 전문가 패스 1 (개발자 관점) 완료: 총 {len(all_extracted_reqs)}개의 요구사항 후보 식별 ---\")\n",
    "    return all_extracted_reqs\n",
    "\n",
    "# === 5. 패스 2 실행 함수 ===\n",
    "def expert_pass2_extract_missed_developer_reqs(\n",
    "    chunks: List[Dict[str, Any]], \n",
    "    client_instance: OpenAI, \n",
    "    model: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    system_prompt = get_expert_system_prompt(pass_number=2)\n",
    "    additional_requirements = []\n",
    "    for i, chunk_data in enumerate(chunks): \n",
    "        chunk_text = chunk_data[\"text\"]\n",
    "        chunk_pages = chunk_data[\"source_pages_in_chunk\"]\n",
    "        print(f\"--- 전문가 패스 2 (개발자 관점): 추가/보완 추출 중 - 청크 {i+1}/{len(chunks)} (원본 페이지: {chunk_pages}) ---\")\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부 텍스트 청크입니다. 이전에 이미 한 번 검토되었을 수 있습니다.\n",
    "        시스템 프롬프트의 '개발자 관점' 지침에 따라, 이 청크에서 **이전에 놓쳤을 가능성이 있는 추가적인 시스템 요구사항** (특히 기술적 세부사항, 비기능적 특성, 제약조건)을 찾아내어 요청된 JSON 형식으로 응답해주십시오.\n",
    "        `source_pages` 필드에는 이 청크에 해당하는 원본 페이지 번호인 {chunk_pages}를 사용하십시오.\n",
    "\n",
    "        --- 텍스트 청크 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        newly_found_reqs_list = expert_llm_call(system_prompt, user_prompt, client_instance, model, expect_single_object=False)\n",
    "\n",
    "        if isinstance(newly_found_reqs_list, list):\n",
    "            for req_idx, req in enumerate(newly_found_reqs_list):\n",
    "                if isinstance(req, dict) and \"description\" in req and \"type\" in req:\n",
    "                    req[\"pass_info\"] = {\"pass\": 2, \"chunk_id\": chunk_data[\"chunk_id\"], \"item_index_in_chunk\": req_idx}\n",
    "                    if not req.get(\"source_pages\") or not isinstance(req.get(\"source_pages\"), list) :\n",
    "                        req[\"source_pages\"] = chunk_pages\n",
    "                    additional_requirements.append(req)\n",
    "                else:\n",
    "                    print(f\"경고 (패스2, 청크 {i+1}): 항목에 주요 키 또는 올바른 타입 누락. 항목: {str(req)[:100]}\")\n",
    "        else:\n",
    "             print(f\"경고 (패스2, 청크 {i+1}): expert_llm_call로부터 리스트가 아닌 결과 반환. 결과: {str(newly_found_reqs_list)[:100]}\")\n",
    "\n",
    "    print(f\"--- 전문가 패스 2 (개발자 관점) 완료: {len(additional_requirements)}개의 추가/보완 요구사항 식별 ---\")\n",
    "    return additional_requirements\n",
    "\n",
    "\n",
    "# === 6. 후처리 함수 ===\n",
    "def expert_post_process_requirements(requirements: List[Dict[str, Any]], exclude_types: List[str] = None) -> List[Dict[str, Any]]:\n",
    "    if exclude_types is None:\n",
    "        exclude_types = [] \n",
    "    \n",
    "    print(f\"\\n--- 전문가 후처리 시작: 초기 {len(requirements)}개 항목 ---\")\n",
    "    if not requirements:\n",
    "        return []\n",
    "\n",
    "    if exclude_types:\n",
    "        initial_count_before_type_filter = len(requirements)\n",
    "        requirements = [req for req in requirements if req.get(\"type\") not in exclude_types]\n",
    "        print(f\"    타입 기반 필터링: '{', '.join(exclude_types)}' 타입 제외 후 {len(requirements)}개 항목 (이전: {initial_count_before_type_filter}개)\")\n",
    "\n",
    "    unique_reqs_by_content = {}\n",
    "    for req in requirements: \n",
    "        desc_key = \"\".join(req.get('description', '').strip().lower().split())[:80]\n",
    "        snippet_key = \"\".join(req.get('raw_text_snippet', '').strip().lower().split())[:80]\n",
    "        page_key_list_integers = sorted(list(set(int(p) for p in req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit())))\n",
    "        page_key = \"_p\" + str(page_key_list_integers[0]) if page_key_list_integers else \"_p0\"\n",
    "        content_key = f\"{desc_key}_{snippet_key}_{page_key}\"\n",
    "\n",
    "        original_req_id_info = req.get('id', '') \n",
    "\n",
    "        if content_key not in unique_reqs_by_content:\n",
    "            req[\"temp_merged_ids_log\"] = [str(original_req_id_info)] \n",
    "            unique_reqs_by_content[content_key] = req\n",
    "        else:\n",
    "            existing_req = unique_reqs_by_content[content_key]\n",
    "            print(f\"    내용 기반 중복 발견. 키: '{content_key[:50]}...'. 기존ID: '{existing_req.get('id', 'N/A')}', 새ID후보: '{original_req_id_info}'. 정보 병합.\")\n",
    "            \n",
    "            new_pages_int = [int(p) for p in req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit()]\n",
    "            existing_pages_int = [int(p) for p in existing_req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit()]\n",
    "            existing_req['source_pages'] = sorted(list(set(existing_pages_int + new_pages_int)))\n",
    "\n",
    "            if len(req.get('description', '')) > len(existing_req.get('description', '')):\n",
    "                existing_req['description'] = req.get('description')\n",
    "            if len(req.get('raw_text_snippet', '')) > len(existing_req.get('raw_text_snippet', '')):\n",
    "                 existing_req['raw_text_snippet'] = req.get('raw_text_snippet')\n",
    "            \n",
    "            ac_placeholder_values = ['추후 분석 필요', '해당하는 경우 명시', '해당 없음', '세부 협의', '구체적인 검증 방법은 세부 설계 시 정의']\n",
    "            if req.get('acceptance_criteria') not in ac_placeholder_values and \\\n",
    "               existing_req.get('acceptance_criteria', ac_placeholder_values[0]) in ac_placeholder_values:\n",
    "                existing_req['acceptance_criteria'] = req.get('acceptance_criteria')\n",
    "            \n",
    "            current_pass_info = req.get('pass_info', {})\n",
    "            existing_pass_info = existing_req.get('pass_info', {})\n",
    "            if current_pass_info.get('pass', 0) > existing_pass_info.get('pass', 0):\n",
    "                existing_req['pass_info'] = current_pass_info\n",
    "                if req.get('type') != '기타' or existing_req.get('type') == '기타': existing_req['type'] = req.get('type')\n",
    "\n",
    "            if 'temp_merged_ids_log' in existing_req and isinstance(existing_req['temp_merged_ids_log'], list):\n",
    "                 existing_req['temp_merged_ids_log'].append(str(original_req_id_info))\n",
    "            else:\n",
    "                 existing_req['temp_merged_ids_log'] = [str(existing_req.get('id','N/A')), str(original_req_id_info)]\n",
    "            existing_req['id'] = existing_req.get('id', 'N/A') # 기존 ID 유지 또는 필요시 업데이트 로직\n",
    "\n",
    "\n",
    "    deduplicated_requirements = list(unique_reqs_by_content.values())\n",
    "    print(f\"    내용 기반 중복 제거 후: {len(deduplicated_requirements)}개 항목\")\n",
    "\n",
    "    final_requirements = []\n",
    "    id_counters = {} \n",
    "    type_prefixes = {\n",
    "        \"기능적\": \"FUNC\", \"비기능적\": \"NFR\", \"성능\": \"PERF\", \"보안\": \"SEC\",\n",
    "        \"데이터\": \"DATA\", \"인터페이스\": \"IF\", \"기술적 제약\": \"TCON\", \"운영환경\": \"OPS\",\n",
    "        \"테스트 조건\": \"TESTC\"\n",
    "        # 제외된 타입: \"프로젝트 관리\", \"프로젝트 지원\", \"정책준수\", \"기타\", \"산출물\" 등\n",
    "    }\n",
    "    valid_type_prefixes = {k: v for k, v in type_prefixes.items() if k not in exclude_types}\n",
    "\n",
    "\n",
    "    for i, req_dict in enumerate(deduplicated_requirements):\n",
    "        req_type = req_dict.get(\"type\", \"기타\")\n",
    "        \n",
    "        if req_type in exclude_types:\n",
    "            print(f\"    최종 필터링 (ID 부여 전): '{req_type}' 타입 항목 (임시ID: '{req_dict.get('id')}') 제외.\")\n",
    "            continue\n",
    "\n",
    "        # 타입이 exclude_types에 없고, valid_type_prefixes에도 없으면 기본 접두사 사용\n",
    "        default_prefix_from_type = req_type[:4].upper().replace(\" \",\"\").replace(\"_\",\"\") if req_type else \"UNKT\" # Unknown Type\n",
    "        prefix = valid_type_prefixes.get(req_type, default_prefix_from_type)\n",
    "        \n",
    "        if prefix not in id_counters:\n",
    "            id_counters[prefix] = 0\n",
    "        id_counters[prefix] += 1\n",
    "        \n",
    "        req_dict[\"id\"] = f\"{prefix}-{id_counters[prefix]:03d}\" # 최종 ID 부여\n",
    "        \n",
    "        req_dict.pop(\"pass_info\", None) \n",
    "        req_dict.pop(\"temp_merged_ids_log\", None)\n",
    "        \n",
    "        final_requirements.append(req_dict)\n",
    "\n",
    "    final_requirements.sort(key=lambda x: (min(x['source_pages']) if x.get('source_pages') else float('inf'), x.get('id', '')))\n",
    "    \n",
    "    print(f\"--- 전문가 후처리 완료: 최종 {len(final_requirements)}개 요구사항 ---\")\n",
    "    return final_requirements\n",
    "\n",
    "\n",
    "# === 메인 실행 로직 ===\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"./docs/제주은행 모바일뱅킹 재구축사업.pdf\" \n",
    "    output_filename_template = \"extracted_requirements_developer_focused_v{version}.json\"\n",
    "\n",
    "    print(f\"--- RFP 요구사항 추출 전문가 시스템 (개발자 관점) 시작 (입력 파일: {pdf_file_path}) ---\")\n",
    "\n",
    "    full_text, total_pages = expert_extract_text_with_pages(pdf_file_path)\n",
    "    if not full_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다.\")\n",
    "        exit()\n",
    "    print(f\"1. PDF 텍스트 추출 완료: 총 {total_pages} 페이지, 전체 텍스트 길이 {len(full_text)}자.\")\n",
    "\n",
    "    chunks = expert_create_chunks(full_text, chunk_size=3800, chunk_overlap=800) \n",
    "    if not chunks:\n",
    "        print(\"오류: 문서에서 청크를 생성하지 못했습니다.\")\n",
    "        exit()\n",
    "    print(f\"2. 문서 청킹 완료: 총 {len(chunks)}개 청크 생성 (overlap: 800).\")\n",
    "\n",
    "    # chunks_map은 현재 스크립트에서 직접 사용되지 않지만, 향후 패스2가 패스1의 특정 후보와 그 주변 문맥을 참조해야 할 경우 필요할 수 있음.\n",
    "    # 현재 패스1, 패스2는 각각 독립적으로 전체 청크를 순회함.\n",
    "\n",
    "    print(\"\\n--- 패스 1: 개발자 관점의 포괄적 요구사항 식별 시작 ---\")\n",
    "    pass1_requirements = expert_pass1_extract_developer_reqs(chunks, client, LLM_MODEL)\n",
    "    if not pass1_requirements:\n",
    "        print(\"패스 1에서 요구사항 후보를 찾지 못했습니다.\")\n",
    "    \n",
    "    print(\"\\n--- 패스 2: 개발자 관점의 추가/보완 요구사항 추출 시작 ---\")\n",
    "    pass2_requirements = expert_pass2_extract_missed_developer_reqs(chunks, client, LLM_MODEL)\n",
    "    if not pass2_requirements:\n",
    "        print(\"패스 2에서 추가/보완 요구사항을 찾지 못했습니다.\")\n",
    "\n",
    "    all_combined_requirements = pass1_requirements + pass2_requirements\n",
    "    print(f\"\\n모든 패스에서 총 {len(all_combined_requirements)}개의 요구사항 후보 수집 (중복 포함).\")\n",
    "    \n",
    "    types_to_exclude_user_defined = [\"기타\", \"산출물\", \"정책준수\", \"프로젝트 지원\"] \n",
    "    # 아래 type_prefixes에 없는 타입들은 어차피 ID 생성 시 \"UNKT\" 등으로 처리되거나,\n",
    "    # exclude_types에 명시된 경우 걸러짐. 개발자 관점에서 필요한 타입들을 type_prefixes에 정의.\n",
    "\n",
    "    print(f\"\\n--- 후처리 작업 시작 (제외할 타입: {types_to_exclude_user_defined}) ---\")\n",
    "    final_processed_requirements = expert_post_process_requirements(all_combined_requirements, exclude_types=types_to_exclude_user_defined)\n",
    "\n",
    "    if final_processed_requirements:\n",
    "        print(f\"\\n--- 최종 추출된 고유 요구사항: {len(final_processed_requirements)}개 ---\")\n",
    "        print(\"\\n--- 상위 5개 요구사항 미리보기 ---\")\n",
    "        for i, req_item in enumerate(final_processed_requirements[:5]):\n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            if i < 4: print(\"-\" * 20)\n",
    "        \n",
    "        # 버전 정보나 필터 정보를 파일명에 포함\n",
    "        script_version = \"5_dev_focused\" \n",
    "        excluded_types_short_str = \"_\".join(sorted([t[:2] for t in types_to_exclude_user_defined])).replace(\" \",\"\") if types_to_exclude_user_defined else \"none\"\n",
    "        output_filename = output_filename_template.format(version=script_version) # + f\"_excl_{excluded_types_short_str}\" # 필요시 제외타입 정보도 파일명에 추가\n",
    "        \n",
    "        try:\n",
    "            with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"\\n최종 추출된 요구사항이 '{output_filename}' 파일에 성공적으로 저장되었습니다.\")\n",
    "        except IOError as e:\n",
    "            print(f\"오류: '{output_filename}' 파일 저장 중 문제가 발생했습니다: {e}\")\n",
    "    else:\n",
    "        print(\"\\n최종적으로 추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    print(f\"--- RFP 요구사항 추출 전문가 시스템 (개발자 관점) 종료 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-nqLnFQ7l-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
