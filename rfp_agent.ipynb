{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. PDF 전체 텍스트 추출 중...\n",
      "   PDF 전체 텍스트 추출 완료. 총 54 페이지, 전체 텍스트 길이: 49066자.\n",
      "\n",
      "2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\n",
      "   목차 원문 텍스트 추출 완료 (길이: 8670자).\n",
      "\n",
      "3. LLM을 사용하여 목차(ToC) 파싱 중...\n",
      "   LLM 목차 파싱 완료. 49개의 목차 항목 식별.\n",
      "\n",
      "4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\n",
      "키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\n",
      "LLM 'is_requirement_related' 플래그 기반: '1. 제안 요청 개요' 섹션 (페이지 1-4) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '1.1. JBANK 시스템 재구축 추진 배경' 섹션 (페이지 1-4) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '1.2. JBANK 시스템 재구축 추진 목표' 섹션 (페이지 1-4) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '1.3. JBANK 시스템 재구축 사업 범위' 섹션 (페이지 2-4) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4. 프로젝트 구축 범위 및 제안 요청 상세' 섹션 (페이지 9-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.1. JBANK 시스템 UI/UX 표준 체계 마련 : 1.3. JBANK 시스템 재구축 사업 범위 참조' 섹션 (페이지 9-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.2. JBANK 시스템 GRC 체계 마련(확인필요)' 섹션 (페이지 9-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.3. JBANK 시스템 개발 프레임워크 도입(확인필요)' 섹션 (페이지 9-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.4. JBANK 시스템 인프라 도입' 섹션 (페이지 11-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.5. JBANK 시스템 DR 구축' 섹션 (페이지 11-11) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '4.1.6. 데이터 이행' 섹션 (페이지 12-12) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6. 시스템 구성 요건' 섹션 (페이지 15-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.1. 개발 환경' 섹션 (페이지 15-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.2. 시스템 실행 운영 환경' 섹션 (페이지 16-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.3. 시스템 테스트 요건' 섹션 (페이지 16-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.3.1. 기능 테스트 수행 방안' 섹션 (페이지 16-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.3.2. 비기능 테스트 수행 방안' 섹션 (페이지 17-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.4. 시스템 이행 요건' 섹션 (페이지 17-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.4.1. 데이터 이행 방안' 섹션 (페이지 17-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.4.2. 시스템 이행 방안' 섹션 (페이지 17-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5. 프로젝트 관리 방안' 섹션 (페이지 19-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5.1. 조직 구성 방안' 섹션 (페이지 19-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5.2. 인력 운영 방안' 섹션 (페이지 19-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5.3. 일정관리 방안' 섹션 (페이지 19-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5.4. 시스템 개발방법론' 섹션 (페이지 20-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.5.5. 프로젝트 관리방법론' 섹션 (페이지 20-21) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '6.6. 차세대 아키텍처 표준 준수' 섹션 (페이지 21-21) 식별\n",
      "\n",
      "5. 식별된 주요 섹션으로부터 텍스트 결합 중...\n",
      "   '1. 제안 요청 개요' 섹션 (페이지 1-4) 텍스트 추출 시도...\n",
      "       '1. 제안 요청 개요' 섹션 텍스트 추출 완료 (길이: 15153자).\n",
      "   '1.1. JBANK 시스템 재구축 추진 배경' 섹션 (페이지 1-4) 텍스트 추출 시도...\n",
      "       '1.1. JBANK 시스템 재구축 추진 배경' 섹션 텍스트 추출 완료 (길이: 15153자).\n",
      "   '1.2. JBANK 시스템 재구축 추진 목표' 섹션 (페이지 1-4) 텍스트 추출 시도...\n",
      "       '1.2. JBANK 시스템 재구축 추진 목표' 섹션 텍스트 추출 완료 (길이: 15153자).\n",
      "   '1.3. JBANK 시스템 재구축 사업 범위' 섹션 (페이지 2-4) 텍스트 추출 시도...\n",
      "       '1.3. JBANK 시스템 재구축 사업 범위' 섹션 텍스트 추출 완료 (길이: 15043자).\n",
      "   '4. 프로젝트 구축 범위 및 제안 요청 상세' 섹션 (페이지 9-11) 텍스트 추출 시도...\n",
      "       '4. 프로젝트 구축 범위 및 제안 요청 상세' 섹션 텍스트 추출 완료 (길이: 2621자).\n",
      "   '4.1.1. JBANK 시스템 UI/UX 표준 체계 마련 : 1.3. JBANK 시스템 재구축 사업 범위 참조' 섹션 (페이지 9-11) 텍스트 추출 시도...\n",
      "       '4.1.1. JBANK 시스템 UI/UX 표준 체계 마련 : 1.3. JBANK 시스템 재구축 사업 범위 참조' 섹션 텍스트 추출 완료 (길이: 2621자).\n",
      "   '4.1.2. JBANK 시스템 GRC 체계 마련(확인필요)' 섹션 (페이지 9-11) 텍스트 추출 시도...\n",
      "       '4.1.2. JBANK 시스템 GRC 체계 마련(확인필요)' 섹션 텍스트 추출 완료 (길이: 2621자).\n",
      "   '4.1.3. JBANK 시스템 개발 프레임워크 도입(확인필요)' 섹션 (페이지 9-11) 텍스트 추출 시도...\n",
      "       '4.1.3. JBANK 시스템 개발 프레임워크 도입(확인필요)' 섹션 텍스트 추출 완료 (길이: 2621자).\n",
      "   '4.1.4. JBANK 시스템 인프라 도입' 섹션 (페이지 11-11) 텍스트 추출 시도...\n",
      "       '4.1.4. JBANK 시스템 인프라 도입' 섹션 텍스트 추출 완료 (길이: 834자).\n",
      "   '4.1.5. JBANK 시스템 DR 구축' 섹션 (페이지 11-11) 텍스트 추출 시도...\n",
      "       '4.1.5. JBANK 시스템 DR 구축' 섹션 텍스트 추출 완료 (길이: 834자).\n",
      "   '4.1.6. 데이터 이행' 섹션 (페이지 12-12) 텍스트 추출 시도...\n",
      "       '4.1.6. 데이터 이행' 섹션 텍스트 추출 완료 (길이: 106자).\n",
      "   '6. 시스템 구성 요건' 섹션 (페이지 15-21) 텍스트 추출 시도...\n",
      "       '6. 시스템 구성 요건' 섹션 텍스트 추출 완료 (길이: 4346자).\n",
      "   '6.1. 개발 환경' 섹션 (페이지 15-21) 텍스트 추출 시도...\n",
      "       '6.1. 개발 환경' 섹션 텍스트 추출 완료 (길이: 4346자).\n",
      "   '6.2. 시스템 실행 운영 환경' 섹션 (페이지 16-21) 텍스트 추출 시도...\n",
      "       '6.2. 시스템 실행 운영 환경' 섹션 텍스트 추출 완료 (길이: 3503자).\n",
      "   '6.3. 시스템 테스트 요건' 섹션 (페이지 16-21) 텍스트 추출 시도...\n",
      "       '6.3. 시스템 테스트 요건' 섹션 텍스트 추출 완료 (길이: 3503자).\n",
      "   '6.3.1. 기능 테스트 수행 방안' 섹션 (페이지 16-21) 텍스트 추출 시도...\n",
      "       '6.3.1. 기능 테스트 수행 방안' 섹션 텍스트 추출 완료 (길이: 3503자).\n",
      "   '6.3.2. 비기능 테스트 수행 방안' 섹션 (페이지 17-21) 텍스트 추출 시도...\n",
      "       '6.3.2. 비기능 테스트 수행 방안' 섹션 텍스트 추출 완료 (길이: 2873자).\n",
      "   '6.4. 시스템 이행 요건' 섹션 (페이지 17-21) 텍스트 추출 시도...\n",
      "       '6.4. 시스템 이행 요건' 섹션 텍스트 추출 완료 (길이: 2873자).\n",
      "   '6.4.1. 데이터 이행 방안' 섹션 (페이지 17-21) 텍스트 추출 시도...\n",
      "       '6.4.1. 데이터 이행 방안' 섹션 텍스트 추출 완료 (길이: 2873자).\n",
      "   '6.4.2. 시스템 이행 방안' 섹션 (페이지 17-21) 텍스트 추출 시도...\n",
      "       '6.4.2. 시스템 이행 방안' 섹션 텍스트 추출 완료 (길이: 2873자).\n",
      "   '6.5. 프로젝트 관리 방안' 섹션 (페이지 19-21) 텍스트 추출 시도...\n",
      "       '6.5. 프로젝트 관리 방안' 섹션 텍스트 추출 완료 (길이: 1665자).\n",
      "   '6.5.1. 조직 구성 방안' 섹션 (페이지 19-21) 텍스트 추출 시도...\n",
      "       '6.5.1. 조직 구성 방안' 섹션 텍스트 추출 완료 (길이: 1665자).\n",
      "   '6.5.2. 인력 운영 방안' 섹션 (페이지 19-21) 텍스트 추출 시도...\n",
      "       '6.5.2. 인력 운영 방안' 섹션 텍스트 추출 완료 (길이: 1665자).\n",
      "   '6.5.3. 일정관리 방안' 섹션 (페이지 19-21) 텍스트 추출 시도...\n",
      "       '6.5.3. 일정관리 방안' 섹션 텍스트 추출 완료 (길이: 1665자).\n",
      "   '6.5.4. 시스템 개발방법론' 섹션 (페이지 20-21) 텍스트 추출 시도...\n",
      "       '6.5.4. 시스템 개발방법론' 섹션 텍스트 추출 완료 (길이: 1330자).\n",
      "   '6.5.5. 프로젝트 관리방법론' 섹션 (페이지 20-21) 텍스트 추출 시도...\n",
      "       '6.5.5. 프로젝트 관리방법론' 섹션 텍스트 추출 완료 (길이: 1330자).\n",
      "   '6.6. 차세대 아키텍처 표준 준수' 섹션 (페이지 21-21) 텍스트 추출 시도...\n",
      "       '6.6. 차세대 아키텍처 표준 준수' 섹션 텍스트 추출 완료 (길이: 725자).\n",
      "   주요 섹션 텍스트 결합 완료. 총 길이: 113550자.\n",
      "\n",
      "6. 결합된 텍스트 초기 분할 중...\n",
      "   총 42개의 초기 청크가 생성되었습니다.\n",
      "\n",
      "7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 1/42 (길이: 3497자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 2/42 (길이: 3432자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 3/42 (길이: 3454자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 4/42 (길이: 3435자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 5/42 (길이: 2279자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 6/42 (길이: 3493자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 7/42 (길이: 3432자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 8/42 (길이: 3454자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 9/42 (길이: 3435자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 10/42 (길이: 2279자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 11/42 (길이: 3493자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 12/42 (길이: 3432자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 13/42 (길이: 3454자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 14/42 (길이: 3435자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 15/42 (길이: 2279자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 16/42 (길이: 3387자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 17/42 (길이: 3432자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 18/42 (길이: 3454자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 19/42 (길이: 3435자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 20/42 (길이: 2279자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 21/42 (길이: 2620자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 22/42 (길이: 2620자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 23/42 (길이: 2620자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 24/42 (길이: 3456자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 25/42 (길이: 941자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 26/42 (길이: 3480자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 27/42 (길이: 1206자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 28/42 (길이: 3480자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 29/42 (길이: 1206자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 30/42 (길이: 3485자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 31/42 (길이: 346자) ---\n",
      "경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: ['id', 'type', 'description', 'acceptance_criteria', 'priority', 'responsible_module', 'source_pages', 'raw_text_snippet']\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 32/42 (길이: 3485자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 33/42 (길이: 346자) ---\n",
      "경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: ['id', 'type', 'description', 'acceptance_criteria', 'priority', 'responsible_module', 'source_pages', 'raw_text_snippet']\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 34/42 (길이: 3485자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 35/42 (길이: 346자) ---\n",
      "경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: ['id', 'type', 'description', 'acceptance_criteria', 'priority', 'responsible_module', 'source_pages', 'raw_text_snippet']\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 36/42 (길이: 2872자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 37/42 (길이: 2872자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 38/42 (길이: 2872자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 39/42 (길이: 2872자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 40/42 (길이: 3331자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 41/42 (길이: 3331자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 42/42 (길이: 3388자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "\n",
      "8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\n",
      "   추출된 요구사항이 없습니다.\n",
      "\n",
      "--- 최종 추출된 고유 요구사항 수: 0개 ---\n",
      "최종적으로 추출된 요구사항이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # initial_text_split 에서 사용\n",
    "import os\n",
    "import json\n",
    "import uuid # llm_based_semantic_chunking_for_dev_reqs 에서 사용\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 (사용자 기존 코드) ---\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL_FOR_PARSING = \"gpt-4o\" # 목차 파싱 및 요구사항 추출에 사용할 모델\n",
    "\n",
    "# --- 사용자 기존 함수 정의 부분 (여기에 extract_text_with_page_info, initial_text_split, llm_based_semantic_chunking_for_dev_reqs 가 있어야 함) ---\n",
    "\n",
    "def extract_text_with_page_info(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 페이지별로 추출하고, 각 페이지 시작에 페이지 번호를 표기합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        # 페이지 마커를 맨 앞에 추가하고, 실제 텍스트 내용과 명확히 구분되도록 줄바꿈 추가\n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def initial_text_split(text, chunk_size=4000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 LLM이 처리할 수 있는 크기로 초기 분할합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "        keep_separator=True # 페이지 마커 유지를 위해 True 권장\n",
    "    )\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs\n",
    "\n",
    "# llm_based_semantic_chunking_for_dev_reqs 함수 정의 (사용자 스크립트 내용)\n",
    "# def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=\"gpt-4o\"): ...\n",
    "# (이전에 제공된 프롬프트와 로직을 그대로 사용한다고 가정)\n",
    "def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    final_semantic_chunks = []\n",
    "    req_id_counter = 0\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 시스템 요구사항을 전문적으로 분석하고 개발 표준에 맞춰 구조화하는 시니어 비즈니스 분석가입니다.\n",
    "    사용자가 제공하는 텍스트는 RFP 문서의 특정 섹션이며, 여기서 모든 기능적, 비기능적, 성능, 보안, 데이터, 제약사항 요구사항을 추출해야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "\n",
    "    -   **id**: 고유 식별자. 예를 들어, 기능적 요구사항은 \"FUNC-001\", 비기능적은 \"NFR-001\", 보안은 \"SEC-001\"과 같이 유형 접두사와 일련번호를 결합하여 생성하십시오. (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. 다음 중 하나를 선택: \"기능적\", \"비기능적\", \"성능\", \"보안\", \"데이터\", \"제약사항\", \"시스템 장비 구성\", \"컨설팅\", \"테스트\", \"품질\", \"프로젝트 관리\", \"프로젝트 지원\", \"기타\". 텍스트에 명시된 내용에 따라 가장 적합한 유형을 선택하십시오. (예: \"시스템 장비 구성요구사항\", \"컨설팅 요구사항\" 등 PDF의 분류명 활용)\n",
    "    -   **description**: 요구사항에 대한 명확하고 간결한 설명. 원본 PDF의 '요구사항 명칭'과 '정의', '상세설명/세부내용'을 종합하여 개발 친화적인 형태로 작성하십시오. 하나의 요구사항은 하나의 독립적인 기능 또는 특성을 나타내야 합니다.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 검증할 수 있는 구체적인 테스트 조건이나 결과. 1~2개의 명확한 문장으로 서술하십시오. 원본 텍스트에 직접적인 검증 기준이 없더라도, 요구사항의 내용에 기반하여 합리적으로 추론하여 작성하십시오. (예: \"사용자가 [기능]을 수행했을 때, [예상 결과]가 나타난다.\")\n",
    "    -   **priority**: 요구사항의 중요도. 다음 중 하나를 선택: \"필수\", \"높음\", \"중간\", \"낮음\". (텍스트에 명시되어 있다면 그대로 사용, 아니면 일반적으로 \"필수\"로 추정)\n",
    "    -   **responsible_module**: 이 요구사항이 주로 영향을 미치거나 구현될 것으로 예상되는 시스템/애플리케이션의 주요 모듈 또는 영역 (예: \"로그인 모듈\", \"결제 시스템\", \"관리자 페이지\", \"데이터베이스\"). 텍스트 내용을 기반으로 추론하십시오.\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트. 페이지 구분자(`---PAGE_START_N---`)를 참조하여 정확한 페이지 번호를 파싱하십시오.\n",
    "    -   **raw_text_snippet**: 이 요구사항이 포함된 원본 텍스트 스니펫. 해당 요구사항을 추출하는 데 사용된 원본 문장 또는 단락(예: 표의 해당 행 전체 내용)을 포함하십시오.\n",
    "\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 요구사항이 없다면 빈 배열 `[]`을 반환하십시오.\n",
    "    불필요한 서론, 사업 배경, 계약 조건, 제안 지침 등은 요구사항으로 추출하지 마십시오. PDF의 '상세 요구사항' 목록에 있는 구조화된 항목들 위주로 추출해주십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, chunk_doc in enumerate(initial_chunks):\n",
    "        chunk_text = chunk_doc.page_content\n",
    "        print(f\"--- LLM 처리 중 (요구사항 상세 추출): 청크 {i+1}/{len(initial_chunks)} (길이: {len(chunk_text)}자) ---\")\n",
    "\n",
    "        page_numbers_in_chunk = sorted(list(set(\n",
    "            int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text)\n",
    "        )))\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부입니다. 이 부분에서 모든 시스템 요구사항을 개발자 표준에 맞춰 JSON 형식으로 추출해 주세요.\n",
    "        주어진 텍스트 내의 \"요구사항 고유번호\", \"요구사항 명칭\", \"요구사항 분류\", \"정의\", \"상세설명/세부내용\" 등의 명시적 필드를 최대한 활용하여 JSON 객체를 구성해주십시오.\n",
    "\n",
    "        --- 텍스트 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            llm_response_content = response.choices[0].message.content\n",
    "            try:\n",
    "                extracted_data_outer = json.loads(llm_response_content)\n",
    "                extracted_data_list = []\n",
    "                if isinstance(extracted_data_outer, list):\n",
    "                    extracted_data_list = extracted_data_outer\n",
    "                elif isinstance(extracted_data_outer, dict):\n",
    "                    # 딕셔너리 값 중에 리스트를 찾아 첫 번째 것을 사용 (일반적인 LLM 응답 패턴)\n",
    "                    for key_in_dict in extracted_data_outer:\n",
    "                        if isinstance(extracted_data_outer[key_in_dict], list):\n",
    "                            extracted_data_list = extracted_data_outer[key_in_dict]\n",
    "                            break\n",
    "                    if not extracted_data_list: # 그래도 못찾으면 경고\n",
    "                        print(f\"경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: {list(extracted_data_outer.keys())}\")\n",
    "                else:\n",
    "                    print(f\"경고: LLM으로부터 예상치 못한 JSON 형식 응답 (리스트 또는 객체 내 리스트가 아님). {llm_response_content[:100]}...\")\n",
    "                    continue\n",
    "            except json.JSONDecodeError as e_inner:\n",
    "                print(f\"LLM 응답 내용 JSON 파싱 오류 (내부 시도): {e_inner}. 응답: {llm_response_content[:500]}...\")\n",
    "                continue\n",
    "\n",
    "            for req_idx, req in enumerate(extracted_data_list):\n",
    "                # 'id'가 없거나 비어있으면 생성, 또는 원본 ID 우선 사용\n",
    "                original_id = req.get('id') # LLM이 원본 ID (ECR-001 등)를 id 필드에 넣어줬길 기대\n",
    "                if not original_id:\n",
    "                    req_type_prefix = \"REQ\"\n",
    "                    req_type = req.get('type', '기타').strip()\n",
    "                    if \"기능\" in req_type: req_type_prefix = \"FUNC\"\n",
    "                    elif \"비기능\" in req_type: req_type_prefix = \"NFR\"\n",
    "                    elif \"성능\" in req_type: req_type_prefix = \"PERF\"\n",
    "                    elif \"보안\" in req_type: req_type_prefix = \"SEC\"\n",
    "                    elif \"데이터\" in req_type: req_type_prefix = \"DATA\"\n",
    "                    elif \"제약\" in req_type: req_type_prefix = \"CONST\"\n",
    "                    elif \"장비\" in req_type: req_type_prefix = \"ECR\"\n",
    "                    elif \"컨설팅\" in req_type: req_type_prefix = \"CSR\"\n",
    "                    elif \"테스트\" in req_type: req_type_prefix = \"TER\"\n",
    "                    elif \"품질\" in req_type: req_type_prefix = \"QUR\"\n",
    "                    elif \"관리\" in req_type: req_type_prefix = \"PMR\"\n",
    "                    elif \"지원\" in req_type: req_type_prefix = \"PSR\"\n",
    "                    req_id_counter += 1\n",
    "                    req['id'] = f\"{req_type_prefix}-{req_id_counter:03d}\"\n",
    "\n",
    "                if 'source_pages' not in req or not req['source_pages']:\n",
    "                    req['source_pages'] = page_numbers_in_chunk if page_numbers_in_chunk else []\n",
    "\n",
    "                if 'raw_text_snippet' not in req or not req['raw_text_snippet']:\n",
    "                    req['raw_text_snippet'] = f\"청크 {i+1}에서 추출됨. 원본 청크 일부: {chunk_text[:200]}...\" # 개선 필요\n",
    "\n",
    "                req['type'] = req.get('type', '기타')\n",
    "                req['description'] = req.get('description', '설명 없음')\n",
    "                req['acceptance_criteria'] = req.get('acceptance_criteria', '해당하는 경우 명시')\n",
    "                req['priority'] = req.get('priority', '필수')\n",
    "                req['responsible_module'] = req.get('responsible_module', '미정')\n",
    "                final_semantic_chunks.append(req)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"LLM API 호출 또는 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    return final_semantic_chunks\n",
    "\n",
    "\n",
    "# --- LLM으로 목차 파싱하는 함수 (이전 답변에서 제공 및 개선된 버전) ---\n",
    "def parse_toc_with_llm(toc_raw_text, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 목차 원문 텍스트를 파싱하여 구조화된 목차 항목을 추출합니다.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 PDF 문서에서 추출된 목차(Table of Contents)의 원시 텍스트를 분석하는 전문가입니다.\n",
    "    주어진 텍스트를 파싱하여 각 목차 항목의 제목, 페이지 번호, 그리고 해당 항목이 '요구사항' 관련 내용을 담고 있을 가능성을 분석하여 JSON 형태로 반환해야 합니다.\n",
    "    JSON의 최상위 레벨은 \"toc_entries\"라는 키를 가진 객체여야 하고, 그 키의 값은 목차 항목 객체들의 리스트여야 합니다.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    다음은 PDF에서 추출한 목차로 추정되는 텍스트입니다:\n",
    "\n",
    "    --- 목차 원문 텍스트 시작 ---\n",
    "    {toc_raw_text}\n",
    "    --- 목차 원문 텍스트 끝 ---\n",
    "\n",
    "    이 텍스트를 분석하여 JSON 객체를 반환해주세요. 이 객체는 \"toc_entries\"라는 키를 가져야 하며,\n",
    "    이 키의 값은 각 목차 항목을 나타내는 객체들의 리스트여야 합니다.\n",
    "    각 목차 항목 객체는 다음 키를 가져야 합니다:\n",
    "    - \"title\": (문자열) 목차 항목의 전체 제목. 제목 앞의 번호(예: \"1.\", \"II.\", \"가.\")도 포함해주세요.\n",
    "    - \"page\": (정수) 해당 항목의 시작 페이지 번호.\n",
    "    - \"is_requirement_related\": (불리언) 제목이나 내용을 볼 때, 해당 항목이 '요구사항', '과업 범위', '제안 요청 상세', '기능 명세', '기술 요건' 등과 관련된 내용을 다룰 가능성이 높으면 true, 그렇지 않으면 false로 설정해주세요.\n",
    "\n",
    "    예시 JSON 출력 형식:\n",
    "    {{\n",
    "      \"toc_entries\": [\n",
    "        {{\n",
    "          \"title\": \"1. 사업 개요\",\n",
    "          \"page\": 5,\n",
    "          \"is_requirement_related\": false\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"III. 제안요청 내용\",\n",
    "          \"page\": 6,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"3. 상세 요구사항\",\n",
    "          \"page\": 11,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"* 보안 요구사항 별표\",\n",
    "          \"page\": 63,\n",
    "          \"is_requirement_related\": true\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    만약 주어진 텍스트가 유효한 목차로 보이지 않거나 항목을 전혀 파싱할 수 없다면,\n",
    "    \"toc_entries\" 키의 값으로 빈 리스트 `[]`를 포함하는 JSON 객체를 반환해주세요. (예: {{\"toc_entries\": []}})\n",
    "    \"\"\"\n",
    "    llm_response_content = \"\" # 오류 발생 시 로깅을 위해 미리 선언\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        # print(f\"DEBUG: LLM RAW RESPONSE FOR TOC: {llm_response_content}\")\n",
    "\n",
    "        parsed_data = json.loads(llm_response_content)\n",
    "\n",
    "        extracted_list = []\n",
    "        if isinstance(parsed_data, dict) and \"toc_entries\" in parsed_data and isinstance(parsed_data[\"toc_entries\"], list):\n",
    "            extracted_list = parsed_data[\"toc_entries\"]\n",
    "        else:\n",
    "            print(f\"LLM 응답이 예상된 'toc_entries' 리스트를 포함하는 객체 형식이 아닙니다. 응답: {llm_response_content[:200]}\")\n",
    "            return [] # 빈 리스트 반환\n",
    "\n",
    "        valid_entries = []\n",
    "        for entry in extracted_list:\n",
    "            if isinstance(entry, dict) and 'title' in entry and 'page' in entry:\n",
    "                try:\n",
    "                    entry['page'] = int(entry['page'])\n",
    "                    entry['is_requirement_related'] = bool(entry.get('is_requirement_related', False)) # 명확히 불리언으로\n",
    "                    valid_entries.append(entry)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: 페이지 번호 '{entry.get('page')}'를 정수로 변환할 수 없습니다. 항목 건너뜀: {entry.get('title')}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"경고: 필수 키(title, page)가 누락된 항목입니다. 건너뜀: {entry}\")\n",
    "\n",
    "        return valid_entries\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 목차 파싱 응답 JSON 파싱 오류: {e}. 응답 미리보기: {llm_response_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생 (목차 파싱): {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 새로운 헬퍼 함수들 ---\n",
    "def extract_text_for_pages(full_text_with_pages, start_page_num, end_page_num):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 특정 페이지 범위의 텍스트만 추출합니다.\n",
    "    페이지 마커 '---PAGE_START_N---'를 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 페이지 범위 유효성 검사 (end_page_num이 start_page_num보다 작을 수 없음)\n",
    "    if end_page_num < start_page_num:\n",
    "        # print(f\"경고: 끝 페이지({end_page_num})가 시작 페이지({start_page_num})보다 작습니다. 빈 텍스트를 반환합니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    # 패턴 구성: 시작 페이지부터 (끝 페이지 + 1) 직전까지 모든 내용을 포함\n",
    "    # re.escape를 사용하여 페이지 마커의 특수 문자를 이스케이프할 필요는 여기서는 없음\n",
    "    # DOTALL 플래그를 사용하여 \\n도 .에 매치되도록 함\n",
    "\n",
    "    # 시작점 찾기\n",
    "    start_marker = f\"---PAGE_START_{start_page_num}---\"\n",
    "    start_match = re.search(re.escape(start_marker), full_text_with_pages) # 마커 자체를 찾아야 함\n",
    "\n",
    "    if not start_match:\n",
    "        # print(f\"경고: 시작 마커 '{start_marker}'를 찾을 수 없습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "    text_from_start_page = full_text_with_pages[start_match.start():]\n",
    "\n",
    "    # 끝점 찾기 (다음 페이지 마커 ---PAGE_START_{end_page_num + 1}---)\n",
    "    # end_page_num이 문서의 마지막 페이지일 수도 있으므로, end_page_num + 1 마커가 없을 수 있음\n",
    "    end_marker_exclusive = f\"---PAGE_START_{end_page_num + 1}---\"\n",
    "    end_match = re.search(re.escape(end_marker_exclusive), text_from_start_page)\n",
    "\n",
    "    if end_match:\n",
    "        return text_from_start_page[:end_match.start()]\n",
    "    else:\n",
    "        # end_page_num + 1 마커를 찾지 못하면, start_page_num부터 문서 끝까지 반환 (또는 start_page_num ~ end_page_num의 마지막 내용까지)\n",
    "        # 이 경우는 end_page_num이 마지막 페이지이거나, 그 이후 페이지 마커가 없는 경우.\n",
    "        # 좀 더 정확하게 하려면, end_page_num까지의 모든 내용을 가져와야 함.\n",
    "        # 그러나 페이지 마커 구조상, end_page_num의 내용은 end_page_num+1 마커 전까지임.\n",
    "        # 따라서 end_match가 없으면 text_from_start_page 전체가 해당 범위임.\n",
    "        return text_from_start_page\n",
    "\n",
    "\n",
    "def get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages):\n",
    "    \"\"\"\n",
    "    LLM으로 파싱된 목차에서 '상세 요구사항' 및 '보안 요구사항' 관련 섹션 정보를 추출합니다.\n",
    "    \"\"\"\n",
    "    target_sections = []\n",
    "\n",
    "    # 페이지 번호 기준으로 목차 정렬 (LLM이 순서대로 안 줄 수도 있으므로)\n",
    "    sorted_toc = sorted(parsed_toc_entries, key=lambda x: x.get('page', 0))\n",
    "\n",
    "    # 주요 키워드 - 사용자가 제공한 PDF 목차 기반\n",
    "    # \"III. 제안요청 내용\" 안에 \"3. 상세 요구사항\"이 있으므로, \"상세 요구사항\"을 찾는 것이 더 정확함.\n",
    "    keywords_to_find = {\n",
    "        \"상세 요구사항\": {\"min_pages\": 5}, # 최소한 이정도는 될 것이라는 기대\n",
    "        \"보안 요구사항 별표\": {\"min_pages\": 1} # 별표는 짧을 수도 있음\n",
    "        # 필요시 다른 주요 섹션 키워드 추가 가능\n",
    "    }\n",
    "\n",
    "    for i, entry in enumerate(sorted_toc):\n",
    "        entry_title = entry.get('title', '').strip()\n",
    "        entry_page = entry.get('page', 0)\n",
    "\n",
    "        for keyword, props in keywords_to_find.items():\n",
    "            if keyword in entry_title:\n",
    "                start_page = entry_page\n",
    "                end_page = total_pages # 기본값: 문서 끝까지\n",
    "\n",
    "                # 다음 목차 항목의 시작 페이지 - 1을 현재 섹션의 끝 페이지로 설정\n",
    "                # 단, 다음 항목이 현재 항목과 같은 페이지에서 시작하면 안됨 (하위 항목일 수 있으므로)\n",
    "                # 좀 더 정교한 로직: 다음 '주요' 항목을 찾아야 함.\n",
    "                # 여기서는 일단 다음 항목의 시작 페이지를 사용.\n",
    "                # 만약 다음 항목이 현재 항목의 하위 항목처럼 보이면 (예: \"3. 상세 요구사항\" 다음 \"3.1 기능 요구사항\")\n",
    "                # 그 하위 항목의 범위를 포함하도록 확장하거나, 아니면 정말 다음 *다른* 주요 섹션까지 봐야 함.\n",
    "                # 현재 LLM 프롬프트는 is_requirement_related로 판단하므로, 이를 우선적으로 신뢰.\n",
    "\n",
    "                # 다음 'is_requirement_related=False'인 섹션 또는 다음 주요 섹션(로마숫자/대문자 알파벳 등)을 찾아 end_page 설정\n",
    "                # 또는 단순히 다음 목차 항목의 시작 페이지 - 1 로 설정\n",
    "                next_major_section_page = total_pages + 1 # 충분히 큰 값\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page : # 현재 섹션 이후의 페이지만 고려\n",
    "                        # 여기서 '주요 섹션'을 판단하는 기준이 필요함 (예: 로마 숫자, 대문자 번호 등)\n",
    "                        # 또는 is_requirement_related=False 인 첫번째 섹션\n",
    "                        # 또는 단순히 다음 목차 항목\n",
    "                        next_major_section_page = next_entry_page\n",
    "                        break\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page -1)\n",
    "\n",
    "                # 시작 페이지와 끝 페이지 유효성 확보\n",
    "                if end_page < start_page:\n",
    "                    end_page = start_page\n",
    "\n",
    "                # 페이지 수가 너무 적으면 해당 섹션 전체를 포함 (예: 11페이지로 나왔는데 실제로는 62까지일 수 있음)\n",
    "                # 이 부분은 heuristic이므로 주의. 더 좋은 방법은 LLM에게 섹션의 끝을 명확히 묻는 것.\n",
    "                # 여기서는 min_pages 이상은 되어야 유의미하다고 가정.\n",
    "                # if (end_page - start_page + 1) < props.get(\"min_pages\", 1) and (start_page + props.get(\"min_pages\", 1) -1) <= total_pages :\n",
    "                #     pass # end_page = start_page + props.get(\"min_pages\", 1) -1 # 최소 페이지 강제는 위험할 수 있음\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry_title,\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 파싱 목차 기반: '{entry_title}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "                # 찾은 키워드는 중복 추가 방지 (더 구체적인 항목이 먼저 찾아지도록 keywords_to_find 순서 중요)\n",
    "                break\n",
    "\n",
    "    # 만약 아무것도 못찾았지만, is_requirement_related=True 인 항목들이 있다면 그것들을 사용\n",
    "    if not target_sections:\n",
    "        print(\"키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\")\n",
    "        for i, entry in enumerate(sorted_toc):\n",
    "            if entry.get('is_requirement_related'):\n",
    "                start_page = entry.get('page',0)\n",
    "                end_page = total_pages\n",
    "                # 위와 동일한 로직으로 end_page 계산\n",
    "                next_major_section_page = total_pages + 1\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page:\n",
    "                        if not next_entry.get('is_requirement_related', False): # 다음 주요 섹션이 요구사항 관련이 아니면\n",
    "                            next_major_section_page = next_entry_page\n",
    "                            break\n",
    "                        # 또는 다음 항목이 현재 항목보다 상위 레벨이면 (예: \"3.1\" 다음 \"4.\")\n",
    "                        # 이 부분은 제목의 번호 체계를 분석해야 해서 복잡함. LLM의 is_requirement_related를 신뢰.\n",
    "\n",
    "                end_page = min(total_pages, next_major_section_page - 1)\n",
    "                if end_page < start_page: end_page = start_page\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry.get('title', '요구사항 관련 섹션'),\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 'is_requirement_related' 플래그 기반: '{entry.get('title')}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "\n",
    "    # 중복 제거 및 병합 (예: \"III. 제안요청 내용\"과 그 하위 \"3. 상세 요구사항\"이 모두 선택된 경우)\n",
    "    # 여기서는 단순화를 위해 중복된 페이지 범위가 있다면 가장 포괄적인 것을 선택하거나,\n",
    "    # 또는 가장 구체적인 \"상세 요구사항\"을 우선. 지금은 일단 나온대로 반환.\n",
    "    # 더 나은 방법은, '상세 요구사항'이 나왔으면 그게 더 우선순위가 높다고 처리.\n",
    "\n",
    "    if not target_sections:\n",
    "        print(\"경고: LLM 파싱 목차에서 주요 요구사항 섹션을 찾지 못했습니다. 전체 문서를 대상으로 할 수 있습니다.\")\n",
    "        return [{'title': '전체 문서 (목차 분석 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    return target_sections\n",
    "\n",
    "\n",
    "def get_toc_raw_text_from_full_text(full_text_with_pages, toc_page_numbers=[2,3]):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 지정된 목차 페이지들의 텍스트만 추출합니다.\n",
    "    \"\"\"\n",
    "    toc_texts = []\n",
    "    for page_num in toc_page_numbers:\n",
    "        # 페이지 마커를 찾아서 해당 페이지의 텍스트를 추출\n",
    "        # (end_page_num + 1) 마커를 찾아서 그 전까지의 내용을 가져옴\n",
    "        page_content = extract_text_for_pages(full_text_with_pages, page_num, page_num)\n",
    "        if page_content:\n",
    "            # 페이지 마커 제거 (이미 extract_text_for_pages가 마커 다음부터 가져오지만, 혹시 몰라서)\n",
    "            # 실제로는 페이지 마커 이후의 텍스트만 필요.\n",
    "            # `extract_text_for_pages`는 마커를 포함해서 반환할 수 있으므로, 마커 이후 내용만 사용.\n",
    "            marker = f\"---PAGE_START_{page_num}---\\n\"\n",
    "            if page_content.startswith(marker):\n",
    "                toc_texts.append(page_content[len(marker):])\n",
    "            else: # 마커가 없는 경우 (예상치 않음)\n",
    "                toc_texts.append(page_content)\n",
    "        else:\n",
    "            print(f\"경고: 목차 페이지로 지정된 {page_num} 페이지에서 텍스트를 찾을 수 없습니다.\")\n",
    "\n",
    "    if not toc_texts:\n",
    "        return None\n",
    "    return \"\\n\".join(toc_texts)\n",
    "\n",
    "# --- 메인 실행 블록 ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"./docs/제주은행 모바일뱅킹 재구축사업.pdf\" # 실제 파일 경로\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"오류: PDF 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "        exit()\n",
    "\n",
    "    print(\"1. PDF 전체 텍스트 추출 중...\")\n",
    "    full_document_text, total_pages = extract_text_with_page_info(pdf_file_path)\n",
    "    if not full_document_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다 ({pdf_file_path}).\")\n",
    "        exit()\n",
    "    print(f\"   PDF 전체 텍스트 추출 완료. 총 {total_pages} 페이지, 전체 텍스트 길이: {len(full_document_text)}자.\")\n",
    "\n",
    "    print(\"\\n2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\")\n",
    "    # 사용자 PDF 분석 결과 PAGE 2, 3에 목차가 있음\n",
    "    toc_raw_text = get_toc_raw_text_from_full_text(full_document_text, toc_page_numbers=[2, 3])\n",
    "\n",
    "    target_sections_for_extraction = []\n",
    "    if toc_raw_text:\n",
    "        print(f\"   목차 원문 텍스트 추출 완료 (길이: {len(toc_raw_text)}자).\")\n",
    "        print(\"\\n3. LLM을 사용하여 목차(ToC) 파싱 중...\")\n",
    "        parsed_toc_entries = parse_toc_with_llm(toc_raw_text, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "        if parsed_toc_entries:\n",
    "            print(f\"   LLM 목차 파싱 완료. {len(parsed_toc_entries)}개의 목차 항목 식별.\")\n",
    "            print(\"\\n4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\")\n",
    "            target_sections_for_extraction = get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages)\n",
    "        else:\n",
    "            print(\"   LLM 목차 파싱 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "            target_sections_for_extraction = [{'title': '전체 문서 (LLM 목차 파싱 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "    else:\n",
    "        print(\"   목차 원문 텍스트 추출 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "        target_sections_for_extraction = [{'title': '전체 문서 (목차 원문 추출 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    if not target_sections_for_extraction: # 만약을 위해 한번 더 체크\n",
    "        print(\"오류: 분석할 대상 섹션을 정의하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n5. 식별된 주요 섹션으로부터 텍스트 결합 중...\")\n",
    "    all_requirements_related_text_parts = []\n",
    "    for section_info in target_sections_for_extraction:\n",
    "        print(f\"   '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']}) 텍스트 추출 시도...\")\n",
    "        section_text = extract_text_for_pages(full_document_text, section_info['start_page'], section_info['end_page'])\n",
    "        if section_text:\n",
    "            all_requirements_related_text_parts.append(section_text)\n",
    "            print(f\"       '{section_info['title']}' 섹션 텍스트 추출 완료 (길이: {len(section_text)}자).\")\n",
    "        else:\n",
    "            print(f\"       경고: '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']})에서 텍스트를 추출하지 못했습니다.\")\n",
    "\n",
    "    if not all_requirements_related_text_parts:\n",
    "        print(\"오류: 주요 요구사항 섹션에서 텍스트를 전혀 추출하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    combined_requirements_text = \"\\n\\n\".join(all_requirements_related_text_parts) # 섹션 간 구분을 위해 두 줄바꿈\n",
    "    print(f\"   주요 섹션 텍스트 결합 완료. 총 길이: {len(combined_requirements_text)}자.\")\n",
    "\n",
    "    print(\"\\n6. 결합된 텍스트 초기 분할 중...\")\n",
    "    # chunk_size는 LLM의 context window와 한글 토큰 소모를 고려하여 설정\n",
    "    initial_chunks = initial_text_split(combined_requirements_text, chunk_size=3500, chunk_overlap=350)\n",
    "    print(f\"   총 {len(initial_chunks)}개의 초기 청크가 생성되었습니다.\")\n",
    "\n",
    "    if not initial_chunks:\n",
    "        print(\"오류: 텍스트 분할 결과 청크가 없습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\")\n",
    "    extracted_requirements = llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "    print(\"\\n8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\")\n",
    "    # (기존 스크립트의 후처리 로직 사용 또는 필요시 개선)\n",
    "    unique_requirements_by_id = {}\n",
    "    processed_requirements = []\n",
    "    if extracted_requirements:\n",
    "        for req in extracted_requirements:\n",
    "            req_id = req.get('id', str(uuid.uuid4())) # ID가 없다면 UUID로 임시 ID\n",
    "            if req_id not in unique_requirements_by_id:\n",
    "                unique_requirements_by_id[req_id] = req\n",
    "            else:\n",
    "                # ID가 중복될 경우, 설명을 합치거나 페이지 정보를 합치는 등의 로직 추가 가능\n",
    "                # 여기서는 간단히 첫 번째 것만 유지하거나, 필요에 따라 업데이트\n",
    "                # 예: 페이지 정보 병합\n",
    "                existing_req = unique_requirements_by_id[req_id]\n",
    "                new_pages = req.get('source_pages', [])\n",
    "                if new_pages:\n",
    "                    existing_req_pages = existing_req.get('source_pages', [])\n",
    "                    existing_req['source_pages'] = sorted(list(set(existing_req_pages + new_pages)))\n",
    "                print(f\"중복 ID '{req_id}' 감지. 정보 업데이트 시도.\")\n",
    "        processed_requirements = list(unique_requirements_by_id.values())\n",
    "    else:\n",
    "        print(\"   추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    # 최종 결과 출력 또는 저장\n",
    "    print(f\"\\n--- 최종 추출된 고유 요구사항 수: {len(processed_requirements)}개 ---\")\n",
    "    if processed_requirements:\n",
    "        print(\"\\n--- 추출된 요구사항 미리보기 (상위 3개) ---\")\n",
    "        for i, req_item in enumerate(processed_requirements[:3]): # 'req' 변수명 충돌 피하기 위해 'req_item'으로 변경\n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        output_filename = \"extracted_requirements_final.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"\\n추출된 요구사항이 '{output_filename}' 파일에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"최종적으로 추출된 요구사항이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. PDF 전체 텍스트 추출 중...\n",
      "   PDF 전체 텍스트 추출 완료. 총 41 페이지, 전체 텍스트 길이: 30359자.\n",
      "\n",
      "2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\n",
      "   목차 원문 텍스트 추출 완료 (길이: 2079자).\n",
      "\n",
      "3. LLM을 사용하여 목차(ToC) 파싱 중...\n",
      "   LLM 목차 파싱 완료. 17개의 목차 항목 식별.\n",
      "\n",
      "4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\n",
      "키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\n",
      "LLM 'is_requirement_related' 플래그 기반: 'II 제안 요청 내역' 섹션 (페이지 4-17) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '1. 사업범위' 섹션 (페이지 4-17) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '2. 제안요건' 섹션 (페이지 7-17) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: 'IV 제안서 작성 요령' 섹션 (페이지 23-25) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '1. 작성순서 및 세부지침' 섹션 (페이지 23-25) 식별\n",
      "LLM 'is_requirement_related' 플래그 기반: '2. 세부 작성 방법' 섹션 (페이지 24-25) 식별\n",
      "\n",
      "5. 식별된 주요 섹션으로부터 텍스트 결합 중...\n",
      "   'II 제안 요청 내역' 섹션 (페이지 4-17) 텍스트 추출 시도...\n",
      "         'II 제안 요청 내역' 섹션 텍스트 추출 완료 (길이: 12080자).\n",
      "   '1. 사업범위' 섹션 (페이지 4-17) 텍스트 추출 시도...\n",
      "         '1. 사업범위' 섹션 텍스트 추출 완료 (길이: 12080자).\n",
      "   '2. 제안요건' 섹션 (페이지 7-17) 텍스트 추출 시도...\n",
      "         '2. 제안요건' 섹션 텍스트 추출 완료 (길이: 10216자).\n",
      "   'IV 제안서 작성 요령' 섹션 (페이지 23-25) 텍스트 추출 시도...\n",
      "         'IV 제안서 작성 요령' 섹션 텍스트 추출 완료 (길이: 3451자).\n",
      "   '1. 작성순서 및 세부지침' 섹션 (페이지 23-25) 텍스트 추출 시도...\n",
      "         '1. 작성순서 및 세부지침' 섹션 텍스트 추출 완료 (길이: 3451자).\n",
      "   '2. 세부 작성 방법' 섹션 (페이지 24-25) 텍스트 추출 시도...\n",
      "         '2. 세부 작성 방법' 섹션 텍스트 추출 완료 (길이: 2991자).\n",
      "   주요 섹션 텍스트 결합 완료. 총 길이: 44279자.\n",
      "\n",
      "6. 결합된 텍스트 초기 분할 중...\n",
      "   총 15개의 초기 청크가 생성되었습니다.\n",
      "\n",
      "7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 1/15 (길이: 3486자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 2/15 (길이: 3491자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 3/15 (길이: 3492자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 4/15 (길이: 2576자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 5/15 (길이: 3486자) ---\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 6/15 (길이: 3491자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 7/15 (길이: 3492자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 8/15 (길이: 2576자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 9/15 (길이: 3457자) ---\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 10/15 (길이: 3485자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 11/15 (길이: 3483자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 12/15 (길이: 773자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 13/15 (길이: 3450자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 14/15 (길이: 3450자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "--- LLM 처리 중 (요구사항 상세 추출): 청크 15/15 (길이: 2990자) ---\n",
      "LLM API 호출 또는 처리 중 오류 발생: 'int' object has no attribute 'get'\n",
      "\n",
      "8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\n",
      "중복 ID 'FUNC-001' 감지. 정보 업데이트 시도.\n",
      "중복 ID 'PERF-001' 감지. 정보 업데이트 시도.\n",
      "중복 ID 'SEC-001' 감지. 정보 업데이트 시도.\n",
      "중복 ID 'SEC-002' 감지. 정보 업데이트 시도.\n",
      "중복 ID 'NFR-001' 감지. 정보 업데이트 시도.\n",
      "중복 ID 'DATA-001' 감지. 정보 업데이트 시도.\n",
      "\n",
      "--- 최종 추출된 고유 요구사항 수: 10개 ---\n",
      "\n",
      "--- 추출된 요구사항 미리보기 (상위 3개) ---\n",
      "{\n",
      "  \"id\": \"FUNC-001\",\n",
      "  \"type\": \"기능적\",\n",
      "  \"description\": \"기존 HR시스템과의 연계 기능을 구현하여 인사이동 및 인원 추천 기능을 지원한다.\",\n",
      "  \"acceptance_criteria\": \"사용자가 HR시스템과 연계된 인사이동 및 인원 추천 기능을 수행할 수 있다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"HR 시스템 연계 모듈\",\n",
      "  \"source_pages\": [\n",
      "    4,\n",
      "    7\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"기존 HR시스템 연계 기능 구현\",\n",
      "  \"raw_snippet_origin_info\": {\n",
      "    \"chunk_index\": 5,\n",
      "    \"chunk_pages\": [\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8\n",
      "    ]\n",
      "  },\n",
      "  \"raw_text_snippet_source_type\": \"llm_extracted\"\n",
      "}\n",
      "------------------------------\n",
      "{\n",
      "  \"id\": \"FUNC-002\",\n",
      "  \"type\": \"기능적\",\n",
      "  \"description\": \"AI 기능을 통해 인원 추천 및 효율적 대안 제시 기능을 구현한다.\",\n",
      "  \"acceptance_criteria\": \"AI 기능을 통해 사용자가 인원 추천 및 대안을 확인할 수 있다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"AI 인사 솔루션\",\n",
      "  \"source_pages\": [\n",
      "    4\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"AI 기능을 통한 인원 추천 및 효율적 대안 제시 기능 구현\",\n",
      "  \"raw_snippet_origin_info\": {\n",
      "    \"chunk_index\": 5,\n",
      "    \"chunk_pages\": [\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8\n",
      "    ]\n",
      "  },\n",
      "  \"raw_text_snippet_source_type\": \"llm_extracted\"\n",
      "}\n",
      "------------------------------\n",
      "{\n",
      "  \"id\": \"DATA-001\",\n",
      "  \"type\": \"데이터\",\n",
      "  \"description\": \"기존 HR시스템 내 인사데이터를 활용하여 인사발령 및 추천 기능을 지원한다.\",\n",
      "  \"acceptance_criteria\": \"인사데이터가 기존 HR시스템에서 적재 및 활용된다.\",\n",
      "  \"priority\": \"필수\",\n",
      "  \"responsible_module\": \"데이터 관리 모듈\",\n",
      "  \"source_pages\": [\n",
      "    4,\n",
      "    8\n",
      "  ],\n",
      "  \"raw_text_snippet\": \"기존 HR시스템 내 인사데이터 활용 필요\",\n",
      "  \"raw_snippet_origin_info\": {\n",
      "    \"chunk_index\": 5,\n",
      "    \"chunk_pages\": [\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8\n",
      "    ]\n",
      "  },\n",
      "  \"raw_text_snippet_source_type\": \"llm_extracted\"\n",
      "}\n",
      "------------------------------\n",
      "\n",
      "추출된 요구사항이 'extracted_requirements_final.json' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # initial_text_split 에서 사용\n",
    "import os\n",
    "import json\n",
    "import uuid # llm_based_semantic_chunking_for_dev_reqs 에서 사용\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 (사용자 기존 코드) ---\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL_FOR_PARSING = \"gpt-4o\" # 목차 파싱 및 요구사항 추출에 사용할 모델\n",
    "\n",
    "# --- 사용자 기존 함수 정의 부분 ---\n",
    "\n",
    "def extract_text_with_page_info(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 페이지별로 추출하고, 각 페이지 시작에 페이지 번호를 표기합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        # 페이지 마커를 맨 앞에 추가하고, 실제 텍스트 내용과 명확히 구분되도록 줄바꿈 추가\n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def initial_text_split(text, chunk_size=4000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 LLM이 처리할 수 있는 크기로 초기 분할합니다.\n",
    "    (사용자 스크립트에 이미 정의된 함수로 가정)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "        keep_separator=True # 페이지 마커 유지를 위해 True 권장\n",
    "    )\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs\n",
    "\n",
    "# llm_based_semantic_chunking_for_dev_reqs 함수 정의 (수정됨)\n",
    "def llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client_instance, llm_model=\"gpt-4o\"):\n",
    "    final_semantic_chunks = []\n",
    "    req_id_counter = 0\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 시스템 요구사항을 전문적으로 분석하고 개발 표준에 맞춰 구조화하는 시니어 비즈니스 분석가입니다.\n",
    "    사용자가 제공하는 텍스트는 RFP 문서의 특정 섹션이며, 여기서 모든 기능적, 비기능적, 성능, 보안, 데이터, 제약사항 요구사항을 추출해야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "\n",
    "    -   **id**: 고유 식별자. 예를 들어, 기능적 요구사항은 \"FUNC-001\", 비기능적은 \"NFR-001\", 보안은 \"SEC-001\"과 같이 유형 접두사와 일련번호를 결합하여 생성하십시오. (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. 다음 중 하나를 선택: \"기능적\", \"비기능적\", \"성능\", \"보안\", \"데이터\", \"제약사항\", \"시스템 장비 구성\", \"컨설팅\", \"테스트\", \"품질\", \"프로젝트 관리\", \"프로젝트 지원\", \"기타\". 텍스트에 명시된 내용에 따라 가장 적합한 유형을 선택하십시오. (예: \"시스템 장비 구성요구사항\", \"컨설팅 요구사항\" 등 PDF의 분류명 활용)\n",
    "    -   **description**: 요구사항에 대한 명확하고 간결한 설명. 원본 PDF의 '요구사항 명칭'과 '정의', '상세설명/세부내용'을 종합하여 개발 친화적인 형태로 작성하십시오. 하나의 요구사항은 하나의 독립적인 기능 또는 특성을 나타내야 합니다.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 검증할 수 있는 구체적인 테스트 조건이나 결과. 1~2개의 명확한 문장으로 서술하십시오. 원본 텍스트에 직접적인 검증 기준이 없더라도, 요구사항의 내용에 기반하여 합리적으로 추론하여 작성하십시오. (예: \"사용자가 [기능]을 수행했을 때, [예상 결과]가 나타난다.\")\n",
    "    -   **priority**: 요구사항의 중요도. 다음 중 하나를 선택: \"필수\", \"높음\", \"중간\", \"낮음\". (텍스트에 명시되어 있다면 그대로 사용, 아니면 일반적으로 \"필수\"로 추정)\n",
    "    -   **responsible_module**: 이 요구사항이 주로 영향을 미치거나 구현될 것으로 예상되는 시스템/애플리케이션의 주요 모듈 또는 영역 (예: \"로그인 모듈\", \"결제 시스템\", \"관리자 페이지\", \"데이터베이스\"). 텍스트 내용을 기반으로 추론하십시오.\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트. 페이지 구분자(`---PAGE_START_N---`)를 참조하여 정확한 페이지 번호를 파싱하십시오.\n",
    "    -   **raw_text_snippet**: 이 요구사항이 포함된 원본 텍스트 스니펫. 해당 요구사항을 추출하는 데 사용된 원본 문장 또는 단락(예: 표의 해당 행 전체 내용)을 포함하십시오.\n",
    "\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 요구사항이 없다면 빈 배열 `[]`을 반환하십시오.\n",
    "    불필요한 서론, 사업 배경, 계약 조건, 제안 지침 등은 요구사항으로 추출하지 마십시오. PDF의 '상세 요구사항' 목록에 있는 구조화된 항목들 위주로 추출해주십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, chunk_doc in enumerate(initial_chunks):\n",
    "        chunk_text = chunk_doc.page_content\n",
    "        print(f\"--- LLM 처리 중 (요구사항 상세 추출): 청크 {i+1}/{len(initial_chunks)} (길이: {len(chunk_text)}자) ---\")\n",
    "\n",
    "        page_numbers_in_chunk = sorted(list(set(\n",
    "            int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text)\n",
    "        )))\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부입니다. 이 부분에서 모든 시스템 요구사항을 개발자 표준에 맞춰 JSON 형식으로 추출해 주세요.\n",
    "        주어진 텍스트 내의 \"요구사항 고유번호\", \"요구사항 명칭\", \"요구사항 분류\", \"정의\", \"상세설명/세부내용\" 등의 명시적 필드를 최대한 활용하여 JSON 객체를 구성해주십시오.\n",
    "\n",
    "        --- 텍스트 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client_instance.chat.completions.create(\n",
    "                model=llm_model,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            llm_response_content = response.choices[0].message.content\n",
    "            try:\n",
    "                extracted_data_outer = json.loads(llm_response_content)\n",
    "                extracted_data_list = []\n",
    "                if isinstance(extracted_data_outer, list):\n",
    "                    extracted_data_list = extracted_data_outer\n",
    "                elif isinstance(extracted_data_outer, dict):\n",
    "                    for key_in_dict in extracted_data_outer:\n",
    "                        if isinstance(extracted_data_outer[key_in_dict], list):\n",
    "                            extracted_data_list = extracted_data_outer[key_in_dict]\n",
    "                            break\n",
    "                    if not extracted_data_list:\n",
    "                        print(f\"경고: LLM이 JSON 객체를 반환했으나, 그 안에 예상된 요구사항 리스트를 찾지 못했습니다. 객체 키: {list(extracted_data_outer.keys())}\")\n",
    "                else:\n",
    "                    print(f\"경고: LLM으로부터 예상치 못한 JSON 형식 응답 (리스트 또는 객체 내 리스트가 아님). {llm_response_content[:100]}...\")\n",
    "                    continue\n",
    "            except json.JSONDecodeError as e_inner:\n",
    "                print(f\"LLM 응답 내용 JSON 파싱 오류 (내부 시도): {e_inner}. 응답: {llm_response_content[:500]}...\")\n",
    "                continue\n",
    "\n",
    "            for req_idx, req in enumerate(extracted_data_list):\n",
    "                original_id = req.get('id')\n",
    "                if not original_id:\n",
    "                    req_type_prefix = \"REQ\"\n",
    "                    req_type = req.get('type', '기타').strip()\n",
    "                    if \"기능\" in req_type: req_type_prefix = \"FUNC\"\n",
    "                    elif \"비기능\" in req_type: req_type_prefix = \"NFR\"\n",
    "                    elif \"성능\" in req_type: req_type_prefix = \"PERF\"\n",
    "                    elif \"보안\" in req_type: req_type_prefix = \"SEC\"\n",
    "                    elif \"데이터\" in req_type: req_type_prefix = \"DATA\"\n",
    "                    elif \"제약\" in req_type: req_type_prefix = \"CONST\"\n",
    "                    elif \"장비\" in req_type: req_type_prefix = \"ECR\"\n",
    "                    elif \"컨설팅\" in req_type: req_type_prefix = \"CSR\"\n",
    "                    elif \"테스트\" in req_type: req_type_prefix = \"TER\"\n",
    "                    elif \"품질\" in req_type: req_type_prefix = \"QUR\"\n",
    "                    elif \"관리\" in req_type: req_type_prefix = \"PMR\"\n",
    "                    elif \"지원\" in req_type: req_type_prefix = \"PSR\"\n",
    "                    req_id_counter += 1\n",
    "                    req['id'] = f\"{req_type_prefix}-{req_id_counter:03d}\"\n",
    "\n",
    "                if 'source_pages' not in req or not req['source_pages']:\n",
    "                    req['source_pages'] = page_numbers_in_chunk if page_numbers_in_chunk else []\n",
    "                \n",
    "                # --- MODIFICATION START: Add detailed source information for raw_text_snippet ---\n",
    "                req['raw_snippet_origin_info'] = {\n",
    "                    \"chunk_index\": i + 1,\n",
    "                    \"chunk_pages\": page_numbers_in_chunk if page_numbers_in_chunk else []\n",
    "                }\n",
    "\n",
    "                if 'raw_text_snippet' not in req or not req['raw_text_snippet']:\n",
    "                    req['raw_text_snippet'] = (\n",
    "                        f\"요구사항 관련 원본 텍스트 스니펫을 LLM으로부터 직접 추출하지 못했습니다. \"\n",
    "                        f\"이 요구사항은 청크 #{i+1} (해당 청크에 포함된 원본 PDF 페이지 번호: {req['raw_snippet_origin_info']['chunk_pages']})에서 식별되었습니다. \"\n",
    "                        f\"해당 청크의 시작 부분: \\\"{chunk_text[:250].strip()}...\\\"\"\n",
    "                    )\n",
    "                    req['raw_text_snippet_source_type'] = \"auto_generated_fallback\"\n",
    "                else:\n",
    "                    req['raw_text_snippet_source_type'] = \"llm_extracted\"\n",
    "                # --- MODIFICATION END ---\n",
    "\n",
    "                req['type'] = req.get('type', '기타')\n",
    "                req['description'] = req.get('description', '설명 없음')\n",
    "                req['acceptance_criteria'] = req.get('acceptance_criteria', '해당하는 경우 명시')\n",
    "                req['priority'] = req.get('priority', '필수')\n",
    "                req['responsible_module'] = req.get('responsible_module', '미정')\n",
    "                final_semantic_chunks.append(req)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"LLM API 호출 또는 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    return final_semantic_chunks\n",
    "\n",
    "\n",
    "# --- LLM으로 목차 파싱하는 함수 (이전 답변에서 제공 및 개선된 버전) ---\n",
    "def parse_toc_with_llm(toc_raw_text, client_instance, llm_model=\"gpt-4o\"): # client_instance로 명칭 변경\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 목차 원문 텍스트를 파싱하여 구조화된 목차 항목을 추출합니다.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 PDF 문서에서 추출된 목차(Table of Contents)의 원시 텍스트를 분석하는 전문가입니다.\n",
    "    주어진 텍스트를 파싱하여 각 목차 항목의 제목, 페이지 번호, 그리고 해당 항목이 '요구사항' 관련 내용을 담고 있을 가능성을 분석하여 JSON 형태로 반환해야 합니다.\n",
    "    JSON의 최상위 레벨은 \"toc_entries\"라는 키를 가진 객체여야 하고, 그 키의 값은 목차 항목 객체들의 리스트여야 합니다.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    다음은 PDF에서 추출한 목차로 추정되는 텍스트입니다:\n",
    "\n",
    "    --- 목차 원문 텍스트 시작 ---\n",
    "    {toc_raw_text}\n",
    "    --- 목차 원문 텍스트 끝 ---\n",
    "\n",
    "    이 텍스트를 분석하여 JSON 객체를 반환해주세요. 이 객체는 \"toc_entries\"라는 키를 가져야 하며,\n",
    "    이 키의 값은 각 목차 항목을 나타내는 객체들의 리스트여야 합니다.\n",
    "    각 목차 항목 객체는 다음 키를 가져야 합니다:\n",
    "    - \"title\": (문자열) 목차 항목의 전체 제목. 제목 앞의 번호(예: \"1.\", \"II.\", \"가.\")도 포함해주세요.\n",
    "    - \"page\": (정수) 해당 항목의 시작 페이지 번호.\n",
    "    - \"is_requirement_related\": (불리언) 제목이나 내용을 볼 때, 해당 항목이 '요구사항', '과업 범위', '제안 요청 상세', '기능 명세', '기술 요건' 등과 관련된 내용을 다룰 가능성이 높으면 true, 그렇지 않으면 false로 설정해주세요.\n",
    "\n",
    "    예시 JSON 출력 형식:\n",
    "    {{\n",
    "      \"toc_entries\": [\n",
    "        {{\n",
    "          \"title\": \"1. 사업 개요\",\n",
    "          \"page\": 5,\n",
    "          \"is_requirement_related\": false\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"III. 제안요청 내용\",\n",
    "          \"page\": 6,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"3. 상세 요구사항\",\n",
    "          \"page\": 11,\n",
    "          \"is_requirement_related\": true\n",
    "        }},\n",
    "        {{\n",
    "          \"title\": \"* 보안 요구사항 별표\",\n",
    "          \"page\": 63,\n",
    "          \"is_requirement_related\": true\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    만약 주어진 텍스트가 유효한 목차로 보이지 않거나 항목을 전혀 파싱할 수 없다면,\n",
    "    \"toc_entries\" 키의 값으로 빈 리스트 `[]`를 포함하는 JSON 객체를 반환해주세요. (예: {{\"toc_entries\": []}})\n",
    "    \"\"\"\n",
    "    llm_response_content = \"\" # 오류 발생 시 로깅을 위해 미리 선언\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        # print(f\"DEBUG: LLM RAW RESPONSE FOR TOC: {llm_response_content}\")\n",
    "\n",
    "        parsed_data = json.loads(llm_response_content)\n",
    "\n",
    "        extracted_list = []\n",
    "        if isinstance(parsed_data, dict) and \"toc_entries\" in parsed_data and isinstance(parsed_data[\"toc_entries\"], list):\n",
    "            extracted_list = parsed_data[\"toc_entries\"]\n",
    "        else:\n",
    "            print(f\"LLM 응답이 예상된 'toc_entries' 리스트를 포함하는 객체 형식이 아닙니다. 응답: {llm_response_content[:200]}\")\n",
    "            return [] # 빈 리스트 반환\n",
    "\n",
    "        valid_entries = []\n",
    "        for entry in extracted_list:\n",
    "            if isinstance(entry, dict) and 'title' in entry and 'page' in entry:\n",
    "                try:\n",
    "                    entry['page'] = int(entry['page'])\n",
    "                    entry['is_requirement_related'] = bool(entry.get('is_requirement_related', False)) # 명확히 불리언으로\n",
    "                    valid_entries.append(entry)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: 페이지 번호 '{entry.get('page')}'를 정수로 변환할 수 없습니다. 항목 건너뜀: {entry.get('title')}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"경고: 필수 키(title, page)가 누락된 항목입니다. 건너뜀: {entry}\")\n",
    "\n",
    "        return valid_entries\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 목차 파싱 응답 JSON 파싱 오류: {e}. 응답 미리보기: {llm_response_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생 (목차 파싱): {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 새로운 헬퍼 함수들 ---\n",
    "def extract_text_for_pages(full_text_with_pages, start_page_num, end_page_num):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 특정 페이지 범위의 텍스트만 추출합니다.\n",
    "    페이지 마커 '---PAGE_START_N---'를 사용합니다.\n",
    "    \"\"\"\n",
    "    if end_page_num < start_page_num:\n",
    "        return \"\"\n",
    "\n",
    "    start_marker = f\"---PAGE_START_{start_page_num}---\"\n",
    "    start_match = re.search(re.escape(start_marker), full_text_with_pages)\n",
    "\n",
    "    if not start_match:\n",
    "        return \"\"\n",
    "\n",
    "    text_from_start_page = full_text_with_pages[start_match.start():]\n",
    "    end_marker_exclusive = f\"---PAGE_START_{end_page_num + 1}---\"\n",
    "    end_match = re.search(re.escape(end_marker_exclusive), text_from_start_page)\n",
    "\n",
    "    if end_match:\n",
    "        return text_from_start_page[:end_match.start()]\n",
    "    else:\n",
    "        return text_from_start_page\n",
    "\n",
    "\n",
    "def get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages):\n",
    "    \"\"\"\n",
    "    LLM으로 파싱된 목차에서 '상세 요구사항' 및 '보안 요구사항' 관련 섹션 정보를 추출합니다.\n",
    "    \"\"\"\n",
    "    target_sections = []\n",
    "    sorted_toc = sorted(parsed_toc_entries, key=lambda x: x.get('page', 0))\n",
    "    keywords_to_find = {\n",
    "        \"상세 요구사항\": {\"min_pages\": 5},\n",
    "        \"보안 요구사항 별표\": {\"min_pages\": 1}\n",
    "    }\n",
    "\n",
    "    for i, entry in enumerate(sorted_toc):\n",
    "        entry_title = entry.get('title', '').strip()\n",
    "        entry_page = entry.get('page', 0)\n",
    "\n",
    "        for keyword, props in keywords_to_find.items():\n",
    "            if keyword in entry_title:\n",
    "                start_page = entry_page\n",
    "                end_page = total_pages\n",
    "                next_major_section_page = total_pages + 1\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page :\n",
    "                        next_major_section_page = next_entry_page\n",
    "                        break\n",
    "                end_page = min(total_pages, next_major_section_page -1)\n",
    "                if end_page < start_page:\n",
    "                    end_page = start_page\n",
    "                \n",
    "                target_sections.append({\n",
    "                    'title': entry_title,\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 파싱 목차 기반: '{entry_title}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "                break \n",
    "    \n",
    "    if not target_sections:\n",
    "        print(\"키워드 기반 섹션 식별 실패. 'is_requirement_related=True' 플래그로 섹션 식별 시도...\")\n",
    "        for i, entry in enumerate(sorted_toc):\n",
    "            if entry.get('is_requirement_related'):\n",
    "                start_page = entry.get('page',0)\n",
    "                end_page = total_pages\n",
    "                next_major_section_page = total_pages + 1\n",
    "                for j in range(i + 1, len(sorted_toc)):\n",
    "                    next_entry = sorted_toc[j]\n",
    "                    next_entry_page = next_entry.get('page', 0)\n",
    "                    if next_entry_page > start_page:\n",
    "                        if not next_entry.get('is_requirement_related', False): \n",
    "                            next_major_section_page = next_entry_page\n",
    "                            break\n",
    "                end_page = min(total_pages, next_major_section_page - 1)\n",
    "                if end_page < start_page: end_page = start_page\n",
    "\n",
    "                target_sections.append({\n",
    "                    'title': entry.get('title', '요구사항 관련 섹션'),\n",
    "                    'start_page': start_page,\n",
    "                    'end_page': end_page\n",
    "                })\n",
    "                print(f\"LLM 'is_requirement_related' 플래그 기반: '{entry.get('title')}' 섹션 (페이지 {start_page}-{end_page}) 식별\")\n",
    "\n",
    "    if not target_sections:\n",
    "        print(\"경고: LLM 파싱 목차에서 주요 요구사항 섹션을 찾지 못했습니다. 전체 문서를 대상으로 할 수 있습니다.\")\n",
    "        return [{'title': '전체 문서 (목차 분석 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    return target_sections\n",
    "\n",
    "\n",
    "def get_toc_raw_text_from_full_text(full_text_with_pages, toc_page_numbers=[2,3]):\n",
    "    \"\"\"\n",
    "    전체 텍스트에서 지정된 목차 페이지들의 텍스트만 추출합니다.\n",
    "    \"\"\"\n",
    "    toc_texts = []\n",
    "    for page_num in toc_page_numbers:\n",
    "        page_content = extract_text_for_pages(full_text_with_pages, page_num, page_num)\n",
    "        if page_content:\n",
    "            marker = f\"---PAGE_START_{page_num}---\\n\"\n",
    "            if page_content.startswith(marker):\n",
    "                toc_texts.append(page_content[len(marker):])\n",
    "            else: \n",
    "                toc_texts.append(page_content)\n",
    "        else:\n",
    "            print(f\"경고: 목차 페이지로 지정된 {page_num} 페이지에서 텍스트를 찾을 수 없습니다.\")\n",
    "\n",
    "    if not toc_texts:\n",
    "        return None\n",
    "    return \"\\n\".join(toc_texts)\n",
    "\n",
    "# --- 메인 실행 블록 ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"./docs/제주은행 모바일뱅킹 재구축사업.pdf\" # 실제 파일 경로\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"오류: PDF 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "        exit()\n",
    "\n",
    "    print(\"1. PDF 전체 텍스트 추출 중...\")\n",
    "    full_document_text, total_pages = extract_text_with_page_info(pdf_file_path)\n",
    "    if not full_document_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다 ({pdf_file_path}).\")\n",
    "        exit()\n",
    "    print(f\"   PDF 전체 텍스트 추출 완료. 총 {total_pages} 페이지, 전체 텍스트 길이: {len(full_document_text)}자.\")\n",
    "\n",
    "    print(\"\\n2. 목차(ToC) 원문 텍스트 추출 중 (지정 페이지: 2, 3)...\")\n",
    "    toc_raw_text = get_toc_raw_text_from_full_text(full_document_text, toc_page_numbers=[2, 3])\n",
    "\n",
    "    target_sections_for_extraction = []\n",
    "    if toc_raw_text:\n",
    "        print(f\"   목차 원문 텍스트 추출 완료 (길이: {len(toc_raw_text)}자).\")\n",
    "        print(\"\\n3. LLM을 사용하여 목차(ToC) 파싱 중...\")\n",
    "        parsed_toc_entries = parse_toc_with_llm(toc_raw_text, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "        if parsed_toc_entries:\n",
    "            print(f\"   LLM 목차 파싱 완료. {len(parsed_toc_entries)}개의 목차 항목 식별.\")\n",
    "            print(\"\\n4. 파싱된 목차에서 주요 요구사항 섹션 범위 식별 중...\")\n",
    "            target_sections_for_extraction = get_target_sections_from_llm_parsed_toc(parsed_toc_entries, total_pages)\n",
    "        else:\n",
    "            print(\"   LLM 목차 파싱 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "            target_sections_for_extraction = [{'title': '전체 문서 (LLM 목차 파싱 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "    else:\n",
    "        print(\"   목차 원문 텍스트 추출 실패. 전체 문서를 대상으로 분석합니다.\")\n",
    "        target_sections_for_extraction = [{'title': '전체 문서 (목차 원문 추출 실패)', 'start_page': 1, 'end_page': total_pages}]\n",
    "\n",
    "    if not target_sections_for_extraction: \n",
    "        print(\"오류: 분석할 대상 섹션을 정의하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n5. 식별된 주요 섹션으로부터 텍스트 결합 중...\")\n",
    "    all_requirements_related_text_parts = []\n",
    "    for section_info in target_sections_for_extraction:\n",
    "        print(f\"   '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']}) 텍스트 추출 시도...\")\n",
    "        section_text = extract_text_for_pages(full_document_text, section_info['start_page'], section_info['end_page'])\n",
    "        if section_text:\n",
    "            all_requirements_related_text_parts.append(section_text)\n",
    "            print(f\"         '{section_info['title']}' 섹션 텍스트 추출 완료 (길이: {len(section_text)}자).\")\n",
    "        else:\n",
    "            print(f\"         경고: '{section_info['title']}' 섹션 (페이지 {section_info['start_page']}-{section_info['end_page']})에서 텍스트를 추출하지 못했습니다.\")\n",
    "\n",
    "    if not all_requirements_related_text_parts:\n",
    "        print(\"오류: 주요 요구사항 섹션에서 텍스트를 전혀 추출하지 못했습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    combined_requirements_text = \"\\n\\n\".join(all_requirements_related_text_parts) \n",
    "    print(f\"   주요 섹션 텍스트 결합 완료. 총 길이: {len(combined_requirements_text)}자.\")\n",
    "\n",
    "    print(\"\\n6. 결합된 텍스트 초기 분할 중...\")\n",
    "    initial_chunks = initial_text_split(combined_requirements_text, chunk_size=3500, chunk_overlap=350)\n",
    "    print(f\"   총 {len(initial_chunks)}개의 초기 청크가 생성되었습니다.\")\n",
    "\n",
    "    if not initial_chunks:\n",
    "        print(\"오류: 텍스트 분할 결과 청크가 없습니다. 프로그램을 종료합니다.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n7. LLM을 이용한 개발자 표준 요구사항 상세 추출 시작...\")\n",
    "    extracted_requirements = llm_based_semantic_chunking_for_dev_reqs(initial_chunks, client, llm_model=LLM_MODEL_FOR_PARSING)\n",
    "\n",
    "    print(\"\\n8. 후처리: ID 중복 제거 및 최종 정렬 (옵션)...\")\n",
    "    unique_requirements_by_id = {}\n",
    "    processed_requirements = []\n",
    "    if extracted_requirements:\n",
    "        for req in extracted_requirements:\n",
    "            req_id = req.get('id', str(uuid.uuid4())) \n",
    "            if req_id not in unique_requirements_by_id:\n",
    "                unique_requirements_by_id[req_id] = req\n",
    "            else:\n",
    "                existing_req = unique_requirements_by_id[req_id]\n",
    "                new_pages = req.get('source_pages', [])\n",
    "                if new_pages:\n",
    "                    existing_req_pages = existing_req.get('source_pages', [])\n",
    "                    existing_req['source_pages'] = sorted(list(set(existing_req_pages + new_pages)))\n",
    "                print(f\"중복 ID '{req_id}' 감지. 정보 업데이트 시도.\")\n",
    "        processed_requirements = list(unique_requirements_by_id.values())\n",
    "    else:\n",
    "        print(\"   추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    print(f\"\\n--- 최종 추출된 고유 요구사항 수: {len(processed_requirements)}개 ---\")\n",
    "    if processed_requirements:\n",
    "        print(\"\\n--- 추출된 요구사항 미리보기 (상위 3개) ---\")\n",
    "        for i, req_item in enumerate(processed_requirements[:3]): \n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        output_filename = \"extracted_requirements_final.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"\\n추출된 요구사항이 '{output_filename}' 파일에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"최종적으로 추출된 요구사항이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RFP 요구사항 추출 전문가 시스템 시작 (입력 파일: ./docs/제주은행 모바일뱅킹 재구축사업.pdf) ---\n",
      "1. PDF 텍스트 추출 완료: 총 54 페이지, 전체 텍스트 길이 57553자.\n",
      "2. 문서 청킹 완료: 총 19개 청크 생성 (overlap: 800).\n",
      "\n",
      "--- 패스 1: 광범위하고 포괄적인 요구사항 후보 식별 시작 ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 1/19 (원본 페이지: [1, 2]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 2/19 (원본 페이지: [3]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 3/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 4/19 (원본 페이지: [4]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 5/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 6/19 (원본 페이지: [5, 6, 7]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 7/19 (원본 페이지: [8, 9]) ---\n",
      "LLM 응답 JSON 파싱 오류: Unterminated string starting at: line 331 column 33 (char 12338). 응답: {\n",
      "    \"requirements_found\": [\n",
      "        {\n",
      "            \"id\": \"REQ-001\",\n",
      "            \"type\": \"기능적\",\n",
      "            \"description\": \"앱 구동 및 로그인, 조회, 이체에 대한 속도 개선\",\n",
      "            \"acceptance_criteria\": \"앱 구동 및 로그인, 조회, 이체 시 속도 개선이 확인됨\",\n",
      "            \"priority\": \"필수\",\n",
      "            \"responsible_module\": \"모바일 앱\",\n",
      "            \"source_pages\": [8],\n",
      "            \"raw_text_snippet\": \"앱 구동 및 로그인, 조회, 이체에 대한 속도 개선\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"REQ-002\",\n",
      "            \"type\": \"기능적\",\n",
      "            \"description\": \"효...\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 8/19 (원본 페이지: [10, 11, 12, 13, 14]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 9/19 (원본 페이지: [15, 16, 17, 18]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 10/19 (원본 페이지: [19, 20, 21, 22]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 11/19 (원본 페이지: [22, 23, 24, 25, 26, 27]) ---\n",
      "LLM 응답 JSON 파싱 오류: Unterminated string starting at: line 309 column 9 (char 11005). 응답: {\"requirements_found\": [\n",
      "    {\n",
      "        \"id\": \"REQ-001\",\n",
      "        \"type\": \"테스트\",\n",
      "        \"description\": \"테스트 결과에 대한 객관적 검증 및 테스트 품질향상을 위한 방안 제시\",\n",
      "        \"acceptance_criteria\": \"제안된 방안의 문서 제출 및 승인\",\n",
      "        \"priority\": \"필수\",\n",
      "        \"responsible_module\": \"테스트 팀\",\n",
      "        \"source_pages\": [22],\n",
      "        \"raw_text_snippet\": \"테스트 결과에 대한 객관적 검증 및 테스트 품질향상을 위한 방안 제시\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"REQ-002\",\n",
      "        \"type\": \"테스트\",\n",
      "        \"description\": \"단위 테스트 수행 방안 제시\",\n",
      "        \"acceptance_criteria\": \"단위 테...\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 12/19 (원본 페이지: [27, 28, 29, 30, 31]) ---\n",
      "LLM 응답 JSON 파싱 오류: Unterminated string starting at: line 270 column 29 (char 10365). 응답: {\"requirements_found\": [\n",
      "    {\n",
      "        \"id\": \"REQ-001\",\n",
      "        \"type\": \"표준준수\",\n",
      "        \"description\": \"당행 차세대 시스템 구축 아키텍처 표준을 준수해야 함\",\n",
      "        \"acceptance_criteria\": \"차세대 아키텍처 표준 준수 여부 확인\",\n",
      "        \"priority\": \"필수\",\n",
      "        \"responsible_module\": \"제안사 전체\",\n",
      "        \"source_pages\": [27],\n",
      "        \"raw_text_snippet\": \"당행 차세대 시스템 구축 아키텍처 표준을 준수해야 함\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"REQ-002\",\n",
      "        \"type\": \"표준준수\",\n",
      "        \"description\": \"TA(Technical Architecture) 차세대 표준을 준수해야 함: OS, 보안, DIR 체계, Log 체계 및...\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 13/19 (원본 페이지: [31, 32, 33, 34]) ---\n",
      "LLM 응답 JSON 파싱 오류: Unterminated string starting at: line 255 column 24 (char 9890). 응답: {\"requirements_found\": [\n",
      "    {\n",
      "        \"id\": \"8.1.10\",\n",
      "        \"type\": \"기타\",\n",
      "        \"description\": \"제안 요청서 수령 후 부득이한 사유로 제안을 포기하는 업체는 반드시 공문(대표이사 직인날인)으로 회신하여야 함\",\n",
      "        \"acceptance_criteria\": \"공문 제출 여부 확인\",\n",
      "        \"priority\": \"필수\",\n",
      "        \"responsible_module\": \"제안사 전체\",\n",
      "        \"source_pages\": [31],\n",
      "        \"raw_text_snippet\": \"제안 요청서 수령 후 부득이한 사유로 제안을 포기하는 업체는 반드시 공문(대표이사 직인날인)으로 회신하여야 함\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"8.2.1\",\n",
      "        \"type\": \"기타\",\n",
      "        \"description\": \"모든 문서의 언어는 한글을 원칙으로...\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 14/19 (원본 페이지: [35, 36, 37]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 15/19 (원본 페이지: [38, 39, 40]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 16/19 (원본 페이지: [41, 42, 43]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 17/19 (원본 페이지: [44, 45, 46, 47, 48, 49]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 18/19 (원본 페이지: [48, 49, 50, 51, 52, 53]) ---\n",
      "--- 전문가 패스 1: 후보 식별 중 - 청크 19/19 (원본 페이지: [54]) ---\n",
      "--- 전문가 패스 1 완료: 총 223개의 잠재적 요구사항 후보 식별 ---\n",
      "\n",
      "--- 패스 2: 추가 탐색 및 보완 추출 시작 ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 1/19 (원본 페이지: [1, 2]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 2/19 (원본 페이지: [3]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 3/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 4/19 (원본 페이지: [4]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 5/19 (원본 페이지: []) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 6/19 (원본 페이지: [5, 6, 7]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 7/19 (원본 페이지: [8, 9]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 8/19 (원본 페이지: [10, 11, 12, 13, 14]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 9/19 (원본 페이지: [15, 16, 17, 18]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 10/19 (원본 페이지: [19, 20, 21, 22]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 11/19 (원본 페이지: [22, 23, 24, 25, 26, 27]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 12/19 (원본 페이지: [27, 28, 29, 30, 31]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 13/19 (원본 페이지: [31, 32, 33, 34]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 14/19 (원본 페이지: [35, 36, 37]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 15/19 (원본 페이지: [38, 39, 40]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 16/19 (원본 페이지: [41, 42, 43]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 17/19 (원본 페이지: [44, 45, 46, 47, 48, 49]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 18/19 (원본 페이지: [48, 49, 50, 51, 52, 53]) ---\n",
      "--- 전문가 패스 2: 추가/보완 추출 중 - 청크 19/19 (원본 페이지: [54]) ---\n",
      "--- 전문가 패스 2 완료: 89개의 추가/보완 요구사항 식별 ---\n",
      "\n",
      "모든 패스에서 총 312개의 요구사항 후보 수집 (중복 포함).\n",
      "\n",
      "--- 후처리 작업 시작 (제외할 타입: ['기타', '산출물', '정책준수', '프로젝트 지원']) ---\n",
      "\n",
      "--- 전문가 후처리 시작: 초기 312개 항목 ---\n",
      "    타입 기반 필터링: '기타, 산출물, 정책준수, 프로젝트 지원' 타입 제외 후 299개 항목 (이전: 312개)\n",
      "    내용 기반 중복 제거 후: 299개 항목\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 397\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;66;03m# <<< ------------------------------------ >>>\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 후처리 작업 시작 (제외할 타입: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes_to_exclude_user_defined\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m final_processed_requirements = \u001b[43mexpert_post_process_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_combined_requirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes_to_exclude_user_defined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m final_processed_requirements:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 최종 추출된 고유 요구사항: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_processed_requirements)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 351\u001b[39m, in \u001b[36mexpert_post_process_requirements\u001b[39m\u001b[34m(requirements, exclude_types)\u001b[39m\n\u001b[32m    347\u001b[39m     req_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mtemp_merged_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    349\u001b[39m     final_requirements.append(req_dict)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[43mfinal_requirements\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msource_pages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- 전문가 후처리 완료: 최종 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_requirements)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 요구사항 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_requirements\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 351\u001b[39m, in \u001b[36mexpert_post_process_requirements.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    347\u001b[39m     req_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mtemp_merged_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    349\u001b[39m     final_requirements.append(req_dict)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m final_requirements.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msource_pages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, x.get(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m    353\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- 전문가 후처리 완료: 최종 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_requirements)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 요구사항 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_requirements\n",
      "\u001b[31mValueError\u001b[39m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "\n",
    "# --- OpenAI API 클라이언트 초기화 ---\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. API 키를 설정해주세요.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "# === 1. 전처리 함수 ===\n",
    "def expert_extract_text_with_pages(pdf_path: str) -> Tuple[str, int]:\n",
    "    document = fitz.open(pdf_path)\n",
    "    full_text_with_pages = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text = page.get_text(\"text\", sort=True) \n",
    "        full_text_with_pages.append(f\"---PAGE_START_{page_num+1}---\\n{text.strip()}\")\n",
    "    return \"\\n\\n\".join(full_text_with_pages), document.page_count\n",
    "\n",
    "def expert_create_chunks(full_text: str, chunk_size: int = 4000, chunk_overlap: int = 500) -> List[Dict[str, Any]]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n---PAGE_START_\\d+---\\n\", \"\\n\\n\\n\", \"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    docs_langchain = text_splitter.create_documents([full_text])\n",
    "    \n",
    "    chunks = []\n",
    "    for i, doc_lc in enumerate(docs_langchain):\n",
    "        chunk_text = doc_lc.page_content\n",
    "        page_numbers = sorted(list(set(int(p) for p in re.findall(r'---PAGE_START_(\\d+)---', chunk_text))))\n",
    "        chunks.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk_text,\n",
    "            \"source_pages_in_chunk\": page_numbers\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# === 2. LLM 호출 헬퍼 함수 ===\n",
    "def expert_llm_call(system_prompt: str, user_prompt: str, client_instance: OpenAI, model: str, expect_single_object: bool = False) -> Union[List[Dict[str, Any]], Dict[str, Any], None]:\n",
    "    llm_response_content = \"\"\n",
    "    try:\n",
    "        response = client_instance.chat.completions.create(\n",
    "            model=model,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=4000 \n",
    "        )\n",
    "        llm_response_content = response.choices[0].message.content\n",
    "        parsed_output = json.loads(llm_response_content)\n",
    "\n",
    "        if expect_single_object:\n",
    "            if isinstance(parsed_output, dict):\n",
    "                return parsed_output\n",
    "            else:\n",
    "                if isinstance(parsed_output, list) and len(parsed_output) == 1 and isinstance(parsed_output[0], dict):\n",
    "                    print(f\"정보: 단일 JSON 객체를 예상했으나 리스트로 감싸인 객체를 받았습니다. 첫 번째 항목 사용. 내용: {str(parsed_output[0])[:100]}\")\n",
    "                    return parsed_output[0]\n",
    "                print(f\"경고: 단일 JSON 객체를 예상했으나 다른 타입/구조를 받았습니다: {type(parsed_output)}. 내용: {llm_response_content[:200]}\")\n",
    "                return None \n",
    "        else: \n",
    "            if isinstance(parsed_output, dict):\n",
    "                for key, value in parsed_output.items():\n",
    "                    if isinstance(value, list):\n",
    "                        if all(isinstance(item, dict) for item in value):\n",
    "                            return value\n",
    "                print(f\"경고: LLM이 JSON 객체를 반환했으나, 내부에 예상된 리스트를 찾지 못했습니다. 키: {list(parsed_output.keys())}, 내용: {str(parsed_output)[:200]}\")\n",
    "                return []\n",
    "            elif isinstance(parsed_output, list):\n",
    "                if all(isinstance(item, dict) for item in parsed_output):\n",
    "                    return parsed_output\n",
    "                else:\n",
    "                    print(f\"경고: LLM이 리스트를 반환했으나, 일부 항목이 딕셔너리가 아닙니다.\")\n",
    "                    return [item for item in parsed_output if isinstance(item, dict)]\n",
    "            else:\n",
    "                print(f\"경고: LLM으로부터 예상치 못한 JSON 루트 형식 응답 (리스트 또는 객체가 아님): {llm_response_content[:200]}...\")\n",
    "                return []\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 응답: {llm_response_content[:500]}...\")\n",
    "        return None if expect_single_object else []\n",
    "    except Exception as e:\n",
    "        print(f\"LLM API 호출 또는 처리 중 오류 발생: {type(e).__name__} {e}\")\n",
    "        if llm_response_content:\n",
    "            print(f\"오류 발생 시 LLM 응답 일부: {llm_response_content[:500]}...\")\n",
    "        return None if expect_single_object else []\n",
    "\n",
    "# === 3. 패스별 시스템 프롬프트 정의 ===\n",
    "def get_expert_system_prompt(pass_number=1):\n",
    "    system_prompt_pass1 = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서에서 시스템 요구사항을 전문적으로 분석하고 개발 표준에 맞춰 구조화하는 시니어 비즈니스 분석가입니다.\n",
    "    사용자가 제공하는 텍스트는 RFP 문서의 일부이며, 여기서 모든 기능적, 비기능적, 성능, 보안, 데이터, 제약사항 등 **모든 종류의 시스템 요구사항 후보**를 추출해야 합니다.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "    -   **id**: 고유 식별자. (RFP 원문에 ID가 있다면 그것을 우선 사용)\n",
    "    -   **type**: 요구사항의 유형. (\"기능적\", \"비기능적\", \"성능\", \"보안\", \"데이터\", \"제약사항\", \"시스템 장비 구성\", \"컨설팅\", \"테스트\", \"품질\", \"프로젝트 관리\", \"프로젝트 지원\", \"운영\", \"표준준수\", \"기타\")\n",
    "    -   **description**: 요구사항에 대한 명확하고 간결한 설명. 원본 텍스트의 핵심 내용을 정확히 반영해야 합니다.\n",
    "    -   **acceptance_criteria**: 이 요구사항이 충족되었음을 검증할 수 있는 구체적인 테스트 조건이나 결과. (추론이 어렵거나 해당 없으면 유연하게 작성)\n",
    "    -   **priority**: 요구사항의 중요도. (텍스트에 명시되어 있다면 그대로 사용, 아니면 일반적으로 \"필수\"로 추정)\n",
    "    -   **responsible_module**: 이 요구사항이 주로 영향을 미치거나 구현될 것으로 예상되는 시스템/애플리케이션의 주요 모듈 또는 영역. (추론이 어렵거나 해당 없으면 유연하게 작성)\n",
    "    -   **source_pages**: 이 요구사항이 발견된 원본 PDF 페이지 번호 리스트.\n",
    "    -   **raw_text_snippet**: 이 요구사항이 포함된 원본 텍스트 스니펫 (추출 근거가 된 문장 또는 단락 전체).\n",
    "\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 요구사항이 없다면 빈 배열 `[]`을 반환하십시오. (실제로는 response_format 지침에 따라 {\"키\": [...]} 형태로 반환될 수 있으며, 이 경우 해당 \"키\"의 값을 사용합니다.)\n",
    "\n",
    "    **패스 1 중요 지침 (매우 관대하고 포괄적으로 추출):**\n",
    "    1.  텍스트 전체를 면밀히 검토하여, 명시적인 요구사항뿐만 아니라 **묵시적으로 요구사항으로 해석될 수 있는 모든 내용**을 포함해 주십시오.\n",
    "    2.  요구사항은 특정 섹션에만 국한되지 않을 수 있습니다. 문서의 **어떤 부분에서든** 발견될 수 있는 요구사항을 모두 찾아내야 합니다.\n",
    "    3.  **단 하나의 잠재적인 요구사항도 놓치지 않는 것이 매우 중요합니다.** 만약 어떤 내용이 요구사항인지 아닌지 판단하기 애매하거나 경계선에 있는 경우에도, **요구사항일 가능성이 조금이라도 있다면 일단 추출**하고, 'type'은 가장 적절하다고 생각되는 유형 또는 '기타'로 지정해주십시오.\n",
    "    4.  **목표는 최대한 많은 후보를 찾는 것입니다. 정밀도보다는 재현율(Recall)을 극대화해주세요.**\n",
    "\n",
    "    5.  **다양한 유형의 요구사항 식별 (매우 중요):** 시스템의 직접적인 기능/성능 외에도, 다음과 같은 내용들을 모두 중요한 요구사항으로 간주하고 추출하십시오:\n",
    "        a.  **제안 제품(H/W, S/W) 조건:** 제품의 상태(예: 단종 여부), 변경 가능성, 공급업체 안정성, 기술 지원 조건, 라이선스 정책, 소스코드 제공 의무 등.\n",
    "            (예: \"생산중단 계획이 없는 제품을 제안하여야 함\", \"제조사의 공급 확약서 및 기술지원 확약서 첨부해야 함\", \"프로그램 소스를 당행에 제공하여야 함\")\n",
    "        b.  **시스템 운영 조건:** 관련 규정 준수 의무, 시스템 관리/장애처리/모니터링/백업 등의 운영 방안 범위, 역할/책임 명시 의무, 솔루션 연계 방안 제시 의무 등.\n",
    "            (예: \"대내외 전산 관리 규정을 준수하여야 함\", \"운영조직은 역할 및 담당 책임자를 명확히 명시해야 함\")\n",
    "        c.  **표준화 및 정책 준수:** 은행 내부 특정 표준(통합백업, SMS, NMS, 통합콘솔, 형상관리, 채널통합(MCI) 및 EAI표준, 데이터 표준화 지침 및 메타시스템 정책, 웹 표준 등) 준수 의무, 특정 개발 방법론 적용 의무 등.\n",
    "            (예: \"당행의 통합백업정책을 준수해야 함\", \"웹 표준기술(HTML5)을 사용해야 함\")\n",
    "        d.  **프로젝트 관리 및 수행 절차:** 단계별 목표/절차/산출물 제시 의무, 테스트 방안/계획 제시 및 승인 의무, 보고 의무, 인력 관리 조건, 보안 대책 수립 및 준수 의무 등.\n",
    "            (예: \"일정별 개발 방안을 제시해야 함\", \"테스트 계획을 구체적으로 수립하고 당행의 승인을 받아야 함\")\n",
    "        e.  **기타 계약 조건 및 제약사항:** 지식재산권, 법적 책임, 하자보수 조건, 추가 요소 지원 의무, 도입 누락 책임 등.\n",
    "            (예: \"도입 누락에 따른 책임은 제안사에 있음\", \"법률상의 문제에 대한 일체의 책임을 져야 함\")\n",
    "\n",
    "    6.  **JSON 필드 작성 유연성:** 위 5번 항목과 같은 유형의 요구사항에 대해 `type`은 \"제약사항\", \"품질\", \"프로젝트 관리\", \"프로젝트 지원\", \"보안\", \"운영\", \"표준준수\", \"기타\" 등으로 분류하고, `acceptance_criteria`는 \"관련 문서 제출 및 승인\", \"해당 표준/정책 준수여부 확인\", \"관련 확약서 제출\", \"계약서 명시 및 이행\" 등으로 기술하거나, 명확한 기준 설정이 어려울 경우 \"해당 없음\" 또는 \"세부 협의\" 등으로 작성해도 됩니다. `responsible_module`도 \"제안사 전체\", \"프로젝트 팀\" 등으로 포괄적으로 지정하거나 비워둘 수 있습니다. **가장 중요한 것은 `description`에 원본 요구사항의 핵심 내용을 정확히 담는 것입니다.** `priority`는 명시되어 있지 않으면 \"필수\"로 간주하십시오.\n",
    "    \n",
    "    LLM 응답은 `{\"requirements_found\": [...]}` 형태의 JSON 객체여야 하며, `requirements_found` 키의 값이 실제 요구사항 객체들의 배열입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt_pass2 = \"\"\"\n",
    "    당신은 RFP(제안요청서) 문서를 매우 꼼꼼하게 재검토하여, 이전 분석에서 놓쳤을 수 있는 추가적인 시스템 요구사항을 발굴하는 전문가입니다.\n",
    "    사용자가 제공하는 텍스트(이전 패스에서 이미 한 번 검토되었을 수 있음)를 새로운 관점에서 다시 한번 분석하여, 숨겨져 있거나 간과된 요구사항을 찾아내 주십시오.\n",
    "\n",
    "    각 요구사항은 다음 속성을 포함하는 JSON 객체로 정의되어야 합니다.\n",
    "    (JSON 구조 설명은 Pass 1과 동일)\n",
    "    -   **id**: ...\n",
    "    -   **type**: ...\n",
    "    -   **description**: ...\n",
    "    -   **acceptance_criteria**: ...\n",
    "    -   **priority**: ...\n",
    "    -   **responsible_module**: ...\n",
    "    -   **source_pages**: ...\n",
    "    -   **raw_text_snippet**: ...\n",
    "    응답은 **JSON 배열 형식으로만** 제공해야 합니다. 만약 추가 요구사항이 없다면 빈 배열 `[]`을 반환하십시오. (실제로는 response_format 지침에 따라 {\"키\": [...]} 형태로 반환될 수 있으며, 이 경우 해당 \"키\"의 값을 사용합니다.)\n",
    "    \"JSON 객체의 id를 제외한 모든 값은 한국어로 기술되어야 합니다.\"\n",
    "    **패스 2 중요 지침 (새로운 관점에서 누락된 부분 찾기):**\n",
    "    1.  이 텍스트는 이미 요구사항 추출 시도가 있었을 수 있다는 점을 감안하고, **이전에 명백하게 추출되지 않았을 것 같은 요구사항들**에 집중해주십시오.\n",
    "    2.  특히, 문맥 속에 숨겨져 있거나, 비기능적 특성(성능, 보안, 사용성, 안정성 등), 제약 조건, 품질 요구사항, 데이터 관련 요구사항 등 **일반적인 기능 목록에서 쉽게 누락될 수 있는 유형**의 요구사항에 주의를 기울여 주십시오. Pass 1에서 놓쳤을 만한 세부적인 정책 준수, 운영 절차, 제품 조건 등을 다시 한번 확인해주십시오.\n",
    "    3.  애매하거나 해석의 여지가 있는 부분도, 요구사항으로 볼 수 있는 합리적인 근거가 있다면 포함시켜 주십시오.\n",
    "    4.  **첫 번째 분석에서 놓쳤을 만한 것들을 찾아내는 것이 목표입니다.** `description`은 명확하게, `acceptance_criteria`는 가능한 구체적으로 작성하되, 어려우면 \"세부 협의\" 등으로 명시하십시오.\n",
    "    \n",
    "    LLM 응답은 `{\"additional_requirements_found\": [...]}` 형태의 JSON 객체여야 하며, `additional_requirements_found` 키의 값이 실제 요구사항 객체들의 배열입니다.\n",
    "    \"\"\"\n",
    "    if pass_number == 1:\n",
    "        return system_prompt_pass1\n",
    "    elif pass_number == 2:\n",
    "        return system_prompt_pass2\n",
    "    else: \n",
    "        return system_prompt_pass1\n",
    "\n",
    "\n",
    "# === 4. 패스 1 실행 함수 ===\n",
    "def expert_pass1_identify_candidates(chunks: List[Dict[str, Any]], client_instance: OpenAI, model: str) -> List[Dict[str, Any]]:\n",
    "    system_prompt = get_expert_system_prompt(pass_number=1)\n",
    "    all_candidates = []\n",
    "    for i, chunk_data in enumerate(chunks):\n",
    "        chunk_text = chunk_data[\"text\"]\n",
    "        chunk_pages = chunk_data[\"source_pages_in_chunk\"]\n",
    "        print(f\"--- 전문가 패스 1: 후보 식별 중 - 청크 {i+1}/{len(chunks)} (원본 페이지: {chunk_pages}) ---\")\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부 텍스트 청크입니다. 이 청크 내에서 시스템 프롬프트의 지침에 따라 모든 '잠재적 요구사항 후보' 텍스트를 식별하여 요청된 JSON 형식으로 응답해주십시오. \n",
    "        `source_pages` 필드에는 이 청크에 해당하는 원본 페이지 번호인 {chunk_pages}를 사용하십시오. (후보 텍스트가 특정 페이지에서 시작된 것을 알 수 있다면 해당 페이지 번호만 사용해도 좋습니다.)\n",
    "\n",
    "        --- 텍스트 청크 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass 1은 LLM이 {\"requirements_found\": [...]} 로 반환하도록 유도\n",
    "        # expert_llm_call은 이 내부 리스트를 반환함\n",
    "        candidates_from_chunk_list = expert_llm_call(system_prompt, user_prompt, client_instance, model, expect_single_object=False) \n",
    "        \n",
    "        if isinstance(candidates_from_chunk_list, list):\n",
    "            for cand_idx, cand in enumerate(candidates_from_chunk_list):\n",
    "                if isinstance(cand, dict) and \"description\" in cand and \"type\" in cand: # Pass1도 기본 구조는 채우도록 유도\n",
    "                    cand[\"pass_info\"] = {\"pass\": 1, \"chunk_id\": chunk_data[\"chunk_id\"], \"candidate_index_in_chunk\": cand_idx}\n",
    "                    if not cand.get(\"source_pages\") or not isinstance(cand.get(\"source_pages\"), list) :\n",
    "                        cand[\"source_pages\"] = chunk_pages # 페이지 정보가 없다면 청크 전체 페이지로\n",
    "                    all_candidates.append(cand)\n",
    "                else:\n",
    "                    print(f\"경고 (패스1, 청크 {i+1}): 후보 항목에 주요 키 또는 올바른 타입 누락. 항목: {str(cand)[:100]}\")\n",
    "        else:\n",
    "            print(f\"경고 (패스1, 청크 {i+1}): expert_llm_call로부터 리스트가 아닌 결과 반환. 결과: {str(candidates_from_chunk_list)[:100]}\")\n",
    "\n",
    "    print(f\"--- 전문가 패스 1 완료: 총 {len(all_candidates)}개의 잠재적 요구사항 후보 식별 ---\")\n",
    "    return all_candidates\n",
    "\n",
    "# === 5. 패스 2 실행 함수 ===\n",
    "def expert_pass2_refine_and_add(\n",
    "    chunks: List[Dict[str, Any]], # 패스 1과 동일한 청크 사용\n",
    "    client_instance: OpenAI, \n",
    "    model: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    system_prompt = get_expert_system_prompt(pass_number=2)\n",
    "    additional_requirements = []\n",
    "    for i, chunk_data in enumerate(chunks): # 전체 청크를 다시 한번 검토\n",
    "        chunk_text = chunk_data[\"text\"]\n",
    "        chunk_pages = chunk_data[\"source_pages_in_chunk\"]\n",
    "        print(f\"--- 전문가 패스 2: 추가/보완 추출 중 - 청크 {i+1}/{len(chunks)} (원본 페이지: {chunk_pages}) ---\")\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        다음은 RFP 문서의 일부 텍스트 청크입니다. 이전에 이미 한 번 검토되었을 수 있습니다.\n",
    "        시스템 프롬프트의 지침에 따라, 이 청크에서 **이전에 놓쳤을 가능성이 있는 추가적인 요구사항**을 찾아내어 요청된 JSON 형식으로 응답해주십시오.\n",
    "        `source_pages` 필드에는 이 청크에 해당하는 원본 페이지 번호인 {chunk_pages}를 사용하십시오.\n",
    "\n",
    "        --- 텍스트 청크 ---\n",
    "        {chunk_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass 2도 LLM이 {\"additional_requirements_found\": [...]} 로 반환하도록 유도\n",
    "        newly_found_reqs_list = expert_llm_call(system_prompt, user_prompt, client_instance, model, expect_single_object=False)\n",
    "\n",
    "        if isinstance(newly_found_reqs_list, list):\n",
    "            for req_idx, req in enumerate(newly_found_reqs_list):\n",
    "                if isinstance(req, dict) and \"description\" in req and \"type\" in req:\n",
    "                    req[\"pass_info\"] = {\"pass\": 2, \"chunk_id\": chunk_data[\"chunk_id\"], \"item_index_in_chunk\": req_idx}\n",
    "                    if not req.get(\"source_pages\") or not isinstance(req.get(\"source_pages\"), list) :\n",
    "                        req[\"source_pages\"] = chunk_pages\n",
    "                    additional_requirements.append(req)\n",
    "                else:\n",
    "                    print(f\"경고 (패스2, 청크 {i+1}): 항목에 주요 키 또는 올바른 타입 누락. 항목: {str(req)[:100]}\")\n",
    "        else:\n",
    "             print(f\"경고 (패스2, 청크 {i+1}): expert_llm_call로부터 리스트가 아닌 결과 반환. 결과: {str(newly_found_reqs_list)[:100]}\")\n",
    "\n",
    "\n",
    "    print(f\"--- 전문가 패스 2 완료: {len(additional_requirements)}개의 추가/보완 요구사항 식별 ---\")\n",
    "    return additional_requirements\n",
    "\n",
    "\n",
    "# === 6. 후처리 함수 (수정됨) ===\n",
    "def expert_post_process_requirements(requirements: List[Dict[str, Any]], exclude_types: List[str] = None) -> List[Dict[str, Any]]:\n",
    "    if exclude_types is None:\n",
    "        exclude_types = [] \n",
    "    \n",
    "    print(f\"\\n--- 전문가 후처리 시작: 초기 {len(requirements)}개 항목 ---\")\n",
    "    if not requirements:\n",
    "        return []\n",
    "\n",
    "    # 0. 지정된 타입 필터링\n",
    "    if exclude_types:\n",
    "        initial_count_before_type_filter = len(requirements)\n",
    "        requirements = [req for req in requirements if req.get(\"type\") not in exclude_types]\n",
    "        print(f\"    타입 기반 필터링: '{', '.join(exclude_types)}' 타입 제외 후 {len(requirements)}개 항목 (이전: {initial_count_before_type_filter}개)\")\n",
    "\n",
    "    # 1. 내용 기반 중복 제거\n",
    "    unique_reqs_by_content = {}\n",
    "    for req in requirements:\n",
    "        desc_key = \"\".join(req.get('description', '').strip().lower().split())[:80]\n",
    "        snippet_key = \"\".join(req.get('raw_text_snippet', '').strip().lower().split())[:80]\n",
    "        page_key_list = sorted(list(set(int(p) for p in req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit()))) # 정수 변환 추가\n",
    "        page_key = \"_p\" + str(page_key_list[0]) if page_key_list else \"_p0\"\n",
    "        content_key = f\"{desc_key}_{snippet_key}_{page_key}\" # 더 정확한 중복 판단을 위해 키 조합\n",
    "\n",
    "        original_req_id = req.get('id', '') # LLM이 부여한 ID 또는 패스에서 생성된 임시ID\n",
    "\n",
    "        if content_key not in unique_reqs_by_content:\n",
    "            req[\"temp_merged_ids\"] = [original_req_id] # 병합될 ID들 추적\n",
    "            unique_reqs_by_content[content_key] = req\n",
    "        else:\n",
    "            existing_req = unique_reqs_by_content[content_key]\n",
    "            print(f\"    내용 기반 중복 발견. 키: '{content_key[:50]}...'. 기존ID: '{existing_req.get('id', 'N/A')}', 새ID: '{original_req_id}'. 정보 병합.\")\n",
    "            \n",
    "            new_pages = [int(p) for p in req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit()]\n",
    "            existing_pages = [int(p) for p in existing_req.get('source_pages', []) if isinstance(p, (int,str)) and str(p).isdigit()]\n",
    "            existing_req['source_pages'] = sorted(list(set(existing_pages + new_pages)))\n",
    "\n",
    "            if len(req.get('description', '')) > len(existing_req.get('description', '')):\n",
    "                existing_req['description'] = req.get('description')\n",
    "            if len(req.get('raw_text_snippet', '')) > len(existing_req.get('raw_text_snippet', '')):\n",
    "                 existing_req['raw_text_snippet'] = req.get('raw_text_snippet')\n",
    "            \n",
    "            # 패스 정보 활용하여 병합 (예: pass_info가 더 나중 것으로 업데이트)\n",
    "            current_pass_info = req.get('pass_info', {})\n",
    "            existing_pass_info = existing_req.get('pass_info', {})\n",
    "            if current_pass_info.get('pass', 0) > existing_pass_info.get('pass', 0):\n",
    "                existing_req['pass_info'] = current_pass_info\n",
    "                # 더 나중 패스의 type, acceptance_criteria 등을 우선 적용할 수 있음\n",
    "                if req.get('type') != '기타' or existing_req.get('type') == '기타': existing_req['type'] = req.get('type')\n",
    "                ac_placeholder = ['추후 분석 필요', '해당하는 경우 명시', '해당 없음', '세부 협의']\n",
    "                if req.get('acceptance_criteria') not in ac_placeholder or existing_req.get('acceptance_criteria') in ac_placeholder:\n",
    "                    existing_req['acceptance_criteria'] = req.get('acceptance_criteria')\n",
    "\n",
    "            if 'temp_merged_ids' in existing_req and isinstance(existing_req['temp_merged_ids'], list):\n",
    "                 existing_req['temp_merged_ids'].append(original_req_id)\n",
    "            else:\n",
    "                 existing_req['temp_merged_ids'] = [existing_req.get('id',''), original_req_id]\n",
    "\n",
    "\n",
    "    deduplicated_requirements = list(unique_reqs_by_content.values())\n",
    "    print(f\"    내용 기반 중복 제거 후: {len(deduplicated_requirements)}개 항목\")\n",
    "\n",
    "    # 2. 최종 ID 부여 및 정제\n",
    "    final_requirements = []\n",
    "    id_counters = {} \n",
    "    type_prefixes = {\n",
    "        \"기능적\": \"FUNC\", \"비기능적\": \"NFR\", \"성능\": \"PERF\", \"보안\": \"SEC\",\n",
    "        \"데이터\": \"DATA\", \"제약사항\": \"CONS\", \"인터페이스\": \"IF\", \"운영\": \"OPS\",\n",
    "        \"테스트\": \"TEST\", \"품질\": \"QUAL\", \"프로젝트 관리\": \"PM\", \n",
    "        # \"프로젝트 지원\": \"PSUP\", # 제외 요청됨\n",
    "        # \"정책준수\": \"POL\",   # 제외 요청됨\n",
    "        # \"기타\": \"ETC\"        # 제외 요청됨\n",
    "    }\n",
    "    # 제외되지 않는 타입에 대해서만 ID 접두사 유지\n",
    "    valid_type_prefixes = {k: v for k, v in type_prefixes.items() if k not in exclude_types}\n",
    "\n",
    "\n",
    "    for i, req_dict in enumerate(deduplicated_requirements):\n",
    "        req_type = req_dict.get(\"type\", \"기타\")\n",
    "        \n",
    "        # 만약 여기서도 exclude_types에 걸리는 타입이 있다면 최종 제외 (안전장치)\n",
    "        if req_type in exclude_types:\n",
    "            print(f\"    최종 필터링: '{req_type}' 타입 항목 ID '{req_dict.get('id')}' 제외.\")\n",
    "            continue\n",
    "\n",
    "        prefix_candidate = req_type[:3].upper().replace(\" \", \"\").replace(\"_\",\"\") if req_type != \"기타\" else \"ETC\"\n",
    "        prefix = valid_type_prefixes.get(req_type, prefix_candidate if prefix_candidate else \"UNK\") # Unknown prefix\n",
    "        \n",
    "        if prefix not in id_counters:\n",
    "            id_counters[prefix] = 0\n",
    "        id_counters[prefix] += 1\n",
    "        \n",
    "        req_dict[\"id\"] = f\"{prefix}-{id_counters[prefix]:03d}\"\n",
    "        \n",
    "        req_dict.pop(\"pass_info\", None) # 임시 필드 제거\n",
    "        req_dict.pop(\"temp_merged_ids\", None)\n",
    "        \n",
    "        final_requirements.append(req_dict)\n",
    "\n",
    "    final_requirements.sort(key=lambda x: (min(x['source_pages']) if x.get('source_pages') else float('inf'), x.get('id', '')))\n",
    "    \n",
    "    print(f\"--- 전문가 후처리 완료: 최종 {len(final_requirements)}개 요구사항 ---\")\n",
    "    return final_requirements\n",
    "\n",
    "\n",
    "# === 메인 실행 로직 ===\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"./docs/제주은행 모바일뱅킹 재구축사업.pdf\" \n",
    "    output_filename_template = \"extracted_requirements_expert_v4_filtered_{types}.json\"\n",
    "\n",
    "    print(f\"--- RFP 요구사항 추출 전문가 시스템 시작 (입력 파일: {pdf_file_path}) ---\")\n",
    "\n",
    "    full_text, total_pages = expert_extract_text_with_pages(pdf_file_path)\n",
    "    if not full_text or total_pages == 0:\n",
    "        print(f\"오류: PDF에서 텍스트를 추출하지 못했거나 페이지 수가 0입니다.\")\n",
    "        exit()\n",
    "    print(f\"1. PDF 텍스트 추출 완료: 총 {total_pages} 페이지, 전체 텍스트 길이 {len(full_text)}자.\")\n",
    "\n",
    "    chunks = expert_create_chunks(full_text, chunk_size=3800, chunk_overlap=800) \n",
    "    if not chunks:\n",
    "        print(\"오류: 문서에서 청크를 생성하지 못했습니다.\")\n",
    "        exit()\n",
    "    print(f\"2. 문서 청킹 완료: 총 {len(chunks)}개 청크 생성 (overlap: 800).\")\n",
    "\n",
    "    chunks_map = {chunk[\"chunk_id\"]: chunk for chunk in chunks}\n",
    "\n",
    "    print(\"\\n--- 패스 1: 광범위하고 포괄적인 요구사항 후보 식별 시작 ---\")\n",
    "    pass1_requirements = expert_pass1_identify_candidates(chunks, client, LLM_MODEL)\n",
    "    if not pass1_requirements:\n",
    "        print(\"패스 1에서 잠재적 요구사항 후보를 찾지 못했습니다.\")\n",
    "    \n",
    "    print(\"\\n--- 패스 2: 추가 탐색 및 보완 추출 시작 ---\")\n",
    "    # 패스2는 패스1과 동일한 청크를 다시 보며 다른 관점에서 찾음\n",
    "    pass2_requirements = expert_pass2_refine_and_add(chunks, client, LLM_MODEL)\n",
    "    if not pass2_requirements:\n",
    "        print(\"패스 2에서 추가/보완 요구사항을 찾지 못했습니다.\")\n",
    "\n",
    "    all_combined_requirements = pass1_requirements + pass2_requirements\n",
    "    print(f\"\\n모든 패스에서 총 {len(all_combined_requirements)}개의 요구사항 후보 수집 (중복 포함).\")\n",
    "    \n",
    "    # <<< --- 사용자 요청 반영: 특정 타입 제외 --- >>>\n",
    "    types_to_exclude_user_defined = [\"기타\", \"산출물\", \"정책준수\", \"프로젝트 지원\"] \n",
    "    # <<< ------------------------------------ >>>\n",
    "\n",
    "    print(f\"\\n--- 후처리 작업 시작 (제외할 타입: {types_to_exclude_user_defined}) ---\")\n",
    "    final_processed_requirements = expert_post_process_requirements(all_combined_requirements, exclude_types=types_to_exclude_user_defined)\n",
    "\n",
    "    if final_processed_requirements:\n",
    "        print(f\"\\n--- 최종 추출된 고유 요구사항: {len(final_processed_requirements)}개 ---\")\n",
    "        print(\"\\n--- 상위 5개 요구사항 미리보기 ---\")\n",
    "        for i, req_item in enumerate(final_processed_requirements[:5]):\n",
    "            print(json.dumps(req_item, ensure_ascii=False, indent=2))\n",
    "            if i < 4: print(\"-\" * 20)\n",
    "        \n",
    "        excluded_types_str = \"_\".join(sorted(types_to_exclude_user_defined)).replace(\" \",\"\") if types_to_exclude_user_defined else \"none\"\n",
    "        output_filename = output_filename_template.format(types=excluded_types_str)\n",
    "        \n",
    "        try:\n",
    "            with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_processed_requirements, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"\\n최종 추출된 요구사항이 '{output_filename}' 파일에 성공적으로 저장되었습니다.\")\n",
    "        except IOError as e:\n",
    "            print(f\"오류: '{output_filename}' 파일 저장 중 문제가 발생했습니다: {e}\")\n",
    "    else:\n",
    "        print(\"\\n최종적으로 추출된 요구사항이 없습니다.\")\n",
    "\n",
    "    print(\"--- RFP 요구사항 추출 전문가 시스템 종료 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-nqLnFQ7l-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
